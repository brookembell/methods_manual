[["index.html", "LASTING Four-Pillar Model Methodology Introduction Github Repository Data Inputs Code Model Output", " LASTING Four-Pillar Model Methodology Brooke M. Bell 2025-05-20 Introduction This is the comprehensive manual that describes all data inputs and methods used for the LASTING 4-pillar model. This manual was built using bookdown, an open-source R package that facilitates writing books and long-form articles/reports with R Markdown. Github Repository A Github repository (AKA repo) titled methods_manual has been created to store all of the project’s code, data, and documentation (including this manual). In order to gain access to the Github repo, you must ask Brooke to add you as a user. Data Inputs All of the raw data inputs and cleaned datasets are located in the repo: GitHub/methods-manual/data_inputs The raw input files are located in their respectively named folders. For example, the raw NHANES intake data is located in: GitHub/methods-manual/data_inputs/DIET/dietary_intake/DATA/raw_data The raw DataField GHG impact factor dataset is located in: GitHub/methods-manual/data_inputs/ENVIRONMENT/ghg_ced_impacts/DATA Code All of the data cleaning code is embedded within this manual. All of the model code is located in a different repo titled LASTING, managed by Fred Cudhea. The goal is to eventually incorporate the model code into this manual as well, but it’s still TBD. Currently, only Fred Cudhea and Brooke Bell have access to this code. To gain access, please contact Fred and Brooke. As of right now, the R code used to run the analysis on the Tufts High Performance Computing (HPC) Cluster is located in: Github/LASTING/Code/cluster code In order to gain access to the cluster, you must first request an account through ITS here. The primary script is “LASTING_cluster_w_masterinput.R”. This script should be run on the cluster. For more details on how to run the code from the cluster, contact Fred and Brooke. Model Output Output from the models is located in the Box folder here: Box/lasting_aim_3/model_development/model_output "],["summary-of-data-inputs.html", "Chapter 1 Summary of Data Inputs 1.1 Overview 1.2 Diet Inputs 1.3 Economic Inputs 1.4 Environment Inputs 1.5 Health Inputs 1.6 Social Inputs 1.7 Other Inputs", " Chapter 1 Summary of Data Inputs 1.1 Overview This chapter describes all of the data inputs that are used in the model. All data inputs fall into one of the following categories: diet, health, environment, economic, social, and other. In the “methods_manual” folder, there is a “data_inputs” subfolder that contains the following subfolders that correspond with each data input: Diet: methods_manual/data_inputs/DIET/counterfactual_intake (Box) methods_manual/data_inputs/DIET/dietary_intake (Box) Economic: methods_manual/data_inputs/ECONOMIC/fah_fafh_ratio methods_manual/data_inputs/ECONOMIC/food_prices Environment: methods_manual/data_inputs/ENVIRONMENT/ghg_ced_impacts methods_manual/data_inputs/ENVIRONMENT/land_use methods_manual/data_inputs/ENVIRONMENT/water_impacts Health: methods_manual/data_inputs/HEALTH/cancer_incidence methods_manual/data_inputs/HEALTH/cvd_mortality methods_manual/data_inputs/HEALTH/effect_sizes_dietfactor_bmi methods_manual/data_inputs/HEALTH/effect_sizes_dietfactor_sbp methods_manual/data_inputs/HEALTH/logrr_dietfactor_disease methods_manual/data_inputs/HEALTH/overweight_prevalence methods_manual/data_inputs/HEALTH/rr_bmi_cancer methods_manual/data_inputs/HEALTH/rr_bmi_cvd methods_manual/data_inputs/HEALTH/rr_sbp_cvd methods_manual/data_inputs/HEALTH/systolic_blood_pressure methods_manual/data_inputs/HEALTH/tmred Social: methods_manual/data_inputs/SOCIAL/forced_labor Other: methods_manual/data_inputs/OTHER/dietfactor_to_fcid_mapping methods_manual/data_inputs/OTHER/dietfactor_to_fndds_mapping methods_manual/data_inputs/OTHER/food_waste methods_manual/data_inputs/OTHER/labels methods_manual/data_inputs/OTHER/unit_conversions methods_manual/data_inputs/OTHER/us_population 1.2 Diet Inputs 1.2.1 Counterfactual Intake Purpose This dataset contains three recommended dietary patterns (Healthy U.S.-Style Dietary Pattern, Healthy Vegetarian Dietary Pattern, and Healthy Mediterranean-Style Dietary Pattern) from the Dietary Guidelines for Americans (DGA) 2020-2025 report; 1 vegan dietary pattern published in the literature, and 1 dietary pattern that was constructed by the LASTING team (DGA+ Pattern). This dataset serves as the “ideal” dietary pattern that we are shifting to in the 4 models. Raw data sources DGA 2020-2025, Table A3-2: Healthy U.S.-Style Dietary Pattern for Ages 2 and Older (data) DGA 2020-2025, Table A3-4: Healthy Vegetarian Dietary Pattern for Ages 2 and Older (data) DGA 2020-2025, Table A3-5: Healthy Mediterranean-Style Dietary Pattern for Ages 2 and Older (data) Vegan dietary pattern: Hess 2022 (paper) DGA+ pattern: AHA recs, ACS recs (Brooke - add more info here) Raw data location methods_manual/data_inputs/DIET/counterfactual_intake/RESOURCES/DGA 2020-2025/Table A3-2 Healthy U.S.-Style.xlsx methods_manual/data_inputs/DIET/counterfactual_intake/RESOURCES/DGA 2020-2025/Table A3-4 Healthy Vegetarian.xlsx methods_manual/data_inputs/DIET/counterfactual_intake/RESOURCES/DGA 2020-2025/Table A3-5 Healthy Mediterranean-Style.xlsx methods_manual/data_inputs/DIET/counterfactual_intake/RESOURCES/Vegan/Hess 2022.pdf methods_manual/data_inputs/DIET/counterfactual_intake/RESOURCES/DGA+/Org dietary recommendations - operationalized.xlsx Data pre-processing notes We use the 2,000-calorie recommendations for all dietary patterns. Standard deviations were calculated as 10% of the recommendation value, and standard errors were set to 0. Any recommendation values at the week-level were converted to day-level. For example, the Healthy U.S.-Style recommends 1.5 cups/week of dark-green vegetables. This value was divided by 7 and the new value is 0.21 cups/day. Some of the DGA recommendations for various food items were grouped together. For example, the Healthy U.S.-Style recommends 26 oz/week of meats, poultry, and eggs, but it does not provide values for just meats, poultry, or eggs. Therefore, to get recommendation values for each of these three food items individually, we used NHANES 2015-2018 data to look at the intake distribution of these three food items and then applied that proportion to the total 26 oz/week value. This same method was applied to the food group ‘Nuts, seeds, and soy products’, and ‘Limit on calories for other uses’ (added sugar and saturated fat). We also had to construct recommendation values for the dietary factors ‘fruit_exc_juice’ (fruit excluding juice) and ‘veg_exc_sta’ (vegetables excluding starchy vegetables). The recommendation value for veg_exc_sta was simply the sum of the recommendation values for veg_dg (dark-green vegetables), veg_ro (red-orange vegetables), and veg_oth (other vegetables). To calculate the recommendation value for fruit_exc_juice, we utilized the proportion of whole fruits to fruit juice from NHANES. Approximately 75% of total fruit consumed was whole fruit excluding juice. Therefore, the recommendation value for fruit_exc_juice was the DGA recommended value for total fruit multiplied by 0.753. The NHANES proportions are located in: methods_manual/data_inputs/DIET/counterfactual_intake/DATA/NHANES proportions.xlsx (sheets ‘Fruit proportions’, ‘Veg proportions’, ‘Animal protein props US MED’, ‘Veg protein proportions US MED’, and ‘Sugar proportions’) Raw data (pre-processed) location methods_manual/data_inputs/DIET/counterfactual_intake/DATA/counterfactual_intake_050724.csv 1.2.2 Dietary Intake Come back to 1.3 Economic Inputs 1.3.1 Food Prices 1.3.2 Food-At-Home (FAH) vs. Food-Away-From-Home (FAFH) Ratio 1.4 Environment Inputs 1.4.1 Greenhouse Gas Emissions (GHG) and Cumulative Energy Demand (CED) Impact Factors 1.4.2 Water Scarcity (WS) and Bluewater Use (BWU) Impact Factors 1.4.3 Land Use Impact Factors 1.5 Health Inputs 1.5.1 Cancer Incidence Purpose This dataset contains U.S. disease-specific cancer incidence rates from 2018, by age, sex, and race/ethnicity. The following cancers were included in the analysis: Colon and rectum (CC) Corpus uteri (UC) Esophagus: adenomas and adenocarcinomas (ECA) (Note: this is a subset of esophagus cancer) Female breast (post-menopause) (BC)* Gallbladder (GC) Kidney and renal pelvis (KC) Liver and intrahepatic bile duct (LVC) Lung and bronchus (LC) Meningiomas: meningiomas (MC) Myeloma: Multiple myeloma/plasma-cell leukemia (MMC) Mouth, larynx, and pharynx cancers (MLPC) Ovary (OC) Pancreas (PC) Prostate (advanced) (APCA) (Note: this is a subset of prostate cancer) Stomach cardia (SCC) Stomach non-cardia (SCNC) Thyroid (TC) *We only included breast cancer cases from women who were diagnosed at ages 51 years or older to estimate the number of post-menopausal breast cancer cases. Raw Data Sources NCI Surveillance, Epidemiology, and End Results (SEER) Database, 2018 Cancer Incidence [data] Raw Data Location methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/cancerrate2018_0213.txt methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/esophagus2018_0213.txt methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/multiplemyeloma2018_0213.txt methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/prostate2018_0213.txt methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/stomach2018_0213.txt methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/txt/postmenopausal2018_1115.txt Raw Data Processing Notes The following SAS codes were used to transform the raw .txt files into SAS datasets: methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/cancerrate_wide2018_0213.sas methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/esophagus2018_0213.sas methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/multiplemyeloma2018_0213.sas methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/prostate2018_0213.sas methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/stomach2018_0213.sas methods_manual/data_inputs/HEALTH/cancer_incidence/CODE/postmenopausal2018_1115.sas The resulting SAS dataset files are located here: methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/cancerrate2018.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/cancer.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/esophagus.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/myeloma.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/prostate.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/stomach.sas7bdat methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/raw_data/postbreast.sas7bdat Then, the following two SAS codes were used to calculate the estimated number of cancer cases per demographic subgroup in 2018: data_final/in/HEALTH PILLAR/Cancer incidence/Cancerrate2018CRUDE_1115.sas data_final/in/HEALTH PILLAR/Cancer incidence/cancerNHANES 1718POP_0212.sas (generates subgroup population number from NHANES) First, the crude rate for each cancer for each demographic subgroup is calculated by dividing the number of cancer cases reported by the sample population size: \\[ Crude rate = count of cancer cases / sample population size \\] Then, this rate is applied to the 2018 subgroup population numbers (from the US Census Bureau—described in previous section): \\[ No. of cases = crude rate * population size \\] The number of post-menopausal breast cancer cases was calculated slightly differently than the others because we only wanted to estimate breast cancer cases from women who were diagnosed at ages 51 years or older. Specifically, for the demographic subgroups that were female and aged 45-54 (subgroups 17, 18, 19, 20), we applied the crude rate to the U.S. population size of those aged 51-54 (rather than aged 45-54). Processed Raw Data Location The resulting processed dataset is located here: methods_manual/data_inputs/HEALTH/cancer_incidence/DATA/2018CANCERRATE_0327.xls Cleaning Code Location The cleaning codes for this data input are located in Chapter 3.1.2 - Health Data Inputs [link] and Chapter 3.2.1 (1) Cancer incidence and (2) CVD mortality [link]. Data Cleaning Notes The standard error of the cancer counts is calculated as: \\[count_se = (crude_se / 100000) * population)\\] Also, the cancer and CMD datasets are merged into one combined “disease” dataset. Clean Data Location The final cleaned dataset is located here: methods_manual/data_inputs/FINAL/cleaned_data/disease_incidence_YYYY-MM-DD_FINAL.csv where “YYYY-MM-DD” is the most recent export date. 1.5.2 Cardiometabolic Disease (CMD) Mortality 1.5.3 Effect Sizes for Diet and Body Mass Index (BMI) 1.5.4 Effect Sizes for Diet and Systolic Blood Pressure (SBP) 1.5.5 Log Relative Risks (LogRR) for Diet-Cancer 1.5.6 Overweight Prevalence 1.5.7 Relative Risks (RR) for BMI and Cancer 1.5.8 Relative Risks (RR) for BMI and CMD 1.5.9 Relative Risks (RR) for SBP and CMD 1.5.10 Systolic Blood Pressure 1.5.11 TMRED 1.6 Social Inputs 1.6.1 Forced Labor Risk 1.7 Other Inputs 1.7.1 Mapping from Food Group to FCID Code 1.7.2 Mapping from Food Group to FNDDS Code 1.7.3 Inedible and Wasted Food Proportions 1.7.4 Labels 1.7.5 Weight Conversion Units 1.7.6 U.S. Population Size "],["cleaning-code-for-nhanes-diet-data.html", "Chapter 2 Cleaning Code for NHANES Diet Data 2.1 Processed and Organ Meat 2.2 Clean Raw NHANES Data 2.3 Create Sugar Sweetened Beverage (SSB) Variables 2.4 Energy Adjustement 2.5 Calculating Standard Deviations Using SAS Macros", " Chapter 2 Cleaning Code for NHANES Diet Data This chapter walks you through all of code used to clean the raw NHANES dietary intake datasets. 2.1 Processed and Organ Meat To start, we need to disaggregate “procecessed meat” into “processed red meat” and “processed poultry’ categories. We need this because the environmental impact factors don’t take”processed” into consideration, so we’ll need to eventually create new food groups for the environment model (“total red meat” and “total poultry”, which include both unprocessed and processed meat). This is done using a SAS MACRO written by the USDA, located here: data_inputs/DIET/dietary_intake/CODE/0. Processed Meat Categories NHANES day 1_revised_121123.sas This code produces four SAS datasets: meat_day1.sas7bdat meat_day1_sum.sas7bdat meat_day2.sas7bdat meat_day2_sum.sas7bdat We also have to disaggregate the organ meat food codes into “red meat” or “poultry” categories. I manually mapped various FNDDS codes that represented organ meats to either “red meat” or “poultry”. The mapping is here: methods_manual/data_inputs/DIET/dietary_intake/DATA/raw_data/meat/organ_meats_bothdays_mapped_121323.csv Then, I merged this mapping with the processed meat data. library(tidyverse) library(haven) rm(list = ls()) # read in meat data meat_day1 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day1.sas7bdat&quot;) meat_day2 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day2.sas7bdat&quot;) # read in organ mapping new_organ &lt;- read_csv(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/meat/organ_meats_bothdays_mapped_121323.csv&quot;) # DAY 1 ----- meat_day1_1 &lt;- meat_day1 %&gt;% filter(!(is.na(SEQN))) %&gt;% select(SEQN, DESCRIPTION, FOODCODE, DR1ILINE, DR1IGRMS, DR1I_PF_ORGAN, total_redmeat, total_poultry) %&gt;% arrange(SEQN, DR1ILINE) # filter to organ intake &gt; 0 meat_day1_1 %&gt;% filter(DR1I_PF_ORGAN &gt; 0) # join with day1 meat_day1_2 &lt;- left_join(meat_day1_1, new_organ, by = &quot;DESCRIPTION&quot;) meat_day1_3 &lt;- meat_day1_2 %&gt;% rowwise() %&gt;% mutate(new = ifelse(is.na(new), &quot;No change&quot;, new), total_redmeat_new = ifelse(new == &quot;pf_redm&quot;, total_redmeat + DR1I_PF_ORGAN, total_redmeat), total_poultry_new = ifelse(new == &quot;pf_poultry&quot;, total_poultry + DR1I_PF_ORGAN, total_poultry)) %&gt;% select(SEQN, DR1ILINE, total_redmeat_new, total_poultry_new) # export write_rds(meat_day1_3, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day1.rds&quot;) # DAY 2 ----- meat_day2_1 &lt;- meat_day2 %&gt;% filter(!(is.na(SEQN))) %&gt;% select(SEQN, DESCRIPTION2, FOODCODE2, DR2ILINE, DR2IGRMS, DR2I_PF_ORGAN, total_redmeat_day2, total_poultry_day2) %&gt;% arrange(SEQN, DR2ILINE) meat_day2_1 %&gt;% filter(DR2I_PF_ORGAN &gt; 0) # join with day2 meat_day2_2 &lt;- left_join(meat_day2_1, new_organ, by = c(&quot;DESCRIPTION2&quot; = &quot;DESCRIPTION&quot;)) meat_day2_3 &lt;- meat_day2_2 %&gt;% rowwise() %&gt;% mutate(new = ifelse(is.na(new), &quot;No change&quot;, new), total_redmeat_new = ifelse(new == &quot;pf_redm&quot;, total_redmeat_day2 + DR2I_PF_ORGAN, total_redmeat_day2), total_poultry_new = ifelse(new == &quot;pf_poultry&quot;, total_poultry_day2 + DR2I_PF_ORGAN, total_poultry_day2)) %&gt;% select(SEQN, DR2ILINE, total_redmeat_new, total_poultry_new) # export write_rds(meat_day2_3, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day2.rds&quot;) 2.2 Clean Raw NHANES Data Now that I have dealt with processed and organ meat, I can start to clean the raw NHANES data. We use data from the 2015-2016 and 2017-2018 cycles. Step 1: Set up workspace rm(list=ls()) # load packages library(foreign) library(survey) library(tidyverse) library(psych) library(haven) library(readxl) Step 2: Clean individual-level food intake datasets # 2015-2016 diet data (i) # foods day 1 foods_i1_nutrients &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr1iff_i.sas7bdat&quot;) foods_i1_whole &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr1iff_1516.sas7bdat&quot;) # join foods_i1 &lt;- left_join(foods_i1_whole, foods_i1_nutrients) %&gt;% mutate(nhanes_cycle = &quot;2015-2016&quot;) # foods day 2 foods_i2_nutrients &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr2iff_i.sas7bdat&quot;) foods_i2_whole &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr2iff_1516.sas7bdat&quot;) # join foods_i2 &lt;- left_join(foods_i2_whole, foods_i2_nutrients) %&gt;% mutate(nhanes_cycle = &quot;2015-2016&quot;) # 2017-2018 diet data (j) # foods day 1 foods_j1_nutrients &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr1iff_j.sas7bdat&quot;) foods_j1_whole &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr1iff_1718.sas7bdat&quot;) #join foods_j1 &lt;- left_join(foods_j1_whole, foods_j1_nutrients) %&gt;% mutate(nhanes_cycle = &quot;2017-2018&quot;) # foods day 2 foods_j2_nutrients &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr2iff_j.sas7bdat&quot;) foods_j2_whole &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr2iff_1718.sas7bdat&quot;) # join foods_j2 &lt;- left_join(foods_j2_whole, foods_j2_nutrients) %&gt;% mutate(nhanes_cycle = &quot;2017-2018&quot;) # create day 1 and 2 datasets foods_day1 &lt;- rbind(foods_i1, foods_j1) %&gt;% mutate(foodsource = ifelse(DR1FS == 1, &quot;Grocery&quot;, &quot;Other&quot;), # create food source variable foodsource = replace_na(foodsource, &quot;Other&quot;), # replace NAs with &quot;other&quot; (applies to tap water and breast milk) dayrec = 1) # day1 foods_day2 &lt;- rbind(foods_i2, foods_j2) %&gt;% mutate(foodsource = ifelse(DR2FS == 1, &quot;Grocery&quot;, &quot;Other&quot;), # create food source variable foodsource = replace_na(foodsource, &quot;Other&quot;), # replace NAs with &quot;other&quot; (applies to tap water and breast milk) dayrec = 2) # read in meat data meat_day1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day1.rds&quot;) meat_day2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/meat_day2.rds&quot;) foods_day1_ &lt;- left_join(foods_day1, meat_day1, by = c(&quot;SEQN&quot;, &quot;DR1ILINE&quot;)) foods_day2_ &lt;- left_join(foods_day2, meat_day2, by = c(&quot;SEQN&quot;, &quot;DR2ILINE&quot;)) # check foods_day1_ %&gt;% select(SEQN, DR1ILINE, DR1I_PF_MPS_TOTAL, DR1I_PF_SEAFD_HI, DR1I_PF_SEAFD_LOW, total_redmeat_new, total_poultry_new) foods_day1_ %&gt;% filter(DR1I_PF_ORGAN &gt; 0) %&gt;% select(SEQN, DR1ILINE, DR1I_PF_MPS_TOTAL, DR1I_PF_SEAFD_HI, DR1I_PF_SEAFD_LOW, total_redmeat_new, total_poultry_new) # Calculate amount of intake for each dietary factor # for day 1 and day 2 # by SEQN and foodsource # first need to create diet variables that are combinations of 2+ vars # day 1 foods_day1_1 &lt;- foods_day1_ %&gt;% rowwise() %&gt;% rename(sat_fat = DR1ISFAT, p_fat = DR1IPFAT, sodium = DR1ISODI, gr_refined = DR1I_G_REFINED, gr_whole = DR1I_G_WHOLE, added_sugar = DR1I_ADD_SUGARS, fruit_tot = DR1I_F_TOTAL, fruit_juice = DR1I_F_JUICE, fiber = DR1IFIBE, dairy_tot = DR1I_D_TOTAL, veg_dg = DR1I_V_DRKGR, veg_oth = DR1I_V_OTHER, veg_ro = DR1I_V_REDOR_TOTAL, veg_sta = DR1I_V_STARCHY_TOTAL, veg_leg = DR1I_V_LEGUMES, oil = DR1I_OILS, pf_egg = DR1I_PF_EGGS, pf_ns = DR1I_PF_NUTSDS, pf_soy = DR1I_PF_SOY, pf_poultry = DR1I_PF_POULT, pf_redm = DR1I_PF_MEAT, pf_redm_tot = total_redmeat_new, pf_poultry_tot = total_poultry_new, pf_leg = DR1I_PF_LEGUMES, kcal = DR1IKCAL) %&gt;% mutate(sea_omega3_fa = sum(DR1IP226, DR1IP205), veg_exc_sta = sum(veg_dg, veg_ro, veg_oth), fruit_exc_juice = sum(DR1I_F_CITMLB, DR1I_F_OTHER), pf_pm = sum(DR1I_PF_CUREDMEAT, DR1I_PF_ORGAN), pf_seafood = sum(DR1I_PF_SEAFD_HI, DR1I_PF_SEAFD_LOW), leg_tot = sum(pf_leg, pf_soy), # doesn&#39;t include soy milk? pf_animal = sum(DR1I_PF_MPS_TOTAL, pf_egg), pf_plant = sum(pf_leg, pf_ns, pf_soy)) %&gt;% ungroup() # create soy milk category foods_day1_2 &lt;- foods_day1_1 %&gt;% mutate(dairy_soy = ifelse(str_detect(DESCRIPTION, &quot;Soy milk&quot;) &amp; dairy_tot &gt; 0, dairy_tot, 0), dairy_cow = ifelse(str_detect(DESCRIPTION, &quot;Soy milk&quot;, negate = TRUE) &amp; dairy_tot &gt; 0, dairy_tot, 0)) # check foods_day1_2 %&gt;% filter(dairy_tot &gt; 0) %&gt;% select(SEQN, DESCRIPTION, dairy_tot, dairy_soy, dairy_cow) #good # day 2 foods_day2_1 &lt;- foods_day2_ %&gt;% rowwise() %&gt;% rename(sat_fat = DR2ISFAT, p_fat = DR2IPFAT, sodium = DR2ISODI, gr_refined = DR2I_G_REFINED, gr_whole = DR2I_G_WHOLE, added_sugar = DR2I_ADD_SUGARS, fruit_tot = DR2I_F_TOTAL, fruit_juice = DR2I_F_JUICE, fiber = DR2IFIBE, dairy_tot = DR2I_D_TOTAL, veg_dg = DR2I_V_DRKGR, veg_oth = DR2I_V_OTHER, veg_ro = DR2I_V_REDOR_TOTAL, veg_sta = DR2I_V_STARCHY_TOTAL, veg_leg = DR2I_V_LEGUMES, oil = DR2I_OILS, pf_egg = DR2I_PF_EGGS, pf_ns = DR2I_PF_NUTSDS, pf_soy = DR2I_PF_SOY, pf_poultry = DR2I_PF_POULT, pf_redm = DR2I_PF_MEAT, pf_redm_tot = total_redmeat_new, pf_poultry_tot = total_poultry_new, pf_leg = DR2I_PF_LEGUMES, kcal = DR2IKCAL) %&gt;% mutate(sea_omega3_fa = sum(DR2IP226, DR2IP205), veg_exc_sta = sum(veg_dg, veg_ro, veg_oth), fruit_exc_juice = sum(DR2I_F_CITMLB, DR2I_F_OTHER), pf_pm = sum(DR2I_PF_CUREDMEAT, DR2I_PF_ORGAN), pf_seafood = sum(DR2I_PF_SEAFD_HI, DR2I_PF_SEAFD_LOW), leg_tot = sum(pf_leg, pf_soy), pf_animal = sum(DR2I_PF_MPS_TOTAL, pf_egg), pf_plant = sum(pf_leg, pf_ns, pf_soy)) %&gt;% ungroup() # create soy milk category foods_day2_2 &lt;- foods_day2_1 %&gt;% mutate(dairy_soy = ifelse(str_detect(DESCRIPTION, &quot;Soy milk&quot;) &amp; dairy_tot &gt; 0, dairy_tot, 0), dairy_cow = ifelse(str_detect(DESCRIPTION, &quot;Soy milk&quot;, negate = TRUE) &amp; dairy_tot &gt; 0, dairy_tot, 0)) # check foods_day2_2 %&gt;% filter(dairy_tot &gt; 0) %&gt;% select(SEQN, DESCRIPTION, dairy_tot, dairy_soy, dairy_cow) #good # export foods day 1 and day 2 for later use write_rds(foods_day1_2, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_clean.rds&quot;) write_rds(foods_day2_2, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_clean.rds&quot;) Step 3: Clean the food and nutrient intake (summary) datasets rm(list=setdiff(ls(), c(&quot;foods_day1_2&quot;, &quot;foods_day2_2&quot;))) # QUICKLY HANDLE MEAT meat_sum_day1 &lt;- foods_day1_2 %&gt;% group_by(SEQN) %&gt;% summarise(pf_redm_tot_1 = sum(pf_redm_tot), pf_poultry_tot_1 = sum(pf_poultry_tot)) meat_sum_day2 &lt;- foods_day2_2 %&gt;% group_by(SEQN) %&gt;% summarise(pf_redm_tot_2 = sum(pf_redm_tot), pf_poultry_tot_2 = sum(pf_poultry_tot)) # 2015-2016 diet data (i) # demographic data demo_i &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/demo_i.sas7bdat&quot;) %&gt;% select(SEQN, RIAGENDR, RIDRETH1, DMDEDUC2, INDFMPIR, RIDAGEYR) # fped day 1 fped_i1 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr1tot_1516.sas7bdat&quot;) # fped day 2 fped_i2 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr2tot_1516.sas7bdat&quot;) # join the two datasets fped_i &lt;- left_join(fped_i1, fped_i2) # nutrients day 1 nutrient_i1 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr1tot_i.sas7bdat&quot;) # nutrients day 2 nutrient_i2 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr2tot_i.sas7bdat&quot;) # join the two datasets nutrient_i &lt;- full_join(nutrient_i1, nutrient_i2) # Combine all datasets nhanes1516 &lt;- fped_i %&gt;% left_join(nutrient_i) %&gt;% left_join(demo_i) # 2017-2018 diet data (j) # demographic data demo_j &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/demo_j.sas7bdat&quot;) %&gt;% select(SEQN, RIAGENDR, RIDRETH1, DMDEDUC2, INDFMPIR, RIDAGEYR) # fped day 1 fped_j1 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr1tot_1718.sas7bdat&quot;) # fped day 2 fped_j2 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_dr2tot_1718.sas7bdat&quot;) # join the two datasets fped_j &lt;- left_join(fped_j1, fped_j2) # nutrients day 1 nutrient_j1 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr1tot_j.sas7bdat&quot;) # nutrients day 2 nutrient_j2 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/dr2tot_j.sas7bdat&quot;) # join the two datasets nutrient_j &lt;- full_join(nutrient_j1, nutrient_j2) # Combine all datasets nhanes1718 &lt;- fped_j %&gt;% left_join(nutrient_j) %&gt;% left_join(demo_j) # combine the two nhanes datasets # first, change 2 variable names that don&#39;t match nhanes1718 &lt;- nhanes1718 %&gt;% rename(DR1TWS = DR1TWSZ, DR2TWS = DR2TWSZ) nhanes_comb &lt;- rbind(nhanes1516, nhanes1718) # combine with meat nhanes_comb1 &lt;- left_join(nhanes_comb, meat_sum_day1, by = &quot;SEQN&quot;) %&gt;% left_join(meat_sum_day2, by = &quot;SEQN&quot;) # create dairy variables dairy_day1 &lt;- foods_day1_2 %&gt;% group_by(SEQN) %&gt;% summarise(dairy_cow_1 = sum(dairy_cow), dairy_soy_1 = sum(dairy_soy)) dairy_day2 &lt;- foods_day2_2 %&gt;% group_by(SEQN) %&gt;% summarise(dairy_cow_2 = sum(dairy_cow), dairy_soy_2 = sum(dairy_soy)) # merge with nhanes dairy_bothdays &lt;- full_join(dairy_day1, dairy_day2) nhanes_comb2 &lt;- nhanes_comb1 %&gt;% left_join(dairy_bothdays, by = &quot;SEQN&quot;) Step 4: Construct dietary factors nhanes_comb3 &lt;- nhanes_comb2 %&gt;% rename(kcal_1 = DR1TKCAL, kcal_2 = DR2TKCAL, sat_fat_1 = DR1TSFAT, sat_fat_2 = DR2TSFAT, sodium_1 = DR1TSODI, sodium_2 = DR2TSODI, gr_refined_1 = DR1T_G_REFINED, gr_refined_2 = DR2T_G_REFINED, gr_whole_1 = DR1T_G_WHOLE, gr_whole_2 = DR2T_G_WHOLE, added_sugar_1 = DR1T_ADD_SUGARS, added_sugar_2 = DR2T_ADD_SUGARS, fruit_tot_1 = DR1T_F_TOTAL, fruit_tot_2 = DR2T_F_TOTAL, fruit_juice_1 = DR1T_F_JUICE, fruit_juice_2 = DR2T_F_JUICE, fiber_1 = DR1TFIBE, fiber_2 = DR2TFIBE, dairy_tot_1 = DR1T_D_TOTAL, dairy_tot_2 = DR2T_D_TOTAL, veg_dg_1 = DR1T_V_DRKGR, veg_dg_2 = DR2T_V_DRKGR, veg_oth_1 = DR1T_V_OTHER, veg_oth_2 = DR2T_V_OTHER, veg_ro_1 = DR1T_V_REDOR_TOTAL, veg_ro_2 = DR2T_V_REDOR_TOTAL, veg_sta_1 = DR1T_V_STARCHY_TOTAL, veg_sta_2 = DR2T_V_STARCHY_TOTAL, # Beans, peas, and lentils (legumes) computed as vegetables (cup eq.) veg_leg_1 = DR1T_V_LEGUMES, veg_leg_2 = DR2T_V_LEGUMES, oil_1 = DR1T_OILS, oil_2 = DR2T_OILS, pf_egg_1 = DR1T_PF_EGGS, pf_egg_2 = DR2T_PF_EGGS, pf_ns_1 = DR1T_PF_NUTSDS, pf_ns_2 = DR2T_PF_NUTSDS, # soy only # Soy products, excluding calcium fortified soy milk (soymilk) # and raw soybeans products (oz. eq.) pf_soy_1 = DR1T_PF_SOY, pf_soy_2 = DR2T_PF_SOY, pf_poultry_1 = DR1T_PF_POULT, pf_poultry_2 = DR2T_PF_POULT, pf_redm_1 = DR1T_PF_MEAT, pf_redm_2 = DR2T_PF_MEAT, pf_pm_1 = DR1T_PF_CUREDMEAT, pf_pm_2 = DR2T_PF_CUREDMEAT, pf_organ_1 = DR1T_PF_ORGAN, pf_organ_2 = DR2T_PF_ORGAN, # Beans and Peas (legumes) computed as protein foods (oz. eq.) pf_leg_1 = DR1T_PF_LEGUMES, pf_leg_2 = DR2T_PF_LEGUMES) %&gt;% rowwise() %&gt;% mutate(sea_omega3_fa_1 = sum(DR1TP226, DR1TP205), sea_omega3_fa_2 = sum(DR2TP226, DR2TP205), veg_exc_sta_1 = sum(veg_dg_1, veg_ro_1, veg_oth_1), veg_exc_sta_2 = sum(veg_dg_2, veg_ro_2, veg_oth_2), fruit_exc_juice_1 = sum(DR1T_F_CITMLB, DR1T_F_OTHER), fruit_exc_juice_2 = sum(DR2T_F_CITMLB, DR2T_F_OTHER), # pf_redm_tot_1 = sum(), # pf_redm_tot_2 = sum(), # # pf_poultry_tot_1 = sum(), # pf_poultry_tot_2 = sum(), pufa_energy_1 = ((DR1TPFAT * 9) / kcal_1) * 100, pufa_energy_2 = ((DR2TPFAT * 9) / kcal_2) * 100, sfat_energy_1 = ((sat_fat_1 * 9) / kcal_1) * 100, sfat_energy_2 = ((sat_fat_2 * 9) / kcal_2) * 100, pf_seafood_1 = sum(DR1T_PF_SEAFD_HI, DR1T_PF_SEAFD_LOW), pf_seafood_2 = sum(DR2T_PF_SEAFD_HI, DR2T_PF_SEAFD_LOW), # includes legumes and soy foods leg_tot_1 = sum(pf_leg_1, pf_soy_1), leg_tot_2 = sum(pf_leg_2, pf_soy_2), pf_animal_1 = sum(DR1T_PF_MPS_TOTAL, pf_egg_1), pf_animal_2 = sum(DR2T_PF_MPS_TOTAL, pf_egg_2), pf_plant_1 = sum(pf_leg_1, pf_ns_1, pf_soy_1), pf_plant_2 = sum(pf_leg_2, pf_ns_2, pf_soy_2) ) # select the variables we need nhanes_comb4 &lt;- nhanes_comb3 %&gt;% select(SEQN, RIAGENDR, RIDRETH1, DMDEDUC2, INDFMPIR, RIDAGEYR, SDMVPSU, SDMVSTRA, WTDRD1, WTDR2D, DR1DRSTZ, DR2DRSTZ, DRDINT, ends_with(&quot;_1&quot;), ends_with(&quot;_2&quot;)) %&gt;% ungroup() # stop using rowwise Step 5: Create sociodemographic subgroups nhanes_comb5 &lt;- nhanes_comb4 %&gt;% mutate( female = ifelse(RIAGENDR == 2, 1, 0), sex = ifelse(female == 1, 1, 2), race = recode(RIDRETH1, `3` = 1, `4` = 2, `1` = 3, `2` = 3, `5` = 4), age = case_when(RIDAGEYR &gt;= 20 &amp; RIDAGEYR &lt; 35 ~ 1, RIDAGEYR &gt;= 35 &amp; RIDAGEYR &lt; 45 ~ 2, RIDAGEYR &gt;= 45 &amp; RIDAGEYR &lt; 55 ~ 3, RIDAGEYR &gt;= 55 &amp; RIDAGEYR &lt; 65 ~ 4, RIDAGEYR &gt;= 65 &amp; RIDAGEYR &lt; 75 ~ 5, RIDAGEYR &gt;= 75 ~ 6), # create new weight variable wtnew = WTDRD1/2) Step 6: Create averages of dietary factors for Day 1 and Day 2 nhanes_comb6 &lt;- nhanes_comb5 %&gt;% rowwise() %&gt;% mutate(kcal = mean(c(kcal_1, kcal_2), na.rm = TRUE), sat_fat = mean(c(sat_fat_1, sat_fat_2), na.rm = TRUE), sodium = mean(c(sodium_1, sodium_2), na.rm = TRUE), gr_refined = mean(c(gr_refined_1, gr_refined_2), na.rm = TRUE), gr_whole = mean(c(gr_whole_1, gr_whole_2), na.rm = TRUE), added_sugar = mean(c(added_sugar_1, added_sugar_2), na.rm = TRUE), fruit_tot = mean(c(fruit_tot_1, fruit_tot_2), na.rm = TRUE), fruit_exc_juice = mean(c(fruit_exc_juice_1, fruit_exc_juice_2), na.rm = TRUE), fruit_juice = mean(c(fruit_juice_1, fruit_juice_2), na.rm = TRUE), fiber = mean(c(fiber_1, fiber_2), na.rm = TRUE), dairy_tot = mean(c(dairy_tot_1, dairy_tot_2), na.rm = TRUE), dairy_cow = mean(c(dairy_cow_1, dairy_cow_2), na.rm = TRUE), dairy_soy = mean(c(dairy_soy_1, dairy_soy_2), na.rm = TRUE), veg_dg = mean(c(veg_dg_1, veg_dg_2), na.rm = TRUE), veg_oth = mean(c(veg_oth_1, veg_oth_2), na.rm = TRUE), veg_ro = mean(c(veg_ro_1, veg_ro_2), na.rm = TRUE), veg_sta = mean(c(veg_sta_1, veg_sta_2), na.rm = TRUE), veg_leg = mean(c(veg_leg_1, veg_leg_2), na.rm = TRUE), veg_exc_sta = mean(c(veg_exc_sta_1, veg_exc_sta_2), na.rm = TRUE), oil = mean(c(oil_1, oil_2), na.rm = TRUE), pf_egg = mean(c(pf_egg_1, pf_egg_2), na.rm = TRUE), pf_ns = mean(c(pf_ns_1, pf_ns_2), na.rm = TRUE), pf_soy = mean(c(pf_soy_1, pf_soy_2), na.rm = TRUE), pf_poultry = mean(c(pf_poultry_1, pf_poultry_2), na.rm = TRUE), pf_poultry_tot = mean(c(pf_poultry_tot_1, pf_poultry_tot_2), na.rm = TRUE), pf_pm = mean(c(pf_pm_1, pf_pm_2), na.rm = TRUE), pf_redm = mean(c(pf_redm_1, pf_redm_2), na.rm = TRUE), pf_redm_tot = mean(c(pf_redm_tot_1, pf_redm_tot_2), na.rm = TRUE), pf_organ = mean(c(pf_organ_1, pf_organ_2), na.rm = TRUE), pf_leg = mean(c(pf_leg_1, pf_leg_2), na.rm = TRUE), sea_omega3_fa = mean(c(sea_omega3_fa_1, sea_omega3_fa_2), na.rm = TRUE), pufa_energy = mean(c(pufa_energy_1, pufa_energy_2), na.rm = TRUE), sfat_energy = mean(c(sfat_energy_1, sfat_energy_2), na.rm = TRUE), pf_seafood = mean(c(pf_seafood_1, pf_seafood_2), na.rm = TRUE), leg_tot = mean(c(leg_tot_1, leg_tot_2), na.rm = TRUE), pf_animal = mean(c(pf_animal_1, pf_animal_2), na.rm = TRUE), pf_plant = mean(c(pf_plant_1, pf_plant_2), na.rm = TRUE)) # get rid of NaN nhanes_comb6[nhanes_comb6 == &quot;NaN&quot;] &lt;- NA # ungroup nhanes_comb7 &lt;- nhanes_comb6 %&gt;% ungroup() # Merge with subgroup file subgroups &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/population_subgroups_48_060923_FINAL.csv&quot;) nhanes_comb8 &lt;- nhanes_comb7 %&gt;% left_join(subgroups, by = c(&quot;age&quot; = &quot;Age&quot;, &quot;sex&quot; = &quot;Sex&quot;, &quot;race&quot; = &quot;Race&quot;)) # create final dataset nhanes_final &lt;- nhanes_comb8 # look at meat variables nhanes_final %&gt;% select(SEQN, starts_with(c(&quot;pf_redm&quot;, &quot;pf_poultry&quot;, &quot;pf_pm&quot;, &quot;pf_organ&quot;))) %&gt;% mutate(sumtot = (pf_redm + pf_poultry + pf_pm + pf_organ == pf_redm_tot + pf_poultry_tot), sum1 = (pf_redm_1 + pf_poultry_1 + pf_pm_1 + pf_organ_1 == pf_redm_tot_1 + pf_poultry_tot_1), sum2 = (pf_redm_2 + pf_poultry_2 + pf_pm_2 + pf_organ_2 == pf_redm_tot_2 + pf_poultry_tot_2)) nhanes_final %&gt;% select(SEQN, starts_with(c(&quot;pf_redm&quot;, &quot;pf_poultry&quot;, &quot;pf_pm&quot;, &quot;pf_organ&quot;))) %&gt;% mutate(sum1 = (pf_redm + pf_poultry + pf_pm + pf_organ == pf_redm_tot + pf_poultry_tot)) %&gt;% filter(sum1 == &quot;FALSE&quot;) # look at day 1 nhanes_final %&gt;% rowwise() %&gt;% select(SEQN, pf_redm_1, pf_poultry_1, pf_pm_1, pf_organ_1, pf_redm_tot_1, pf_poultry_tot_1) %&gt;% mutate(sum1 = round(sum(pf_redm_1, pf_poultry_1, pf_pm_1, pf_organ_1), digits = 3), sum2 = round(sum(pf_redm_tot_1, pf_poultry_tot_1), digits = 3), my_test = (sum1 == sum2)) %&gt;% filter(my_test == &quot;FALSE&quot;) %&gt;% mutate(my_subtract = sum2 - sum1) %&gt;% filter(my_subtract &lt; -0.05 | my_subtract &gt; 0.05) # not bad # look at day2 nhanes_final %&gt;% rowwise() %&gt;% select(SEQN, pf_redm_2, pf_poultry_2, pf_pm_2, pf_organ_2, pf_redm_tot_2, pf_poultry_tot_2) %&gt;% mutate(sum1 = round(sum(pf_redm_2, pf_poultry_2, pf_pm_2, pf_organ_2), digits = 3), sum2 = round(sum(pf_redm_tot_2, pf_poultry_tot_2), digits = 3), my_test = (sum1 == sum2)) %&gt;% filter(my_test == &quot;FALSE&quot;) %&gt;% mutate(my_subtract = sum2 - sum1) %&gt;% filter(my_subtract &lt; -0.05 | my_subtract &gt; 0.05) # not bad Step 7: Examine cleaned NHANES data # check missing summary(nhanes_final) # check for outliers # kcal &lt; 500 nhanes_final %&gt;% filter(kcal_1 &lt; 500) %&gt;% nrow() #233 nhanes_final %&gt;% filter(kcal_2 &lt; 500) %&gt;% nrow() #301 # kcal &gt; 3500 nhanes_final %&gt;% filter(kcal_1 &gt; 3500) %&gt;% nrow() #1028 nhanes_final %&gt;% filter(kcal_2 &gt; 3500) %&gt;% nrow() #588 # do not remove because I will filter out # dietary recalls that are not valid later # diet recall status table(nhanes_final$DR1DRSTZ, useNA = &quot;always&quot;) table(nhanes_final$DR2DRSTZ, useNA = &quot;always&quot;) # first, create inAnalysis variable nhanes_final1 &lt;- nhanes_final %&gt;% rowwise() %&gt;% mutate( # Define sub-population of interest: # Adults aged 20+ with 1 or 2 days of reliable dietary recalls reliable_yes = ifelse((DRDINT == 1 &amp; DR1DRSTZ == 1) | (DRDINT == 2 &amp; DR1DRSTZ == 1 &amp; DR2DRSTZ == 1), 1, 0), inAnalysis = (!(is.na(subgroup)) &amp; reliable_yes == 1), # if subgroup ISN&#39;T missing and reliable data # Change NAs to 0s, otherwise svydesign function below won&#39;t run wtnew = ifelse(is.na(wtnew), 0, wtnew), SDMVPSU = ifelse(is.na(SDMVPSU), 0, SDMVPSU), SDMVSTRA = ifelse(is.na(SDMVSTRA), 0, SDMVSTRA) ) # check new survey weight nhanes_final1 %&gt;% select(SEQN, wtnew, SDMVPSU, SDMVSTRA, inAnalysis) # looks good # export write_rds(nhanes_final1, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_clean.rds&quot;) Finally, the cleaned dataset is exported to use later. 2.3 Create Sugar Sweetened Beverage (SSB) Variables Now we must separately deal with the beverage data in NHANES. Because SSB can be defined many different ways, there is no “SSB” variable that comes with the NHANES dataset. We must use the raw data to create our own. Our goal is to create SSB variables that we can use in our analysis. 2.3.1 Import and Merge Data Inputs Set up the working directory. rm(list=ls()) # load packages library(tidyverse) library(readxl) library(haven) Import the WWEIA 2015-2016 and 2017-2018 datasets. These contain categorizations of the FNDDS food codes that we will utilize later on. wweia1516 &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA1516_foodcat_FNDDS.xlsx&quot;) wweia1718 &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA1718_foodcat_FNDDS.xlsx&quot;) Then import these other categorizations (GL1, GL2, GL3) that are used. Not really sure what these are for… gl1 &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA category codes.xlsx&quot;, sheet = &quot;GL1&quot;) gl2 &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA category codes.xlsx&quot;, sheet = &quot;GL2&quot;) gl2b &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA category codes.xlsx&quot;, sheet = &quot;GL2b&quot;) gl3 &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA category codes.xlsx&quot;, sheet = &quot;GL3&quot;) Then, import a mapping from the WWEIA categories to these GL categories; and then join everything together. map &lt;- read_xlsx(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/WWEIA category codes.xlsx&quot;, sheet = &quot;Mapping&quot;) # join map_join &lt;- map %&gt;% left_join(gl1) %&gt;% left_join(gl2) %&gt;% left_join(gl2b) %&gt;% left_join(gl3) # merge with wweia datasets wweia1516_1 &lt;- wweia1516 %&gt;% left_join(map_join, by = &quot;category_number&quot;) wweia1718_1 &lt;- wweia1718 %&gt;% left_join(map_join, by = &quot;category_number&quot;) Import FPED 2015-2016 and 2017-2018 datasets. fped1516 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_1516.sas7bdat&quot;) fped1718 &lt;- read_sas(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/fped_1718.sas7bdat&quot;) Calculate the number of grams of added sugar (add_sugars_g), originally provided in teaspoons (ADD_SUGARS), in one serving of each FNDDS food code. fped1516_1 &lt;- fped1516 %&gt;% rename(food_code = FOODCODE) %&gt;% # convert tsp to gram using 1 tsp=4.2g sugar mutate(add_sugars_g = ADD_SUGARS * 4.2) %&gt;% select(food_code, add_sugars_g) fped1718_1 &lt;- fped1718 %&gt;% rename(food_code = FOODCODE) %&gt;% # convert tsp to gram using 1 tsp=4.2g sugar mutate(add_sugars_g = ADD_SUGARS * 4.2) %&gt;% select(food_code, add_sugars_g) Import the NHANES individual-level food data (cleaned in Chapter XX), and merge with the FPED and WWEIA datasets. # read in nhanes individual food data foods_day1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_clean.rds&quot;) foods_day2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_clean.rds&quot;) # split up by NHANES cycle x Day of intake nhanes1516_day1 &lt;- foods_day1 %&gt;% filter(nhanes_cycle == &quot;2015-2016&quot;) nhanes1718_day1 &lt;- foods_day1 %&gt;% filter(nhanes_cycle == &quot;2017-2018&quot;) nhanes1516_day2 &lt;- foods_day2 %&gt;% filter(nhanes_cycle == &quot;2015-2016&quot;) nhanes1718_day2 &lt;- foods_day2 %&gt;% filter(nhanes_cycle == &quot;2017-2018&quot;) # merge fped and wweia datasets merge1516 &lt;- left_join(wweia1516_1, fped1516_1, by = &quot;food_code&quot;) merge1718 &lt;- left_join(wweia1718_1, fped1718_1, by = &quot;food_code&quot;) # merge &quot;merge&quot; datasets with nhanes datasets nhanes1516_day1_join &lt;- left_join(nhanes1516_day1, merge1516, by = c(&quot;DR1IFDCD&quot; = &quot;food_code&quot;)) nhanes1516_day2_join &lt;- left_join(nhanes1516_day2, merge1516, by = c(&quot;DR2IFDCD&quot; = &quot;food_code&quot;)) nhanes1718_day1_join &lt;- left_join(nhanes1718_day1, merge1718, by = c(&quot;DR1IFDCD&quot; = &quot;food_code&quot;)) nhanes1718_day2_join &lt;- left_join(nhanes1718_day2, merge1718, by = c(&quot;DR2IFDCD&quot; = &quot;food_code&quot;)) 2.3.2 Create SSB Indicator Variable Our team decided that a beverage would only be considered an “SSB” if it contained more than 5 grams of added sugar per serving. We set the indicator vairable “ssb” equal to 1 if the number of grams of added sugar per serving (“add_sugars_g”) was greater than or equal to 5 AND if the GL1 category was equal to 151 (“Sugar-sweetened beverages”), 152 (“Sugar-sweetened beverages (diet vs. SSB)”), 153 (“Nutritional beverages (diet vs. SSB)), 154 (”Smoothies and grain drinks (diet vs. SSB)“), 155 (”Coffee”), or 156 (“Tea”). We set “ssb” equal to 0 in all other cases. # work on Day 1 of NHANES &#39;15-&#39;16 first nhanes1516_day1_join_1 &lt;- nhanes1516_day1_join %&gt;% mutate(ssb = ifelse(add_sugars_g &gt;= 5 &amp; between(GL1, 151, 156), 1, 0)) # Day 1 of NHANES &#39;17--18 nhanes1718_day1_join_1 &lt;- nhanes1718_day1_join %&gt;% mutate(ssb = ifelse(add_sugars_g &gt;= 5 &amp; between(GL1, 151, 156), 1, 0)) # only select necessary vars nhanes1516_day1_join_2 &lt;- nhanes1516_day1_join_1 %&gt;% select(SEQN, DR1ILINE, DR1IFDCD, DESCRIPTION, DR1IGRMS, ssb) nhanes15718_day1_join_2 &lt;- nhanes1718_day1_join_1 %&gt;% select(SEQN, DR1ILINE, DR1IFDCD, DESCRIPTION, DR1IGRMS, ssb) # bind Day 1 of NHANES &#39;15-&#39;16 and &#39;17-&#39;18 together day1_final &lt;- rbind(nhanes1516_day1_join_2, nhanes15718_day1_join_2) # now work on Day 2 of NHANES &#39;15-&#39;16 nhanes1516_day2_join_1 &lt;- nhanes1516_day2_join %&gt;% mutate(ssb = ifelse(add_sugars_g &gt;= 5 &amp; between(GL1, 151, 156), 1, 0)) # Day 2 of NHANES &#39;17-&#39;18 nhanes1718_day2_join_1 &lt;- nhanes1718_day2_join %&gt;% mutate(ssb = ifelse(add_sugars_g &gt;= 5 &amp; between(GL1, 151, 156), 1, 0)) # only select necessary vars nhanes1516_day2_join_2 &lt;- nhanes1516_day2_join_1 %&gt;% select(SEQN, DR2ILINE, DR2IFDCD, DESCRIPTION, DR2IGRMS, ssb) nhanes1718_day2_join_2 &lt;- nhanes1718_day2_join_1 %&gt;% select(SEQN, DR2ILINE, DR2IFDCD, DESCRIPTION, DR2IGRMS, ssb) # bind Day 2 of NHANES &#39;15-&#39;16 and &#39;17-&#39;18 together day2_final &lt;- rbind(nhanes1516_day2_join_2, nhanes1718_day2_join_2) Export the datasets to use in the next Chapter section. write_rds(day1_final, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_ssb.rds&quot;) write_rds(day2_final, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_ssb.rds&quot;) 2.3.3 Calculate SSB Intake Now that we know which foodcodes are sugar-sweetened beverages, we want to calculate how much SSB each participant consumed (in grams), per day. # Day 1 ssb_day1 &lt;- day1_final %&gt;% mutate(ssb = as.character(ssb)) %&gt;% group_by(SEQN, ssb) %&gt;% summarise(grams = sum(DR1IGRMS)) %&gt;% #calculate grams of intake by person arrange(SEQN, ssb) ssb_day1_wide &lt;- pivot_wider(ssb_day1, id_cols = SEQN, names_from = ssb, values_from = grams, names_prefix = &quot;ssb&quot;) ssb_day1_wide1 &lt;- ssb_day1_wide %&gt;% mutate(ssb1 = ifelse(!is.na(ssb0) &amp; is.na(ssb1), 0, ssb1)) %&gt;% select(SEQN, ssb1) %&gt;% rename(ssb_1 = ssb1) # Day 2 ssb_day2 &lt;- day2_final %&gt;% mutate(ssb = as.character(ssb)) %&gt;% group_by(SEQN, ssb) %&gt;% summarise(grams = sum(DR2IGRMS)) %&gt;% #calculate grams of intake by person arrange(SEQN, ssb) ssb_day2_wide &lt;- pivot_wider(ssb_day2, id_cols = SEQN, names_from = ssb, values_from = grams, names_prefix = &quot;ssb&quot;) ssb_day2_wide1 &lt;- ssb_day2_wide %&gt;% mutate(ssb1 = ifelse(!is.na(ssb0) &amp; is.na(ssb1), 0, ssb1)) %&gt;% select(SEQN, ssb1) %&gt;% rename(ssb_2 = ssb1) # combine ssb_bothdays &lt;- full_join(ssb_day1_wide1, ssb_day2_wide1, by = &quot;SEQN&quot;) Next, calculate the each participant’s average intake across 2 days of intake. # check # are there any where both are missing? no ssb_bothdays %&gt;% filter(is.na(ssb_1) &amp; is.na(ssb_2)) # calculate day1/day2 ssb intake average ssb_bothdays_1 &lt;- ssb_bothdays %&gt;% rowwise() %&gt;% mutate(ssb = mean(c(ssb_1, ssb_2), na.rm=TRUE)) # get rid of NaN ssb_bothdays_1[ssb_bothdays_1 == &quot;NaN&quot;] &lt;- NA Now merge with the main NHANES intake dataset. # read in clean nhanes dataset nhanes &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_clean.rds&quot;) # merge nhanes_1 &lt;- left_join(nhanes, ssb_bothdays_1, by = &quot;SEQN&quot;) # which ones where ssb (in grams) is more than 0 but lower than 10 grams? (maybe a sip?) nhanes_1 %&gt;% filter(ssb_1 &gt; 0 &amp; ssb_1 &lt; 11) %&gt;% head() nhanes_1 %&gt;% filter(ssb_2 &gt; 0 &amp; ssb_2 &lt; 11) %&gt;% head() # look at just one person - 84956 foods_day2 %&gt;% filter(SEQN == 84956) %&gt;% head() foods_day1 %&gt;% filter(SEQN == 84997) %&gt;% head() # it looks fine Export. write_rds(nhanes_1, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_incl_ssb_clean.rds&quot;) 2.4 Energy Adjustement This next section describes the process of conducting energy adjustment. Energy adjustment is an analytic method by which nutrient and food group intakes are evaluated in relation to total energy intake. Energy adjustment methods are used for two primary reasons: They account for the fact that total energy requirements are related to body size, metabolic efficiency, and physical activity, thereby providing a measure of diet composition. They are useful in mitigating the effects of [glossary term:]measurement error in data collected using self-reported dietary assessment instruments. One frequently used energy adjustment method is the residual method. In this method, the energy-adjusted intake estimate is the residual from a regression model in which total energy intake is the independent variable and absolute nutrient intake is the dependent variable. Thus, the residual is an estimate of nutrient intake uncorrelated with total energy intake and directly related to overall variation in food choice and composition. You can find more information about this on the NCI website here. Additionally, you can refer to Willett WC, Howe GR, Kushi LH. Adjustment for total energy intake in epidemiologic studies. Am J Clin Nutr. 1997 Apr;65(4 Suppl):1220S-1228S; discussion 1229S-1231S. doi: 10.1093/ajcn/65.4.1220S. PMID: 9094926. Step 1: Set up workspace rm(list=ls()) # load packages library(tidyverse) library(modelr) library(survey) Step 2: Import and prepare cleaned NHANES dataset nhanes &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_incl_ssb_clean.rds&quot;) %&gt;% ungroup() # get rid of rowwise formatting nhanes1 &lt;- nhanes %&gt;% select(-c(kcal:pf_plant, ssb)) %&gt;% relocate(c(wtnew:inAnalysis), .before = fruit_juice_1) # wide to long nhanes_long &lt;- pivot_longer(nhanes1, cols = ends_with(c(&quot;_1&quot;, &quot;_2&quot;)), names_to = &quot;names_temp&quot;, values_to = &quot;values_temp&quot;) nhanes_long1 &lt;- nhanes_long %&gt;% separate(names_temp, into=c(&quot;name&quot;, &quot;day&quot;), sep = &quot;_(?=[^_]+$)&quot;) nhanes_long2 &lt;- nhanes_long1 %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;values_temp&quot;) 2.4.0.1 Step 3: Conduct energy adjustment using the residual method Calculate the mean calorie intake across all participants and days (“meancalories”), each observation’s log(calories), the log of “meancalories”, and the log of 2000 kcals. nhanes2 &lt;- nhanes_long2 %&gt;% mutate(calories = kcal, meancalories = mean(calories, na.rm = TRUE), log_calories = log(calories), log_meancalories = log(meancalories), log_2000 = log(2000)) There are a few people who have kcal intake = 0, and the log of this value is -Inf. We need to change this to NA so that the function will run. # 7 people have kcal=0 nhanes2 %&gt;% filter(log_calories == &quot;-Inf&quot; &amp; inAnalysis == &quot;TRUE&quot;) %&gt;% head() # if logcalories is -Inf, change to NA nhanes3 &lt;- nhanes2 %&gt;% mutate(log_calories = ifelse(log_calories == &quot;-Inf&quot;, NA, log_calories)) %&gt;% arrange(SEQN, day) # check nhanes3 %&gt;% filter(log_calories == &quot;-Inf&quot; &amp; inAnalysis == &quot;TRUE&quot;) #good Below is a function that we can apply to all dietary factors in order to calculate the residual method for each. resid_function &lt;- function(x, y){ dat &lt;- x dat[[&quot;var_tem&quot;]] &lt;- dat[[y]] dat1 &lt;- dat %&gt;% mutate(log_var_tem = ifelse(var_tem &gt; 0, log(var_tem), NA)) mod &lt;- lm(log_var_tem ~ log_calories, data = dat1) a = summary(mod)$coefficients[&quot;(Intercept)&quot;, &quot;Estimate&quot;] b = summary(mod)$coefficients[&quot;log_calories&quot;, &quot;Estimate&quot;] dat_new &lt;- dat1 %&gt;% add_residuals(mod) %&gt;% rowwise() %&gt;% mutate(log_cons_var_tem = a + (b * log_2000), a_log_var_tem = log_cons_var_tem + resid, a_var_tem = ifelse(var_tem == 0, 0,exp(a_log_var_tem)), &quot;{y}_adj&quot; := a_var_tem) dat_new1 &lt;- dat_new %&gt;% arrange(SEQN, day) %&gt;% select(paste0(y, &quot;_adj&quot;)) print(dat_new1) } # test resid_function(nhanes3, &quot;pf_pm&quot;) resid_function(nhanes3, &quot;fruit_exc_juice&quot;) resid_function(nhanes3, &quot;sodium&quot;) Create a vector of dietary factors we want to use. diet_vars &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/dietary_factors_010424_FINAL.csv&quot;) %&gt;% select(Food_group) %&gt;% unlist() %&gt;% as.vector() nums &lt;- which(variable.names(nhanes3) %in% diet_vars) new_diet_vars &lt;- variable.names(nhanes3[nums]) Apply the function of all dietary factors of interest. # create empty list resid_list &lt;- list() # loop through all diet factors for (i in new_diet_vars) { resid_list[[i]] &lt;- resid_function(nhanes3, i) } Create a dataset that contains all of the adjusted values, and export. # nhanes with adjusted vars nhanes_adj &lt;- nhanes3 %&gt;% cbind(bind_cols(resid_list)) # check a few diet vars nhanes_adj %&gt;% select(ssb, ssb_adj) %&gt;% head() nhanes_adj %&gt;% select(fruit_exc_juice, fruit_exc_juice_adj) %&gt;% head() nhanes_adj %&gt;% select(pf_ns, pf_ns_adj) %&gt;% head() nhanes_adj %&gt;% select(pf_redm_tot, pf_redm_tot_adj) %&gt;% head() nhanes_adj %&gt;% select(pf_poultry_tot, pf_poultry_tot_adj) %&gt;% head() # export data write_rds(nhanes_adj, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_long.rds&quot;) write_csv(nhanes_adj, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_long.csv&quot;) 2.4.0.2 Step 4: Calculate average daily intake of adjusted variables Pivot to wide format, then calculate the average daily intake by taking the mean of Day 1 and Day 2 values. # pivot to wide nhanes_adj_wide &lt;- nhanes_adj %&gt;% pivot_wider(id_cols = SEQN:inAnalysis, names_from = day, values_from = ends_with(&quot;_adj&quot;)) # calculate averages nhanes_adj_wide1 &lt;- nhanes_adj_wide %&gt;% rowwise() %&gt;% mutate( # fruits fruit_tot_adj = mean(c(fruit_tot_adj_1, fruit_tot_adj_2), na.rm = TRUE), fruit_exc_juice_adj = mean(c(fruit_exc_juice_adj_1, fruit_exc_juice_adj_2), na.rm = TRUE), fruit_juice_adj = mean(c(fruit_juice_adj_1, fruit_juice_adj_2), na.rm = TRUE), # vegs veg_dg_adj = mean(c(veg_dg_adj_1, veg_dg_adj_2), na.rm = TRUE), veg_oth_adj = mean(c(veg_oth_adj_1, veg_oth_adj_2), na.rm = TRUE), veg_ro_adj = mean(c(veg_ro_adj_1, veg_ro_adj_2), na.rm = TRUE), veg_sta_adj = mean(c(veg_sta_adj_1, veg_sta_adj_2), na.rm = TRUE), veg_leg_adj = mean(c(veg_leg_adj_1, veg_leg_adj_2), na.rm = TRUE), veg_exc_sta_adj = mean(c(veg_exc_sta_adj_1, veg_exc_sta_adj_2), na.rm = TRUE), # grains gr_refined_adj = mean(c(gr_refined_adj_1, gr_refined_adj_2), na.rm = TRUE), gr_whole_adj = mean(c(gr_whole_adj_1, gr_whole_adj_2), na.rm = TRUE), # plant based proteins pf_ns_adj = mean(c(pf_ns_adj_1, pf_ns_adj_2), na.rm = TRUE), pf_soy_adj = mean(c(pf_soy_adj_1, pf_soy_adj_2), na.rm = TRUE), pf_leg_adj = mean(c(pf_leg_adj_1, pf_leg_adj_2), na.rm = TRUE), leg_tot_adj = mean(c(leg_tot_adj_1, leg_tot_adj_2), na.rm = TRUE), pf_plant_adj = mean(c(pf_plant_adj_1, pf_plant_adj_2), na.rm = TRUE), # animal proteins pf_egg_adj = mean(c(pf_egg_adj_1, pf_egg_adj_2), na.rm = TRUE), pf_seafood_adj = mean(c(pf_seafood_adj_1, pf_seafood_adj_2), na.rm = TRUE), pf_poultry_adj = mean(c(pf_poultry_adj_1, pf_poultry_adj_2), na.rm = TRUE), pf_poultry_tot_adj = mean(c(pf_poultry_tot_adj_1, pf_poultry_tot_adj_2), na.rm = TRUE), pf_pm_adj = mean(c(pf_pm_adj_1, pf_pm_adj_2), na.rm = TRUE), pf_redm_adj = mean(c(pf_redm_adj_1, pf_redm_adj_2), na.rm = TRUE), pf_redm_tot_adj = mean(c(pf_redm_tot_adj_1, pf_redm_tot_adj_2), na.rm = TRUE), pf_animal_adj = mean(c(pf_animal_adj_1, pf_animal_adj_2), na.rm = TRUE), # ssb ssb_adj = mean(c(ssb_adj_1, ssb_adj_2), na.rm=TRUE), # dairy dairy_tot_adj = mean(c(dairy_tot_adj_1, dairy_tot_adj_2), na.rm = TRUE), dairy_cow_adj = mean(c(dairy_cow_adj_1, dairy_cow_adj_2), na.rm = TRUE), dairy_soy_adj = mean(c(dairy_soy_adj_1, dairy_soy_adj_2), na.rm = TRUE), # other foods oil_adj = mean(c(oil_adj_1, oil_adj_2), na.rm = TRUE), sodium_adj = mean(c(sodium_adj_1, sodium_adj_2), na.rm = TRUE), added_sugar_adj = mean(c(added_sugar_adj_1, added_sugar_adj_2), na.rm = TRUE), # other nutrients sea_omega3_fa_adj = mean(c(sea_omega3_fa_adj_1, sea_omega3_fa_adj_2), na.rm = TRUE), pufa_energy_adj = mean(c(pufa_energy_adj_1, pufa_energy_adj_2), na.rm = TRUE), sfat_energy_adj = mean(c(sfat_energy_adj_1, sfat_energy_adj_2), na.rm = TRUE), sat_fat_adj = mean(c(sat_fat_adj_1, sat_fat_adj_2), na.rm = TRUE), fiber_adj = mean(c(fiber_adj_1, fiber_adj_2), na.rm = TRUE)) Change unit to grams. Use the conversion units from the following file: data_inputs/OTHER/unit_conversions/DATA/Unit_conversions_1.4.24.csv # calculate food group means in grams nhanes_adj_wide2 &lt;- nhanes_adj_wide1 %&gt;% rowwise() %&gt;% mutate(veg_dg_adj_grams = veg_dg_adj * 118 , veg_oth_adj_grams = veg_oth_adj * 140, veg_ro_adj_grams = veg_ro_adj * 144, veg_sta_adj_grams = veg_sta_adj * 134, veg_tot_adj_grams = sum(veg_dg_adj_grams, veg_oth_adj_grams, veg_ro_adj_grams, veg_sta_adj_grams), gr_refined_adj_grams = gr_refined_adj * 36, gr_whole_adj_grams = gr_whole_adj * 51, gr_tot_adj_grams = sum(gr_refined_adj_grams, gr_whole_adj_grams), pf_egg_adj_grams = pf_egg_adj * 50, pf_poultry_tot_adj_grams = pf_poultry_tot_adj * 29, pf_redm_tot_adj_grams = pf_redm_tot_adj * 31, pf_seafood_adj_grams = pf_seafood_adj * 29, pf_ns_adj_grams = pf_ns_adj * 15, leg_tot_adj_grams = leg_tot_adj * 37, pf_tot_adj_grams = sum(pf_egg_adj_grams, pf_poultry_tot_adj_grams, pf_redm_tot_adj_grams, pf_seafood_adj_grams, pf_ns_adj_grams, leg_tot_adj_grams), fruit_exc_juice_adj_grams = fruit_exc_juice_adj * 152, fruit_juice_adj_grams = fruit_juice_adj * 251, fruit_tot_adj_grams = sum(fruit_exc_juice_adj_grams, fruit_juice_adj_grams)) # get rid of NaN nhanes_adj_wide2[nhanes_adj_wide2 == &quot;NaN&quot;] &lt;- NA Export. write_rds(nhanes_adj_wide2, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_wide.rds&quot;) write_csv(nhanes_adj_wide2, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_wide.csv&quot;, na = &quot;&quot;) 2.5 Calculating Standard Deviations Using SAS Macros When we estimate the average intakes, by demographic subgroup, in the previous section XX, the mean and standard error are calculated. We also need to calculate the standard deviations of the mean intake for each dietary factor. This can be done using the NCI Method SAS macros. We use a modified version of the SIMPLE macro, which is a single macro that links 3 NCI macros, the MIXTRAN, DISTRIB, and BRR_PVALUE_CI, to facilitate estimation of usual intake distributions for food and nutrients consumed “nearly-daily.” The SIMPLE macro documentation is provided here. An updated version of the macro was provided to our team by Hanqi Luo. The publication describing the macro is located here. The NCI macro documentation is provided here. I highly recommend you read all of the aforementioned documentation before your proceed. The SIMPLE macro was modified by Brooke Bell (the person writing this!). She added code to the macro to additionally calculate the standard deviation of the mean intake. The version that she modified is located in the LASTING GitHub repo here: GitHub/LASTING/standard-deviations/macros/simple_macro_v3.4_bmb.sas This macro is run on the Tufts cluster because it uses a lot of processing power. The following sections will describe the data inputs that are used in the macro, and how to run the macro on the cluster. 2.5.1 Prepare NHANES Data for SAS Macros We need to make some minor adjustments to the diet dataset’s structure in order to properly use the SAS macro. First, import the adjusted intake dataset (long format) that was created in the previous section. rm(list = ls()) library(tidyverse) library(fastDummies) # Import data nhanes &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_long.rds&quot;) # only select certain variables nhanes1 &lt;- nhanes %&gt;% select(SEQN, age, sex, race, subgroup, DRDINT, SDMVPSU, SDMVSTRA, wtnew, reliable_yes, inAnalysis, day, ends_with(&quot;adj&quot;)) Then, we need to create a new variable (“subgroup_new”) that only has a non-missing subgroup number if that participant’s data is reliable (i.e., inAnalysis == TRUE). This essentially changes any subgroup number to NA if the participant’s data is unreliable. nhanes2 &lt;- nhanes1 %&gt;% mutate(subgroup_new = ifelse(inAnalysis == &quot;TRUE&quot;, subgroup, NA)) %&gt;% relocate(subgroup_new, .after = subgroup) # check nhanes2 %&gt;% filter(!(is.na(subgroup)) &amp; !(is.na(subgroup_new))) %&gt;% head() Next, create dummy variables for the variables “day”, “inAnalysis”, “subgroup”, and “subgroup_new”. We utilize the “dummy_cols” function from the “fastDummies” package to do this quickly. You can learn more about this function by running the command “?dummy_cols”. nhanes3 &lt;- nhanes2 %&gt;% dummy_cols(select_columns = c(&quot;day&quot;, &quot;inAnalysis&quot;, &quot;subgroup&quot;, &quot;subgroup_new&quot;), remove_first_dummy = TRUE) %&gt;% relocate(day_2, .after = day) We need to remove the rows where a participant’s number of days of intake is 1 (DRDINT == 1) and day == 2 (since they don’t have any data for this day). # check nhanes3 %&gt;% filter(DRDINT == 1 &amp; day == 2) %&gt;% head() nhanes4 &lt;- nhanes3 %&gt;% filter(!(DRDINT == 1 &amp; day == 2)) # check nhanes4 %&gt;% filter(is.na(fruit_tot_adj)) %&gt;% head() #good nhanes4 %&gt;% filter(is.na(fruit_tot_adj) &amp; inAnalysis == &quot;TRUE&quot;) %&gt;% head() #good Export to Box. write_csv(nhanes4, &quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes_incl_ssb_adj_clean_long.csv&quot;, na = &quot;&quot;) Export to the LASTING Github repository. Note that you will need to replace this file path with your own in order for this code to run. write_csv(nhanes4, &quot;/Users/bmb73/Documents/GitHub/LASTING/standard-deviations/in/nhanes_incl_ssb_adj_clean_long.csv&quot;, na = &quot;&quot;) 2.5.2 Fill Out Macro Template Before running the SIMPLE macro, I highly suggest that you read the following documentation: data_inputs/DIET/dietary_intake/RESOURCES/SAS MACRO User Guides/SIMPLE_macro_user_manual_10-30-2020.pdf The Simulating Intake of Micronutrients for Policy Learning and Engagement (SIMPLE) macro is a ‘wrapper’ for the National Cancer Institute MIXTRAN, DISTRIB, and BOXCOX_SURVEY macros to facilitate estimation of usual intake distributions for food and nutrients consumed ‘nearly-daily’. You must first fill out a CSV file that lists all of the diet variables that you want the SIMPLE macro to run. If you would like to run all the diet variables that were included in the four-pillar paper analysis, then you can use the following file: /Users/bmb73/Documents/GitHub/LASTING/standard-deviations/in/macro_input_LASTING_ALL_VARS.csv I will refer you to the above documentation if you want to make any modifications to the input file that already exists. 2.5.3 Log In to Tufts HPC The next step is to actually run the macro on the cluster (“HPC”). The file that you will be running is the following: GitHub/LASTING/standard-deviations/cluster_code/Calculate_SD_nci_method_05-19-25_cluster_loop.sas Please read the SAS file first before running it on the cluster so that you understand what is happening in the code. You should save a new version of the SAS code for your own project, so that you don’t accidentally write over the orignial one. You must first log into the cluster computer via OnDemand. See Chapter XX for information on how to gain access to OnDemand, and how to get a GitHub access token. 2.5.4 Run SAS Macro Once logged in to OnDemand, navigate to /cluster/tufts/lasting/shared/LASTING. Then, open the terminal. Type “git pull” into the command prompt. It will ask you to log into Github with your username and token. Then, it will start to sync with the most updated version of the LASTING repo. NOTE: NEVER use the “git push” command. Just trust me. Ask Fred if you’re really curious. Then, type “exit” and close the terminal. Now, navigate to /cluster/tufts/lasting/shared/LASTING/standard-devations/cluster_code. The batch file you’re going to be running is “Run_SDs_cluster.sh”. I also recommend saving a new version of this for your own project. You will also need to edit some of the parameters in the file, such as time requested and email. You can edit the file by clicking the button “Edit”. Don’t forget to click “Save” when you’re done. Then, open the terminal again. Type “sbatch Run_SDs_cluster” into the command prompt. Once you see that the job was submitted, you can exit the terminal. 2.5.5 Export Output to Box When the code is done running, the output is saved to the following folders: /cluster/tufts/lasting/shared/model_development/data/outputs/CRA/ /cluster/tufts/lasting/shared/model_development/data/outputs/cost_env/ You will need to use a file transfer software to copy the output files to Box. Fred and I use FileZilla, but it looks like Tufts IT recommends Globus). I’d go with that. Follow IT’s instructions on how to set up the connection. Anyway, using whatever software you decide on, you will simply copy the files to the following Box folder: /Box/lasting_aim_3/model development/methods_manual/outputs/intake/ Create a folder named “output_INSERTDATE_ncimethod” and put the files in there. 2.5.6 Clean Output from Cluster Lastly (phew), we need to clean the output to use in the following chapters. You will need to update the file path when running this. First, retrieve all the output file names. rm(list=ls()) my_date &lt;- Sys.Date() # Specify the directory containing the CSV files directory &lt;- &quot;outputs/intake/output_031025_ncimethod&quot; # Get the list of all CSV files in the directory file_list &lt;- list.files(path = directory, pattern = &quot;*.csv&quot;, full.names = TRUE) Then, import the files and clean. # Read each CSV file and store them in a list of data frames data_list &lt;- lapply(file_list, read_csv) # Combine all data frames into one data frame combined_data &lt;- bind_rows(data_list) # Clean intake &lt;- combined_data %&gt;% select(note, subgroup_new, N, mean, mean_SE, StdDev) %&gt;% # only select subgroups 1-48 filter(subgroup_new %in% c(1:48)) %&gt;% rename(food = note, subgroup = subgroup_new, SE = mean_SE) %&gt;% arrange(subgroup, food) # fix food name intake1 &lt;- intake %&gt;% mutate(food = str_remove(food, &quot;_adj$&quot;)) # fix poultry name intake2 &lt;- intake1 %&gt;% mutate(food = ifelse(food == &quot;poult_tot&quot;, &quot;pf_poultry_tot&quot;, food)) Read in two datasets (food labels and % grocery intake) and merge with intake data. # merge with food labels labels &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/dietary_factors_010424_FINAL.csv&quot;) labels1 &lt;- labels %&gt;% rename(food = Food_group) %&gt;% relocate(food) # read in pro_gro from original output ratio &lt;- read_csv(&quot;data_inputs/DIET/dietary_intake/DATA/output_data/NHANES_1518_summary_allfoods_adj_bysub_bysource_02-03-2025.csv&quot;) %&gt;% select(subgroup, food, pro_gro) %&gt;% mutate(subgroup = as.character(subgroup)) # join intake3 &lt;- left_join(intake2, labels1, by = &quot;food&quot;) %&gt;% left_join(ratio, by = c(&quot;subgroup&quot;, &quot;food&quot;)) intake4 &lt;- intake3 %&gt;% relocate(subgroup) %&gt;% rename(food_label = Var_label, food_desc = Var_desc) %&gt;% arrange(subgroup, food) Export. write_csv(intake4, paste0(&quot;data_inputs/DIET/dietary_intake/DATA/output_data_from_cluster/NHANES_1518_summary_allfoods_adj_bysub_ncimethod_&quot;, my_date, &quot;.csv&quot;)) "],["cleaning-code-for-health-data.html", "Chapter 3 Cleaning Code for Health Data 3.1 Create Final Data Inputs 3.2 Clean Health Datasets 3.3 Restructure data", " Chapter 3 Cleaning Code for Health Data This chapter walks you through all of the R code used to clean the raw HEALTH-related data inputs. The resulting cleaned datasets are then used in the modeling (see next Chapter). 3.1 Create Final Data Inputs This script imports all of raw health-related data inputs needed for the model. Note that you must first open the ‘methods_manual’ R project before running this script or else it will not work. First, let’s set up our environment. rm(list = ls()) options(scipen=999) library(tidyverse) library(readxl) library(stringr) # check working directory getwd() Create a date string that will be appended to all data file names. my_date &lt;- paste0(&quot;_&quot;, Sys.Date(), &quot;_FINAL.csv&quot;) 3.1.1 Other Data Inputs U.S. population Just need to round the population number the nearest whole number. Then export data to FINAL folder. pop &lt;- read_xlsx(&quot;data_inputs/OTHER/us_population/DATA/NHANES 17 SUBPOPratio_0327.xlsx&quot;, sheet = &quot;final&quot;) pop1 &lt;- pop %&gt;% rename(subgroup = subgroup_id, `2018_pop` = Pop_2018) %&gt;% mutate(`2018_pop` = ceiling(`2018_pop`)) # round up to next whole number write_csv(pop1, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/population_distribution&quot;, my_date)) Conversion units Just select the needed variables then export. units &lt;- read_csv(&quot;data_inputs/OTHER/unit_conversions/DATA/Unit_conversions_1.4.24.csv&quot;) units1 &lt;- units %&gt;% select(Food_group, DGA_unit, Conversion_to_grams, Equation) write_csv(units1, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/unit_conversions&quot;, my_date)) Clear global environment expect for my_date. rm(list=setdiff(ls(), c(&quot;my_date&quot;))) 3.1.2 Health Data Inputs Cancer incidence Import the raw cancer data input, clean up the variable names, and calculate the standard error of the cancer counts (‘count_se’). # import cancer data cancer &lt;- read_xls(&quot;data_inputs/HEALTH/cancer_incidence/DATA/2018CANCERRATE_0327.xls&quot;, sheet = &quot;2018pop&quot;) cancer1 &lt;- cancer %&gt;% select(subgroup_id, cancer_code_ICD_O_3, Crude_Rate, Standard_Error, `_2018_pop`, No_2018) %&gt;% rename(crude_rate = Crude_Rate, crude_se = Standard_Error, count = No_2018, population = `_2018_pop`, subgroup = subgroup_id, diseases = cancer_code_ICD_O_3) %&gt;% mutate(count_se = (crude_se / 100000) * population) Recode the cancer labels as shorter abbreviations. cancer2 &lt;- cancer1 %&gt;% mutate(diseases = recode(diseases, &quot;All Sites&quot; = &quot;ALL&quot;, &quot;Colon and Rectum&quot; = &quot;CC&quot;, &quot;Corpus Uteri&quot; = &quot;UC&quot;, &quot;Esophagus&quot; = &quot;ECA&quot;, &quot;Breast&quot; = &quot;BC&quot;, &quot;Gallbladder&quot; = &quot;GC&quot;, &quot;Kidney and Renal Pelvis&quot; = &quot;KC&quot;, &quot;Liver and Intrahepatic Bile Duct&quot; = &quot;LVC&quot;, &quot;Lung and Bronchus&quot; = &quot;LC&quot;, &quot;myeloma&quot; = &quot;MMC&quot;, &quot;Ovary&quot; = &quot;OC&quot;, &quot;Pancreas&quot; = &quot;PC&quot;, &quot;prostate(advanced)&quot; = &quot;APCA&quot;, &quot;stomach_cardia&quot; = &quot;SCC&quot;, &quot;stomach_noncar&quot; = &quot;SCNC&quot;, &quot;Thyroid&quot; = &quot;TC&quot;, &quot;oral cavity and pharynx and larynx&quot; = &quot;MLPC&quot;)) Round the count values to the nearest whole number. cancer3 &lt;- cancer2 %&gt;% mutate(population = ceiling(population), count = ceiling(count), count_se = ceiling(count_se)) %&gt;% arrange(diseases, subgroup) Lastly, merge with population subsgroup information and cancer labels. # import subgroups info subgrps &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/population_subgroups_48_060923_FINAL.csv&quot;) # join with cancer data cancer4 &lt;- left_join(cancer3, subgrps, by = &quot;subgroup&quot;) # import cancer label data dis_labels &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/disease_outcomes_060923_FINAL.csv&quot;) %&gt;% select(outcome, outcome_label) cancer5 &lt;- left_join(cancer4, dis_labels, by = c(&quot;diseases&quot; = &quot;outcome&quot;)) %&gt;% rename(diseases_label = outcome_label) %&gt;% relocate(diseases_label, .after = diseases) If the rate or standard error variable are missing, then replace with 0. Lastly, export the cleaned file to the “FINAL” folder. cancer6 &lt;- cancer5 %&gt;% mutate(crude_rate = ifelse(is.na(crude_rate), 0, crude_rate), crude_se = ifelse(is.na(crude_se), 0, crude_se), count_se = ifelse(is.na(count_se), 0, count_se)) # export final dataset write_csv(cancer6, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/cancer_incidence&quot;, my_date)) Cardiovascular disease (CVD) mortaliaty Import raw CVD data and tidy. cvd &lt;- read_xlsx(&quot;data_inputs/HEALTH/cvd_mortality/DATA/CVDmotality2018_11022023.xlsx&quot;, sheet = &quot;merge&quot;) cvd1 &lt;- cvd %&gt;% select(cause, subgroup_id, Deaths, Deaths_se) %&gt;% rename(subgroup = subgroup_id) %&gt;% mutate(deaths_rounded = ceiling(Deaths), deaths_se_rounded = ceiling(Deaths_se)) # look at outcome labels unique(cvd1$cause) # need to rename diabetes cvd2 &lt;- cvd1 %&gt;% mutate(cause = recode(cause, &quot;DM&quot; = &quot;DIAB&quot;)) %&gt;% select(-c(Deaths, Deaths_se)) Transform the mean and SE data from long to wide format and then rejoin. # just mean death values cvd_wide_mean &lt;- pivot_wider(cvd2 %&gt;% select(-deaths_se_rounded), names_from = cause, values_from = deaths_rounded) # just se death values cvd_wide_se &lt;- pivot_wider(cvd2 %&gt;% select(-deaths_rounded), names_from = cause, values_from = deaths_se_rounded, names_prefix = &quot;se_&quot;) # merge cvd_wide &lt;- left_join(cvd_wide_mean, cvd_wide_se, by = &quot;subgroup&quot;) Join with population subgroup information. # get rid of NA row cvd_wide1 &lt;- cvd_wide %&gt;% filter(!(is.na(subgroup))) # merge with cvd data cvd_final &lt;- left_join(cvd_wide1, subgrps, by = &quot;subgroup&quot;) %&gt;% relocate(subgroup, Age, Age_label, Sex, Sex_label, Race, Race_label) Create the BMI-mediated and SBP-mediated variables by simply setting them equal to the cvd death values. This is needed for the model code to work properly later. cvd_final1 &lt;- cvd_final %&gt;% mutate( # BMI AA_medBMI = AA, se_AA_medBMI = se_AA, AFF_medBMI = AFF, se_AFF_medBMI = se_AFF, CM_medBMI = CM, se_CM_medBMI = se_CM, DIAB_medBMI = DIAB, se_DIAB_medBMI = se_DIAB, ENDO_medBMI = ENDO, se_ENDO_medBMI = se_ENDO, HHD_medBMI = HHD, se_HHD_medBMI = se_HHD, HSTK_medBMI = HSTK, se_HSTK_medBMI = se_HSTK, IHD_medBMI = IHD, se_IHD_medBMI = se_IHD, ISTK_medBMI = ISTK, se_ISTK_medBMI = se_ISTK, OSTK_medBMI = OSTK, se_OSTK_medBMI = se_OSTK, OTH_medBMI = OTH, se_OTH_medBMI = se_OTH, PVD_medBMI = PVD, se_PVD_medBMI = se_PVD, RHD_medBMI = RHD, se_RHD_medBMI = se_RHD, TSTK_medBMI = TSTK, se_TSTK_medBMI = se_TSTK, # SBP AA_medSBP = AA, se_AA_medSBP = se_AA, AFF_medSBP = AFF, se_AFF_medSBP = se_AFF, CM_medSBP = CM, se_CM_medSBP = se_CM, DIAB_medSBP = DIAB, se_DIAB_medSBP = se_DIAB, ENDO_medSBP = ENDO, se_ENDO_medSBP = se_ENDO, HHD_medSBP = HHD, se_HHD_medSBP = se_HHD, HSTK_medSBP = HSTK, se_HSTK_medSBP = se_HSTK, IHD_medSBP = IHD, se_IHD_medSBP = se_IHD, ISTK_medSBP = ISTK, se_ISTK_medSBP = se_ISTK, OSTK_medSBP = OSTK, se_OSTK_medSBP = se_OSTK, OTH_medSBP = OTH, se_OTH_medSBP = se_OTH, PVD_medSBP = PVD, se_PVD_medSBP = se_PVD, RHD_medSBP = RHD, se_RHD_medSBP = se_RHD, TSTK_medSBP = TSTK, se_TSTK_medSBP = se_TSTK) Export to FINAL folder. write_csv(cvd_final1, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/cvd_mortality&quot;, my_date)) Other health data Import other health datsets. weight &lt;- read_xls(&quot;data_inputs/HEALTH/overweight_prevalence/DATA/overweight1518_48grp_04.10.23.xls&quot;) hbp &lt;- read_xls(&quot;data_inputs/HEALTH/systolic_blood_pressure/DATA/SBP_1718_04192023.xls&quot;, sheet = &quot;HBPbyGRP&quot;) sbp &lt;- read_xls(&quot;data_inputs/HEALTH/systolic_blood_pressure/DATA/SBP_1718_04192023.xls&quot;, sheet = &quot;over20yr&quot;) #high sbp variables highSBP &lt;- read_xlsx(&quot;data_inputs/HEALTH/systolic_blood_pressure/DATA/highSBP_data.xlsx&quot;) Create non-Hipsanic Black (NHB) variables. oth_health &lt;- weight %&gt;% mutate(nhb = ifelse(Race_label == &quot;NHB&quot;, 1, 0), nhb_se = 0) %&gt;% rename(overweight_rate = Percent, overweight_rate_se = StdErr) %&gt;% select(subgroup, overweight_rate, overweight_rate_se, nhb, nhb_se) The SBP data is at the participant-level so it needs to be summarized at population subgroup level. sbp1 &lt;- sbp %&gt;% filter(!(is.na(mean_sbp))) # only include those with non-missing mean_sbp value # summarize by subgroup ID sbp_vars &lt;- sbp1 %&gt;% group_by(subgroup_id) %&gt;% summarise(sbp_mean = mean(mean_sbp), # calculate standard error sbp_se = sd(mean_sbp)/sqrt(length(mean_sbp))) # merge with highSBP highSBP1 &lt;- highSBP %&gt;% select(subgroup_id, Percent, StdErr) %&gt;% rename(highSBP_rate = Percent, highSBP_rate_se = StdErr) sbp_vars1 &lt;- left_join(sbp_vars, highSBP1, by = &quot;subgroup_id&quot;) # merge sbp vars with oth_health oth_health1 &lt;- left_join(oth_health, sbp_vars1, by = c(&quot;subgroup&quot; = &quot;subgroup_id&quot;)) # hbp variables hbp1 &lt;- hbp %&gt;% rename(hbp = Percent, hbp_se = StdErr) %&gt;% mutate(hbp = hbp/100, hbp_se = hbp_se/100) %&gt;% select(subgroup_id, hbp, hbp_se) # merge hbp vars with oth_health oth_health2 &lt;- left_join(oth_health1, hbp1, by = c(&quot;subgroup&quot; = &quot;subgroup_id&quot;)) Export to FINAL folder. write_csv(oth_health2, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/other_health&quot;, my_date)) Effect sizes for diet and body mass index (BMI) No changes are needed so just import the file then export to FINAL folder. bmi_effects &lt;- read_csv(&quot;data_inputs/HEALTH/effect_sizes_dietfactor_bmi/DATA/food_to_BMI_effects_from_Dari_1.5.24.csv&quot;) write_csv(bmi_effects, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/food_to_bmi_effects&quot;, my_date)) Effect sizes for diet and systolic blood pressure (SBP) No changes are needed so just import the file then export to FINAL folder. sbp_effects &lt;- read_csv(&quot;data_inputs/HEALTH/effect_sizes_dietfactor_sbp/DATA/food_to_sbp_effects_NOT_converted_1.5.24.csv&quot;) write_csv(sbp_effects, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/food_to_sbp_effects&quot;, my_date)) Relative risks (RR) for BMI and cancer No changes are needed so just import the file then export to FINAL folder. bmi_cancer &lt;- read_csv(&quot;data_inputs/HEALTH/rr_bmi_cancer/DATA/RR_BMI_cancer_11.23.22.csv&quot;) write_csv(bmi_cancer, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_bmi_cancer&quot;, my_date)) Relative risks (RR) for BMI and CVD No changes are needed so just import the file then export to FINAL folder. bmi_cvd &lt;- read_csv(&quot;data_inputs/HEALTH/rr_bmi_cvd/DATA/RR_BMI_cvd_3.2.23.csv&quot;) write_csv(bmi_cvd, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_bmi_cvd&quot;, my_date)) Relative risks (RR) for SBP and CVD No changes are needed so just import the file then export to FINAL folder. sbp_cvd &lt;- read_csv(&quot;data_inputs/HEALTH/rr_sbp_cvd/DATA/RR_sbp_cvd_2.16.23.csv&quot;) write_csv(sbp_cvd, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_sbp_cvd&quot;, my_date)) Log relative risks (LogRR) for diet-CVD No changes are needed so just import the file then export to FINAL folder. rm(list=ls(pattern=&quot;^cvd&quot;)) cvd &lt;- read_csv(&quot;data_inputs/HEALTH/logrr_dietfactor_disease/DATA/logRR_diet_cvd_byage_1.26.24.csv&quot;) write_csv(cvd, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/logRR_diet_cvd&quot;, my_date)) Log relative risks (LogRR) for diet-cancer No changes are needed so just import the file then export to FINAL folder. rm(list=ls(pattern=&quot;^cancer&quot;)) cancer &lt;- read_csv(&quot;data_inputs/HEALTH/logrr_dietfactor_disease/DATA/logRR_diet_cancer_1.5.24.csv&quot;) write_csv(cancer, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/logRR_diet_cancer&quot;, my_date)) TMRED Import the TMRED values (in grams). Then, import the conversion units and join with the TMRED data. tmred_g &lt;- read_csv(&quot;data_inputs/HEALTH/tmred/DATA/TMRED_grams_1.5.24.csv&quot;) # import conversion units conversion &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/unit_conversions&quot;, my_date)) # join with tmred dataset tmred_dga &lt;- left_join(tmred_g, conversion, by = c(&quot;Risk_factor&quot; = &quot;Food_group&quot;)) Then, transform the TMRED mean and standard deviation values from grams to “FPED units” (i.e., cups or ounces). tmred_dga1 &lt;- tmred_dga %&gt;% mutate(tmred_dga_units = TMRED / Conversion_to_grams, sd_dga_units = SD / Conversion_to_grams) tmred_dga2 &lt;- tmred_dga1 %&gt;% select(Risk_factor, tmred_dga_units, sd_dga_units, DGA_unit) %&gt;% rename(TMRED = tmred_dga_units, SD = sd_dga_units, Unit = DGA_unit) %&gt;% mutate(TMRED = signif(TMRED, 3), # round to 3 sig figs SD = signif(SD, 3), # round to 3 sig figs Unit = str_sub(Unit, start = 3)) # fix unit var Then, export the conversion units in both grams and FPED units to be used later. # export grams dataset write_csv(tmred_g, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/tmred_grams&quot;, my_date)) # export FPED units write_csv(tmred_dga2, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/tmred_dga_units&quot;, my_date)) Clear global environment expect for my_date. rm(list=setdiff(ls(), c(&quot;my_date&quot;))) 3.1.3 Diet Data Inputs Dietary intake Import the NHANES diet intake dataset and clean up. nhanes &lt;- read_csv(&quot;data_inputs/DIET/dietary_intake/DATA/output_data_from_cluster/NHANES_1518_summary_allfoods_adj_bysub_ncimethod_2025-03-10.csv&quot;) nhanes1 &lt;- nhanes %&gt;% rename(&quot;Foodgroup&quot; = &quot;food&quot;, &quot;Mean_Intake&quot; = &quot;mean&quot;, &quot;SE_Intake&quot; = &quot;SE&quot;, &quot;Food_label&quot; = &quot;food_label&quot;, &quot;Food_desc&quot; = &quot;food_desc&quot;) %&gt;% mutate(Food_label = ifelse(Foodgroup == &quot;kcal&quot;, &quot;Kilocalorires&quot;, Food_label), Food_desc = ifelse(Foodgroup == &quot;kcal&quot;, &quot;Energy (kcal)&quot;, Food_desc)) %&gt;% select(-c(starts_with(c(&quot;gro_&quot;, &quot;oth_&quot;)))) Then, convert the sugar sweetened beverage (SSB) mean and standard error from grams to cup (8 fl oz). nhanes2 &lt;- nhanes1 %&gt;% # Divide by 240 to go from grams to cup mutate(Mean_Intake = ifelse(Foodgroup == &quot;ssb&quot;, Mean_Intake/240, Mean_Intake), SE_Intake = ifelse(Foodgroup == &quot;ssb&quot;, SE_Intake/240, SE_Intake), Food_desc = ifelse(Foodgroup == &quot;ssb&quot;, &quot;Sugar sweetened beverages (1 cup [8 fl oz])&quot;, Food_desc)) nhanes3 &lt;- nhanes2 %&gt;% arrange(Foodgroup, subgroup) Lastly, rename the standard deviation variable and then export. # rename stddev nhanes4 &lt;- nhanes3 %&gt;% rename(sigma_u_wgt = StdDev) %&gt;% mutate(sigma_u_wgt = ifelse(Foodgroup == &quot;ssb&quot;, sigma_u_wgt/240, sigma_u_wgt)) %&gt;% relocate(sigma_u_wgt, .after = &quot;SE_Intake&quot;) # export write_csv(nhanes4, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/nhanes1518_agesexrace&quot;, my_date)) Counterfactual intake No changes are needed so just import the file then export to FINAL folder. cf &lt;- read_csv(&quot;data_inputs/DIET/counterfactual_intake/DATA/counterfactual_intake_050724.csv&quot;) write_csv(cf, paste0(&quot;data_inputs/FINAL/cleaned_raw_data/counterfactual_intake&quot;, my_date)) 3.2 Clean Health Datasets This script cleans all of the health-related data inputs needed for the model. Note that you must first open the ‘methods_manual’ R project before running this script or else it will not work. First, let’s set up our environment. rm(list = ls()) options(scipen=999) library(tidyverse) library(readxl) library(stringr) # check working directory getwd() Create a date string that will be appended to all data file names. my_date &lt;- paste0(&quot;_&quot;, Sys.Date(), &quot;_FINAL.csv&quot;) There are 13 health-related datasets that we will clean. 3.2.1 (1) Cancer incidence and (2) CVD mortality In the code below, these two datasets get restructured and merged together into one “disease” dataset. # import cvd mortality dataset cvd &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/cvd_mortality&quot;, my_date)) cancer &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/cancer_incidence&quot;, my_date)) # transform to long format (without se for now) cvd_long_mean &lt;- cvd %&gt;% select(-starts_with(&quot;se_&quot;)) %&gt;% pivot_longer(cols = !(c(subgroup, Age, Age_label, Sex, Sex_label, Race, Race_label)), names_to = &quot;diseases&quot;, values_to = &quot;count&quot;) # just do se now cvd_long_se &lt;- cvd %&gt;% select(subgroup, Age, Age_label, Sex, Sex_label, Race, Race_label, starts_with(&quot;se_&quot;)) %&gt;% pivot_longer(cols = !(c(subgroup, Age, Age_label, Sex, Sex_label, Race, Race_label)), names_to = &quot;diseases&quot;, values_to = &quot;count_se&quot;) %&gt;% mutate(diseases = gsub(&quot;se_&quot;, &quot;&quot;, diseases)) # combine cvd_long &lt;- left_join(cvd_long_mean, cvd_long_se, by = c(&quot;subgroup&quot;, &quot;Age&quot;, &quot;Age_label&quot;, &quot;Sex&quot;, &quot;Sex_label&quot;, &quot;Race&quot;, &quot;Race_label&quot;, &quot;diseases&quot;)) # any missing? cvd_long %&gt;% filter(is.na(count) | is.na(count_se)) #none-good # remove some vars from cancer dataset cancer1 &lt;- cancer %&gt;% select(-c(diseases_label, # Sex_label, Age_label, Race_label, crude_rate, population, crude_se)) # bind cvd and cancer datasets together cvd_cancer_merged &lt;- rbind(cvd_long, cancer1) %&gt;% rename(crude_se = count_se) cvd_cancer_merged1 &lt;- cvd_cancer_merged %&gt;% arrange(diseases, subgroup) # read in population distribution pop &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/population_distribution&quot;, my_date)) cvd_cancer_merged2 &lt;- left_join(cvd_cancer_merged1, pop, by = &quot;subgroup&quot;) %&gt;% rename(population = `2018_pop`) # export merged dataset write_csv(cvd_cancer_merged2, paste0(&quot;data_inputs/FINAL/model_data/cvd_cancer_merged&quot;, my_date)) Then, we continue cleaning this merged disease dataset that is later appended to the NHANES dataset. # FYI - this function is stored in the LASTING Github repo # This function was written by Fred source(&quot;/Users/bmb73/Documents/GitHub/LASTING/Code/swap.r&quot;) raw_file &lt;- cvd_cancer_merged2 # remove all cancers and total stroke outcome categories raw_file1 &lt;- raw_file %&gt;% # remove all cancers and total stroke outcome categories filter(diseases != &quot;ALL&quot; &amp; diseases != &quot;TSTK&quot;) %&gt;% # remove BMImed and SBPmed for now filter(!(str_detect(diseases, &quot;_medBMI|_medSBP&quot;))) %&gt;% # Fix Sex var mutate(Sex = factor(Sex), SexTemp = as.character(Sex), SexTemp = as.factor(SexTemp), # set SE se = crude_se) %&gt;% # rename disease rename(&quot;disease&quot; = &quot;diseases&quot;) # select subset of variables mort &lt;- raw_file1 %&gt;% select(disease, subgroup, count, se) %&gt;% rename(mn = count) # transform long to wide mort_wide &lt;- pivot_wider(mort, id_cols = subgroup, names_from = disease, values_from = c(mn, se), names_glue = &quot;{disease}{.value}&quot;) # replace na with 0 mort_wide1 &lt;- mort_wide %&gt;% replace(is.na(.), 0) # merge with subgroup info subgrps &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/population_subgroups_48_060923_FINAL.csv&quot;) # join mort_wide2 &lt;- mort_wide1 %&gt;% left_join(subgrps, by = &quot;subgroup&quot;) mort_wide3 &lt;- mort_wide2 %&gt;% mutate(agecat = as.numeric(as.factor(Age_label)), female = ifelse(Sex_label == &quot;Female&quot;, 1, 0), race = as.numeric(Race), racecat = race) # rearrange variable order mort_wide4 &lt;- mort_wide3 %&gt;% relocate(subgroup, agecat, female, race, racecat, Age, Age_label, Sex, Sex_label, Race, Race_label, ends_with(&quot;mn&quot;), ends_with(&quot;se&quot;)) # brooke fix this later medBMI &lt;- mort_wide4[, c(names(mort_wide4)[grep(pattern=&quot;mn&quot;, x=names(mort_wide4))], names(mort_wide4)[grep(pattern=&quot;se&quot;, x=names(mort_wide4))])] names(medBMI)[grep(pattern=&quot;mn&quot;, names(medBMI))] &lt;- gsub(pattern=&quot;mn&quot;, replacement=&quot;_medBMImn&quot;, x=names(medBMI[grep(pattern=&quot;mn&quot;, names(medBMI))])) names(medBMI)[grep(pattern=&quot;se&quot;, names(medBMI))] &lt;- gsub(pattern=&quot;se&quot;, replacement=&quot;_medBMIse&quot;, x=names(medBMI[grep(pattern=&quot;se&quot;, names(medBMI))])) medSBP &lt;- mort_wide4[, c(names(mort_wide4)[grep(pattern=&quot;mn&quot;, x=names(mort_wide4))], names(mort_wide4)[grep(pattern=&quot;se&quot;, x=names(mort_wide4))])] names(medSBP)[grep(pattern=&quot;mn&quot;, names(medSBP))] &lt;- gsub(pattern=&quot;mn&quot;, replacement=&quot;_medSBPmn&quot;, x=names(medSBP[grep(pattern=&quot;mn&quot;, names(medSBP))])) names(medSBP)[grep(pattern=&quot;se&quot;, names(medSBP))] &lt;- gsub(pattern=&quot;se&quot;, replacement=&quot;_medSBPse&quot;, x=names(medSBP[grep(pattern=&quot;se&quot;, names(medSBP))])) mort_wide5 &lt;- cbind(mort_wide4, medBMI, medSBP) # fix order again mort_wide6 &lt;- mort_wide5 %&gt;% relocate(subgroup, agecat, female, race, racecat, Age, Age_label, Sex, Sex_label, Race, Race_label, ends_with(&quot;mn&quot;), ends_with(&quot;se&quot;)) %&gt;% arrange(subgroup) # export to FINAL folder write_csv(mort_wide6, paste0(&quot;data_inputs/FINAL/cleaned_data/disease_incidence&quot;, my_date)) 3.2.2 (3) Effect sizes for diet and BMI and (4) diet and SBP Clean up the global environment. rm(list=setdiff(ls(), &quot;my_date&quot;)) First, import the effect sizes for diet and BMI. ef &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/food_to_bmi_effects&quot; , my_date)) We need to convert the effect sizes for four dietary factors: pf_pm, pf_redm, added_sugar, and leg_tot. The current unit for pf_redm (red meat) is 3.5 oz eq/day, and needs to be transformed to 1 oz eq/day. So, we will divide the effects and standard errors by 3.5. The current unit for pf_pm (processed meat) is 2 oz eq/day, and needs to be transformed to 1 oz eq/day. So, we will divide the effects and standard errors by 2. The current unit for added_sugar is 1 gram/day, and needs to be transformed to 1 tsp/day. So, we will multiple the effects and standard errors by 4.2 (1 tsp=4.2 g). The current unit for leg_tot is 1 cup/day, and needs to be transformed to 1 oz/day. So, we will multiple the effects and standard errors by (175/44). ef_new &lt;- ef %&gt;% mutate( # effects for normal weight effect_normal_mean_converted = ifelse(food_group == &quot;pf_redm&quot; | food_group == &quot;pf_redm_tot&quot;, effect_normal_mean / 3.5, ifelse(food_group == &quot;pf_pm&quot;, effect_normal_mean / 2, ifelse(food_group == &quot;added_sugar&quot;, effect_normal_mean * 4.2, ifelse(food_group == &quot;leg_tot&quot;, effect_normal_mean * (175/44), effect_normal_mean)))), effect_normal_mean_se_converted = ifelse(food_group == &quot;pf_redm&quot; | food_group == &quot;pf_redm_tot&quot;, effect_normal_mean_se / 3.5, ifelse(food_group == &quot;pf_pm&quot;, effect_normal_mean_se / 2, ifelse(food_group == &quot;added_sugar&quot;, effect_normal_mean_se * 4.2, ifelse(food_group == &quot;leg_tot&quot;, effect_normal_mean_se * (175/44), effect_normal_mean_se)))), # effects for overweight effect_overweight_mean_converted = ifelse(food_group == &quot;pf_redm&quot; | food_group == &quot;pf_redm_tot&quot;, effect_overweight_mean / 3.5, ifelse(food_group == &quot;pf_pm&quot;, effect_overweight_mean / 2, ifelse(food_group == &quot;added_sugar&quot;, effect_overweight_mean * 4.2, ifelse(food_group == &quot;leg_tot&quot;, effect_overweight_mean * (175/44), effect_overweight_mean)))), effect_overweight_mean_se_converted = ifelse(food_group == &quot;pf_redm&quot; | food_group == &quot;pf_redm_tot&quot;, effect_overweight_mean_se / 3.5, ifelse(food_group == &quot;pf_pm&quot;, effect_overweight_mean_se / 2, ifelse(food_group == &quot;added_sugar&quot;, effect_overweight_mean_se * 4.2, ifelse(food_group == &quot;leg_tot&quot;, effect_overweight_mean_se * (175/44), effect_overweight_mean_se)))) ) %&gt;% rename(&quot;effect_unit_converted&quot; = nhanes_unit) # look at original and converted values ef_new_sub &lt;- ef_new %&gt;% select(food_group, effect_normal_mean, effect_normal_mean_converted, effect_normal_mean_se, effect_normal_mean_se_converted, effect_unit, effect_overweight_mean, effect_overweight_mean_converted, effect_overweight_mean_se, effect_overweight_mean_se_converted, effect_unit_converted) Now, create the file that is used in the CRA model. Select relevant variables and rename variables. ef_model_dat &lt;- ef_new %&gt;% select(food_group, effect_normal_mean_converted, effect_normal_mean_se_converted, effect_overweight_mean_converted, effect_overweight_mean_se_converted, effect_unit_converted) %&gt;% rename(&quot;effect_normal_mean&quot; = effect_normal_mean_converted, &quot;effect_normal_mean_se&quot; = effect_normal_mean_se_converted, &quot;effect_overweight_mean&quot; = effect_overweight_mean_converted, &quot;effect_overweight_mean_se&quot; = effect_overweight_mean_se_converted, &quot;effect_unit&quot; = effect_unit_converted) # export to model folder write_csv(ef_model_dat, paste0(&quot;data_inputs/FINAL/model_data/food_to_bmi_effects_converted&quot;, my_date)) Next, import the effect sizes for diet and SBP. sbp_ef &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/food_to_sbp_effects&quot;, my_date)) There is only one effect size that needs to be fixed: sodium. The unit of the sodium-sbp effect size is currently mmHg/(1000mg/day). Therefore, the effect size needs to be divided by 1000 to get the unit mmHg/(1mg/day). #divide columns 2-9 by 1000 idx &lt;- c(2:ncol(sbp_ef)) sbp_ef[,idx] &lt;- sbp_ef[,idx] / 1000 # Update the effect size unit label sbp_ef_model_dat &lt;- sbp_ef %&gt;% mutate(effect_unit = ifelse(food_group == &quot;sodium&quot;, &quot;1 mg/day&quot;, NA)) # export to TEMP folder write_csv(sbp_ef_model_dat, paste0(&quot;data_inputs/FINAL/model_data/food_to_sbp_effects_converted&quot;, my_date)) 3.2.3 (5) RRs for BMI and cancer and (6) for BMI and CVD No unit conversions need to be made, so we just need to join the files and export. rm(list=setdiff(ls(), &quot;my_date&quot;)) # import data bmi_cancer &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_bmi_cancer&quot;, my_date)) bmi_cvd &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_bmi_cvd&quot;, my_date)) # join 2 bmi datasets bmi_join &lt;- left_join(bmi_cvd, bmi_cancer, by = c(&quot;risk_factor&quot;, &quot;subgroup&quot;)) # export to cleaned data folder write_csv(bmi_join, paste0(&quot;data_inputs/FINAL/cleaned_data/rr_bmi_disease&quot;, my_date)) 3.2.4 (7) LogRRs for diet and cancer and (8) for diet and CVD 3.2.4.1 Part (i): Create LogRR dataset The goal is to create a mega file that contains all diet and disease combinations (for all 48 subgroups). rm(list=setdiff(ls(), &quot;my_date&quot;)) # Retrieve list of disease outcomes disease_dat &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/disease_outcomes_060923_FINAL.csv&quot;) disease_outcomes &lt;- c(disease_dat$outcome) disease_labels &lt;- c(disease_dat$outcome_label) # Retrieve list of dietary factors diet_dat &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/dietary_factors_010424_FINAL.csv&quot;) diet_factors &lt;- c(diet_dat$Food_group) # Retrieve population subgroups pop_dat &lt;- read_csv(&quot;data_inputs/OTHER/labels/DATA/population_subgroups_48_060923_FINAL.csv&quot;) pop_dat1 &lt;- pop_dat %&gt;% select(subgroup, Age, Sex, Race) # Number of population subgroups subgroup_num &lt;- 1:48 my_list &lt;- list() for (i in diet_factors) { dat &lt;- tibble( #subgroup=1, outcome=disease_outcomes, #outcome_label=disease_labels, risk_factor=i) my_list[[i]] &lt;- dat } dat_bind &lt;- bind_rows(my_list) #second loop my_list1 &lt;- list() for (j in subgroup_num) { dat_bind_more &lt;- dat_bind %&gt;% mutate(subgroup = j) my_list1[[j]] &lt;- dat_bind_more } final_dat &lt;- bind_rows(my_list1) # Left join with pop dataset final_dat1 &lt;- final_dat %&gt;% left_join(pop_dat1, by = &quot;subgroup&quot;) # JOIN WITH CVD AND CANCER DATASETS # Retrieve cvd dataset cvd_real &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/logRR_diet_cvd&quot;, my_date)) %&gt;% select(-c(outcome_label, Age_label)) # join with final_dat1 join1 &lt;- left_join(final_dat1, cvd_real, by = c(&quot;outcome&quot;, &quot;risk_factor&quot;, &quot;Age&quot;)) # test join1 %&gt;% filter(outcome == &quot;OSTK&quot; &amp; risk_factor == &quot;fruit_tot&quot;) %&gt;% head() # looks good # Retrieve cancer dataset cancer_real &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/logRR_diet_cancer&quot;, my_date)) %&gt;% select(-c(outcome_label, RR, CI_lower, CI_upper, evidence)) %&gt;% mutate(logRR_se = (logCI_upper - logCI_lower) / 3.92) # join with join1 join2 &lt;- left_join(final_dat1, cancer_real, by = c(&quot;outcome&quot;, &quot;risk_factor&quot;)) # test join2 %&gt;% filter(outcome == &quot;CC&quot; &amp; risk_factor == &quot;dairy_tot&quot;) %&gt;% head() #good join2 %&gt;% filter(outcome == &quot;CC&quot; &amp; risk_factor == &quot;dairy_cow&quot;) %&gt;% head() #good join2 %&gt;% filter(outcome == &quot;CC&quot; &amp; risk_factor == &quot;dairy_soy&quot;) %&gt;% head() #good join2 %&gt;% filter(outcome == &quot;MLPC&quot; &amp; risk_factor == &quot;fruit_tot&quot;) %&gt;% head() #good # need to merge join1 and join2 # get rid of rows where rr=na join1_sub &lt;- join1 %&gt;% filter(!(is.na(logRR))) join2_sub &lt;- join2 %&gt;% filter(!(is.na(logRR))) # combine these datasets # need to reconcile variable names join2_sub &lt;- join2_sub %&gt;% select(-c(logCI_lower, logCI_upper)) my_join &lt;- rbind(join1_sub, join2_sub) # lastly, join with final_dat1 template big_join &lt;- left_join(final_dat1, my_join, by=NULL) # retrieve conversion units for diet factors convert &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/unit_conversions&quot;, my_date)) # fill in NA values with logRR = 0 big_join1 &lt;- big_join %&gt;% mutate(logRR = ifelse(is.na(logRR), 0, logRR)) # merge with convert big_join2 &lt;- left_join(big_join1, convert, by = c(&quot;risk_factor&quot; = &quot;Food_group&quot;)) # calculate RR unit if RR is missing big_join3 &lt;- big_join2 %&gt;% mutate(RR_unit = ifelse(is.na(RR_unit), paste0(DGA_unit, &quot;/day&quot;), RR_unit)) # reorder columns big_join4 &lt;- big_join3 %&gt;% relocate(subgroup, Age, Sex, Race) %&gt;% arrange(subgroup, outcome) # export write_csv(big_join4, paste0(&quot;data_inputs/FINAL/cleaned_data/logRR_diet_disease&quot;, my_date)) # look at just the non-missing RRs join_subset &lt;- big_join4 %&gt;% filter(logRR != 0) # export write_csv(join_subset, paste0(&quot;data_inputs/FINAL/cleaned_data/logRR_diet_disease_SUBSET&quot;, my_date)) 3.2.4.2 Part (ii): Convert LogRR Units Now we need to convert the units of the LogRR dataset we just created. rm(list=setdiff(ls(), &quot;my_date&quot;)) # Read in diet-disease file rr &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_data/logRR_diet_disease&quot;, my_date), col_types = &quot;ddddccddccdc&quot;) %&gt;% select(-c(Age, Sex, Race)) # create variable that contains the numeric value of the original unit rr &lt;- rr %&gt;% mutate(RR_unit_num = parse_number(RR_unit), unit_type = sub(&quot;.*/&quot;, &quot;&quot;, RR_unit)) # fix &quot;day&quot; rr &lt;- rr %&gt;% mutate(unit_type = ifelse(unit_type == &quot;d&quot;, &quot;day&quot;, unit_type)) table(rr$unit_type, useNA = &quot;always&quot;) # Function 1: Day function # Use this function when we need to convert the RR unit from /week to /day day_func &lt;- function(x, y, u){ # x=dataset # y=dietary factor name # u=newly converted unit x %&gt;% split(list(x$risk_factor, x$unit_type)) %&gt;% modify_at(paste0(y, &quot;.wk&quot;), ~mutate(., logRR = logRR * 7, logRR_se = logRR_se * 7, RR_unit = paste0(RR_unit_num, &quot; &quot;, u), unit_type = &quot;day&quot;)) %&gt;% bind_rows() } # test day_func(x=rr, y=&quot;pf_redm&quot;, u=&quot;g/day&quot;) %&gt;% filter(risk_factor==&quot;pf_redm&quot; &amp; logRR != 0) %&gt;% head() # apply to the RRs that are in week unit rr %&gt;% filter(unit_type == &quot;wk&quot;) %&gt;% select(risk_factor) %&gt;% distinct() # pf_ns, pf_redm, pf_pm, pf_seafood rr1 &lt;- rr %&gt;% day_func(y=&quot;pf_ns&quot;, u=&quot;oz eq/day&quot;) %&gt;% day_func(y=&quot;pf_redm&quot;, u=&quot;g/day&quot;) %&gt;% day_func(y=&quot;pf_redm_tot&quot;, u=&quot;g/day&quot;) %&gt;% day_func(y=&quot;pf_pm&quot;, u=&quot;g/day&quot;) %&gt;% day_func(y=&quot;pf_seafood&quot;, u=&quot;g/day&quot;) # check rr1 %&gt;% filter(risk_factor==&quot;pf_seafood&quot; &amp; logRR != 0) %&gt;% head() #good rr1 %&gt;% filter(risk_factor==&quot;pf_redm_tot&quot; &amp; logRR != 0) %&gt;% head() #good # Function 2: Convert function # Use this function when we need to convert the RR unit to a different type of unit (e.g., grams to cup, grams to oz) convert_func &lt;- function(x, y){ # x=dataset # y=dietary factor name # z=conversion factor # u=newly converted unit x %&gt;% split(~risk_factor == paste0(y)) %&gt;% modify_at(&quot;TRUE&quot;, ~mutate(., RR_converted = (logRR / RR_unit_num) * Conversion_to_grams, SE_converted = (logRR_se / RR_unit_num) * Conversion_to_grams, RR_unit_converted = paste0(DGA_unit, &quot;/&quot;, unit_type) )) %&gt;% bind_rows() } # test rr1 %&gt;% convert_func(y=&quot;pf_poultry&quot;) %&gt;% filter(risk_factor==&quot;pf_poultry&quot;) %&gt;% head() rr1 %&gt;% convert_func(y=&quot;dairy&quot;) %&gt;% filter(risk_factor==&quot;dairy&quot;) %&gt;% head() rr1 %&gt;% convert_func(y=&quot;fruit_juice&quot;) %&gt;% filter(risk_factor==&quot;fruit_juice&quot;) %&gt;% head() # APPLY FUNCTION TO DIET FACTORS rr2 &lt;- rr1 %&gt;% # RRs exist # grams to cups or oz convert_func(y=&quot;dairy_tot&quot;) %&gt;% convert_func(y=&quot;dairy_cow&quot;) %&gt;% convert_func(y=&quot;dairy_soy&quot;) %&gt;% convert_func(y=&quot;fruit_tot&quot;) %&gt;% convert_func(y=&quot;fruit_exc_juice&quot;) %&gt;% convert_func(y=&quot;veg_exc_sta&quot;) %&gt;% convert_func(y=&quot;gr_whole&quot;) %&gt;% convert_func(y=&quot;leg_tot&quot;) %&gt;% convert_func(y=&quot;pf_pm&quot;) %&gt;% convert_func(y=&quot;pf_redm&quot;) %&gt;% convert_func(y=&quot;pf_redm_tot&quot;) %&gt;% convert_func(y=&quot;pf_seafood&quot;) %&gt;% # RRs don&#39;t exist convert_func(y=&quot;pf_poultry&quot;) %&gt;% convert_func(y=&quot;pf_poultry_tot&quot;) %&gt;% convert_func(y=&quot;pf_egg&quot;) %&gt;% convert_func(y=&quot;pf_leg&quot;) %&gt;% convert_func(y=&quot;pf_soy&quot;) %&gt;% convert_func(y=&quot;fruit_juice&quot;) %&gt;% convert_func(y=&quot;veg_dg&quot;) %&gt;% convert_func(y=&quot;veg_leg&quot;) %&gt;% convert_func(y=&quot;veg_oth&quot;) %&gt;% convert_func(y=&quot;veg_ro&quot;) %&gt;% convert_func(y=&quot;veg_sta&quot;) %&gt;% convert_func(y=&quot;added_sugar&quot;) %&gt;% convert_func(y=&quot;gr_refined&quot;) %&gt;% convert_func(y=&quot;oil&quot;) %&gt;% convert_func(y=&quot;sodium&quot;) %&gt;% # conversion factors don&#39;t exist # and we&#39;re not using these dietary factors for the CRA anyway convert_func(y=&quot;pf_animal&quot;) %&gt;% convert_func(y=&quot;pf_plant&quot;) %&gt;% convert_func(y=&quot;babyfood&quot;) %&gt;% convert_func(y=&quot;coffee_tea&quot;) %&gt;% convert_func(y=&quot;other&quot;) %&gt;% convert_func(y=&quot;water&quot;) # check rr2 %&gt;% filter(risk_factor==&quot;leg_tot&quot; &amp; RR_converted !=0) %&gt;% head() rr2 %&gt;% filter(risk_factor==&quot;sodium&quot;) %&gt;% head() rr2 %&gt;% filter(risk_factor==&quot;water&quot;) %&gt;% head() # Function 3: Divide function # Use this function when we need to scale down the RR unit (e.g., 100 mg to 1 mg) divide_func &lt;- function(x, y){ # x=dataset # y=dietary factor name # u=newly converted unit x %&gt;% split(~risk_factor == paste0(y)) %&gt;% modify_at(&quot;TRUE&quot;, ~mutate(., RR_converted = logRR / RR_unit_num, SE_converted = logRR_se / RR_unit_num, RR_unit_converted = paste0(DGA_unit, &quot;/&quot;, unit_type) )) %&gt;% bind_rows() } # APPLY rr3 &lt;- rr2 %&gt;% # scale down units divide_func(y=&quot;sea_omega3_fa&quot;) %&gt;% # want to get unit 1 mg/day divide_func(y=&quot;fiber&quot;) %&gt;% # want to get unit 1 g/day divide_func(y=&quot;pufa_rep_carb&quot;) %&gt;% # want to get unit 1%E/day divide_func(y=&quot;pufa_rep_sfa&quot;) %&gt;% # want to get unit 1%E/day divide_func(y=&quot;pufa_rep_carbsfa&quot;) %&gt;% # want to get unit 1%E/day divide_func(y=&quot;sat_fat&quot;) # want to get unit 1%E/day # check rr3 %&gt;% filter(risk_factor==&quot;sea_omega3_fa&quot; &amp; RR_converted !=0) %&gt;% head() rr3 %&gt;% filter(risk_factor==&quot;fiber&quot; &amp; RR_converted !=0) %&gt;% head() # Function 4: No changes needed # Use this function when the unit is already correct nochange_func &lt;- function(x, y){ # x=dataset # y=dietary factor name # u=newly converted unit x %&gt;% split(~risk_factor == paste0(y)) %&gt;% modify_at(&quot;TRUE&quot;, ~mutate(., RR_converted = logRR, SE_converted = logRR_se , RR_unit_converted = paste0(DGA_unit, &quot;/&quot;, unit_type))) %&gt;% bind_rows() } # APPLY rr4 &lt;- rr3 %&gt;% # no changes needed nochange_func(y=&quot;ssb&quot;) %&gt;% nochange_func(y=&quot;pf_ns&quot;) # check rr4 %&gt;% filter(risk_factor==&quot;ssb&quot; &amp; RR_converted !=0) %&gt;% head() rr4 %&gt;% filter(risk_factor==&quot;pf_ns&quot; &amp; RR_converted !=0) %&gt;% head() # determine if any RRs have not been converted yet rr4 %&gt;% filter(is.na(RR_converted)) %&gt;% select(risk_factor) %&gt;% unique() #none-good # rearrange the data by subgroup and outcome rr5 &lt;- rr4 %&gt;% arrange(subgroup, outcome) # now create full dataset for the model # need to rename variable names rr6 &lt;- rr5 %&gt;% select(-c(RR_unit, logRR, logRR_se, Conversion_to_grams, RR_unit_num, unit_type, DGA_unit, Equation)) %&gt;% rename(&quot;RR&quot; = RR_converted, &quot;SE&quot; = SE_converted, &quot;RR_unit&quot; = RR_unit_converted) # if rr is 0, then set se=0 rr7 &lt;- rr6 %&gt;% mutate(SE = ifelse(RR == 0, 0, SE)) # export to TEMP folder write_csv(rr7, paste0(&quot;data_inputs/FINAL/cleaned_data/logRR_diet_disease_converted&quot;, my_date)) 3.2.5 (9) RRs for SBP and CVD rm(list=setdiff(ls(), &quot;my_date&quot;)) No conversions need to be made to the RRs for SBP and CVD, but we do need to merge and reformat all of the RRs into one file. raw.RRs &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_data/logRR_diet_disease_converted&quot;, my_date)) # need to rename 2 vars raw.RRs &lt;- raw.RRs %&gt;% rename(&quot;logRR&quot; = RR, &quot;logRRse&quot; = SE) # remove TSTK rows raw.RRs &lt;- raw.RRs %&gt;% filter(outcome != &quot;TSTK&quot;) n.diseases &lt;- length(unique(raw.RRs$outcome)) vars.to.keep &lt;- c(&quot;subgroup&quot;,&quot;risk_factor&quot;, &quot;outcome&quot;, &quot;logRR&quot;, &quot;logRRse&quot;) raw.RRs &lt;- raw.RRs[,vars.to.keep] # this is better way to do it food.names &lt;- unique(raw.RRs$risk_factor) # at this point, all of the units are 1 RR_unit &lt;- rep(1, length(food.names)) disease.names &lt;- as.character(unique(raw.RRs$outcome)) disease.names.se &lt;- paste(disease.names, &quot;se&quot;, sep=&quot;&quot;) col.names.main &lt;- as.vector(rbind(disease.names, disease.names.se)) RRs.wide &lt;- pivot_wider(raw.RRs, names_from = &quot;outcome&quot;, values_from = c(&quot;logRR&quot;, &quot;logRRse&quot;), names_sep = &quot;.&quot;) RRs.wide[is.na(RRs.wide)] &lt;- 0 # renaming to columns to make consistent with old names from CVD papers names(RRs.wide)[grep(pattern=&quot;logRRse.&quot;, x=names(RRs.wide))] &lt;- paste(gsub(pattern=&quot;logRRse.&quot;, replacement=&quot;&quot;, x=names(RRs.wide)[grep(pattern=&quot;logRRse.&quot;, x=names(RRs.wide))]), replacement=&quot;se&quot;, sep=&quot;&quot;) names(RRs.wide) &lt;- gsub(pattern=&quot;logRR.&quot;, replacement=&quot;&quot;, x=names(RRs.wide)) names(RRs.wide)[names(RRs.wide)==&quot;risk_factor&quot;] &lt;- &quot;RF&quot; RRs.wide$RRunit &lt;- 0 for(i in 1:length(food.names)) { RRs.wide$RRunit[RRs.wide$RF==food.names[i]] &lt;- RR_unit[i] } RRs.wide&lt;-RRs.wide[order(RRs.wide$RF, RRs.wide$subgroup),] # Now let&#39;s move on to mediated effects, that is effects of BMI on sex, and effects of BMI on disease.names.BMImed &lt;- paste(disease.names, &quot;_medBMI&quot;, sep=&quot;&quot;) disease.names.BMImed.se &lt;- paste(disease.names.BMImed, &quot;se&quot;, sep=&quot;&quot;) col.names.BMI &lt;- as.vector(rbind(disease.names.BMImed, disease.names.BMImed.se)) BMI_RRs&lt;-read.csv(paste0(&quot;data_inputs/FINAL/cleaned_data/rr_bmi_disease&quot;, my_date)) BMI_RRs &lt;- BMI_RRs %&gt;% select(-c(ALL, ALLse)) new.order &lt;- c(&quot;risk_factor&quot;,&quot;subgroup&quot;, as.vector(rbind(disease.names, disease.names.se))) BMI_RRs &lt;- BMI_RRs[,new.order[new.order %in% names(BMI_RRs)]] current.bmi.colnames &lt;- names(BMI_RRs)[3:(length(names(BMI_RRs)))] for(i in grep(&quot;se&quot;, current.bmi.colnames)) { names(BMI_RRs)[2+i] &lt;- paste(strsplit(current.bmi.colnames[i], split=&quot;se&quot;), &quot;_medBMI&quot;, &quot;se&quot;, sep=&quot;&quot;) names(BMI_RRs)[2+i-1] &lt;- paste(names(BMI_RRs)[2+i-1], &quot;_medBMI&quot;, sep=&quot;&quot;) } BMI_RRs&lt;-BMI_RRs[order(BMI_RRs$risk_factor,BMI_RRs$subgroup),] # effects of SBP on disease disease.names.SBPmed &lt;- paste(disease.names, &quot;_medSBP&quot;, sep=&quot;&quot;) disease.names.SBPmed.se &lt;- paste(disease.names.SBPmed, &quot;se&quot;, sep=&quot;&quot;) col.names.SBP &lt;- as.vector(rbind(disease.names.SBPmed, disease.names.SBPmed.se)) # This dataset didn&#39;t need any changes # so it&#39;s in the raw data folder SBP_RRs &lt;- read.csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/rr_sbp_cvd&quot;, my_date)) new.order &lt;- c(&quot;risk_factor&quot;,&quot;subgroup&quot;, as.vector(rbind(disease.names, disease.names.se))) SBP_RRs &lt;- SBP_RRs[,new.order[new.order %in% names(SBP_RRs)]] current.sbp.colnames &lt;- names(SBP_RRs)[3:(length(names(SBP_RRs)))] for(i in grep(&quot;se&quot;, current.sbp.colnames)) { names(SBP_RRs)[2+i] &lt;- paste(strsplit(current.sbp.colnames[i], split=&quot;se&quot;), &quot;_medSBP&quot;, &quot;se&quot;, sep=&quot;&quot;) names(SBP_RRs)[2+i-1] &lt;- paste(names(SBP_RRs)[2+i-1], &quot;_medSBP&quot;, sep=&quot;&quot;) } SBP_RRs &lt;- SBP_RRs[order(SBP_RRs$risk_factor,SBP_RRs$subgroup),] # remove risk factor var SBP_RRs &lt;- SBP_RRs %&gt;% select(-risk_factor) BMI_RRs &lt;- BMI_RRs %&gt;% select(-risk_factor) allRRs &lt;- Reduce(function(x, y) merge(x, y, by.x=&quot;subgroup&quot;), list(RRs.wide, BMI_RRs, SBP_RRs)) allRRs &lt;- allRRs[order(allRRs$RF, allRRs$subgroup), ] # export write_csv(allRRs, paste0(&quot;data_inputs/FINAL/model_data/rr_agesexrace&quot;, my_date)) 3.2.6 (10) Current intake (NHANES), (11) TMRED, (12) Counterfactual, and (13) Other health data Other health data includes overweight rate, average SBP, % with hypertension, and high SBP rate. The other health dataset does not need to be changed, but it needs to be merged with the NHANES dataset. rm(list=setdiff(ls(), &quot;my_date&quot;)) # import nhanes.dat &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/nhanes1518_agesexrace&quot;, my_date)) # rename var nhanes.dat1 &lt;- nhanes.dat %&gt;% rename(diet = Foodgroup, mean = Mean_Intake, se = SE_Intake, #n = N, #intake_unit = IntakeUnit, diet_label = Food_label) # sea_omega3_fa is in grams and we want it in milligrams # first, look at data nhanes.dat1 %&gt;% filter(diet == &quot;ssb&quot;) %&gt;% head() #this is fine nhanes.dat1 %&gt;% filter(diet == &quot;sea_omega3_fa&quot;) %&gt;% head() # fix sea_omega3_fa # g -&gt; mg # 1 g = 1000 mg nhanes.dat2 &lt;- nhanes.dat1 %&gt;% split(~diet == &quot;sea_omega3_fa&quot;) %&gt;% modify_at(&quot;TRUE&quot;, ~mutate(., mean = mean * 1000, se = se * 1000, sigma_u_wgt = sigma_u_wgt * 1000)) %&gt;% bind_rows() # look at data # nhanes.dat2 %&gt;% filter(diet == &quot;ssb&quot;) %&gt;% head() nhanes.dat2 %&gt;% filter(diet == &quot;sea_omega3_fa&quot;) %&gt;% head() # read in counterfactual data counterfactuals &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/counterfactual_intake&quot;, my_date)) # rename vars counterfactuals &lt;- counterfactuals %&gt;% rename(diet = food_group, CF_intake_unit = intake_units) %&gt;% select(diet, diet_pattern, CF_mean_intake, CF_se_intake, CF_sd_intake, CF_intake_unit) # manually fix some of the units # added sugar (g -&gt; tsp) # pf_leg (cup -&gt; oz) counterfactuals1 &lt;- counterfactuals %&gt;% mutate(# added sugar # Brooke updated this on 5/20/25 - values are already in tsp # CF_mean_intake = round(ifelse(diet == &quot;added_sugar&quot;, CF_mean_intake / 4.2, CF_mean_intake), digits = 2), # CF_sd_intake = round(ifelse(diet == &quot;added_sugar&quot;, CF_sd_intake / 4.2, CF_sd_intake), digits = 3), # CF_intake_unit = ifelse(diet == &quot;added_sugar&quot;, &quot;tsp eq/day&quot;, CF_intake_unit), # pf_leg CF_mean_intake = round(ifelse(diet == &quot;pf_leg&quot;, CF_mean_intake * 4, CF_mean_intake), digits = 2), CF_sd_intake = round(ifelse(diet == &quot;pf_leg&quot;, CF_sd_intake * 4, CF_sd_intake), digits = 3), CF_intake_unit = ifelse(diet == &quot;pf_leg&quot;, &quot;ounce eq/day&quot;, CF_intake_unit)) # read in TMRED data tmred &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/tmred_dga_units&quot;, my_date)) # rename vars tmred &lt;- tmred %&gt;% rename(TMRED_mean_intake = TMRED, TMRED_sd_intake = SD, TMRED_intake_unit = Unit) # read in death data deaths.dat &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_data/disease_incidence&quot;, my_date)) # read in other health data other_healh &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/other_health&quot;, my_date)) # merge nhanes and counterfactual dat1 &lt;- left_join(nhanes.dat2, counterfactuals1, by = &quot;diet&quot;) # check pf_seafood to make sure all 5 dietary patterns were merged dat1 %&gt;% filter(diet == &quot;pf_seafood&quot;) %&gt;% select(subgroup, diet, diet_pattern, CF_mean_intake) %&gt;% head() #looks good # merge dat1 with tmred dat2 &lt;- left_join(dat1, tmred, by = c(&quot;diet&quot; = &quot;Risk_factor&quot;)) # merge dat2 with other health data dat3 &lt;- left_join(dat2, other_healh, by = &quot;subgroup&quot;) # lastly, merge with deaths data merged &lt;- left_join(dat3, deaths.dat, by = &quot;subgroup&quot;) # create merged file merged1 &lt;- merged %&gt;% arrange(diet, subgroup, diet_pattern) %&gt;% relocate(c(agecat, Age_label, female, Sex, race, Race_label), .after = subgroup) # check data merged1 %&gt;% select(subgroup, overweight_rate) %&gt;% head() # export file write_csv(merged1, paste0(&quot;data_inputs/FINAL/model_data/nhanes1518_agesexrace_merged&quot;, my_date)) 3.3 Restructure data This script transforms the NHANES dataset to match the structure of the cost/environment mega dataset. rm(list=setdiff(ls(), &quot;my_date&quot;)) # IMPORT NHANES DATA nhanes &lt;- read_csv(paste0(&quot;data_inputs/FINAL/model_data/nhanes1518_agesexrace_merged&quot;, my_date)) ## Rows: 6480 Columns: 211 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (9): Age_label, Race_label, diet, diet_label, Food_desc, diet_pattern, CF_intake_unit, TMRED_intake... ## dbl (202): subgroup, agecat, female, Sex, race, N, mean, se, sigma_u_wgt, pro_gro, CF_mean_intake, CF_se_... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # update variable names nhanes1 &lt;- nhanes %&gt;% rename(subgroup_id = subgroup, Foodgroup = diet, Mean_Intake = mean, SE_Intake = se, CF_Mean_Intake = CF_mean_intake, CF_SE_Intake = CF_se_intake, TMRED_Mean_Intake = TMRED_mean_intake, TMRED_SD_Intake = TMRED_sd_intake) %&gt;% mutate(datatype=&quot;Total&quot;, pro_nongro = 1 - pro_gro) %&gt;% relocate(datatype, .after = Food_desc) %&gt;% relocate(pro_nongro, .after = pro_gro) # remove extra ssb rows nhanes1 %&gt;% filter(Foodgroup == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 213 ## subgroup_id agecat Age_label female Sex race Race_label Foodgroup N Mean_Intake SE_Intake ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 20-34 1 1 1 NHW ssb 381 1.42 0.129 ## 2 1 1 20-34 1 1 1 NHW ssb 381 1.42 0.129 ## 3 1 1 20-34 1 1 1 NHW ssb 381 1.42 0.129 ## 4 1 1 20-34 1 1 1 NHW ssb 381 1.42 0.129 ## 5 1 1 20-34 1 1 1 NHW ssb 381 1.42 0.129 ## 6 2 1 20-34 1 1 2 NHB ssb 282 1.29 0.0943 ## # ℹ 202 more variables: sigma_u_wgt &lt;dbl&gt;, diet_label &lt;chr&gt;, Food_desc &lt;chr&gt;, datatype &lt;chr&gt;, pro_gro &lt;dbl&gt;, ## # pro_nongro &lt;dbl&gt;, diet_pattern &lt;chr&gt;, CF_Mean_Intake &lt;dbl&gt;, CF_SE_Intake &lt;dbl&gt;, CF_sd_intake &lt;dbl&gt;, ## # CF_intake_unit &lt;chr&gt;, TMRED_Mean_Intake &lt;dbl&gt;, TMRED_SD_Intake &lt;dbl&gt;, TMRED_intake_unit &lt;chr&gt;, ## # overweight_rate &lt;dbl&gt;, overweight_rate_se &lt;dbl&gt;, nhb &lt;dbl&gt;, nhb_se &lt;dbl&gt;, sbp_mean &lt;dbl&gt;, sbp_se &lt;dbl&gt;, ## # highSBP_rate &lt;dbl&gt;, highSBP_rate_se &lt;dbl&gt;, hbp &lt;dbl&gt;, hbp_se &lt;dbl&gt;, racecat &lt;dbl&gt;, Age &lt;dbl&gt;, ## # Sex_label &lt;chr&gt;, Race &lt;dbl&gt;, AAmn &lt;dbl&gt;, AFFmn &lt;dbl&gt;, APCAmn &lt;dbl&gt;, BCmn &lt;dbl&gt;, CCmn &lt;dbl&gt;, CMmn &lt;dbl&gt;, ## # DIABmn &lt;dbl&gt;, ECAmn &lt;dbl&gt;, ENDOmn &lt;dbl&gt;, GCmn &lt;dbl&gt;, HHDmn &lt;dbl&gt;, HSTKmn &lt;dbl&gt;, IHDmn &lt;dbl&gt;, … nhanes2 &lt;- nhanes1 %&gt;% filter(!(is.na(subgroup_id))) # create grocery data grocery &lt;- nhanes2 %&gt;% mutate(datatype = recode(datatype, `Total` = &quot;Grocery&quot;), Mean_Intake = Mean_Intake * pro_gro, SE_Intake = SE_Intake * pro_gro, sigma_u_wgt = sigma_u_wgt * pro_gro, CF_Mean_Intake = CF_Mean_Intake * pro_gro, CF_SE_Intake = CF_SE_Intake * pro_gro, CF_sd_intake = CF_sd_intake * pro_gro) nongrocery &lt;- nhanes2 %&gt;% mutate(datatype = recode(datatype, `Total` = &quot;Non-Grocery&quot;), Mean_Intake = Mean_Intake * pro_nongro, SE_Intake = SE_Intake * pro_nongro, sigma_u_wgt = sigma_u_wgt * pro_nongro, CF_Mean_Intake = CF_Mean_Intake * pro_nongro, CF_SE_Intake = CF_SE_Intake * pro_nongro, CF_sd_intake = CF_sd_intake * pro_nongro) # bind together nhanes_comb &lt;- rbind(nhanes2, grocery, nongrocery) # rearrange nhanes_comb1 &lt;- nhanes_comb %&gt;% arrange(subgroup_id, Foodgroup, datatype, diet_pattern) %&gt;% relocate(c(datatype, diet_pattern), .before = Mean_Intake) # lastly, add 2018 population variable # read in population distribution pop &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_raw_data/population_distribution&quot;, my_date)) ## Rows: 48 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (2): subgroup, 2018_pop ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. nhanes_comb2 &lt;- left_join(nhanes_comb1, pop, by = c(&quot;subgroup_id&quot; = &quot;subgroup&quot;)) %&gt;% rename(population = `2018_pop`) %&gt;% relocate(population, .before = overweight_rate) # export write_csv(nhanes_comb2, paste0(&quot;data_inputs/FINAL/cleaned_data/mega_costenv_structure_temp&quot;, my_date)) "],["cleaning-code-for-environment-data.html", "Chapter 4 Cleaning Code for Environment Data 4.1 Clean and Restructure Intermediary Datasets", " Chapter 4 Cleaning Code for Environment Data This chapter walks you through all of the R code used to clean the raw ENVIRONMENT-related data inputs. The resulting cleaned dataset is then used to calculate the environment impact factors (see Chapter XXX). 4.1 Clean and Restructure Intermediary Datasets This script imports all of raw cost-related data inputs, and then cleans and merges them so that the cost impact factors can later be calculated. Note that you must first open the ‘methods_manual’ R project before running this script or else it will not work. First, let’s set up our environment. # check working directory getwd() ## [1] &quot;/Users/bmb73/Library/CloudStorage/Box-Box/lasting_aim_3/model development/methods_manual&quot; # SET UP ----- rm(list = ls()) options(scipen=999) library(tidyverse) library(readxl) library(survey) my_date &lt;- Sys.Date() 4.1.1 Import and Merge Data Inputs NHANES Diet Intake The following code is the same code used in Section XXX. First, read in the NHANES food-level datasets. The data were split into “day 1” and “day 2” earlier, and here we are going to merge them into “both days”. There also are different datasets containing just sugar sweetened beverage (SSB) data, so we have to import those in separately, and then merge with the rest of the day1/day2 diet datasets. Import all of the “day 1” datasets first. # import day1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_clean.rds&quot;) # only select needed variables day1_sub &lt;- day1 %&gt;% select(SEQN, DRDINT, DR1DRSTZ, DR1ILINE, DR1IFDCD, DR1IGRMS, DESCRIPTION, foodsource, nhanes_cycle, dayrec, added_sugar) %&gt;% rename(seqn = SEQN, line = DR1ILINE, foodcode = DR1IFDCD, grams = DR1IGRMS, description = DESCRIPTION, daysintake = DRDINT, reliable = DR1DRSTZ) # ssb ssb_1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_ssb.rds&quot;) # merge food and ssb day1_sub1 &lt;- left_join(day1_sub, ssb_1, by = c(&quot;seqn&quot; = &quot;SEQN&quot;, &quot;line&quot; = &quot;DR1ILINE&quot;, &quot;foodcode&quot; = &quot;DR1IFDCD&quot;, &quot;description&quot; = &quot;DESCRIPTION&quot;, &quot;grams&quot; = &quot;DR1IGRMS&quot;)) Then import all of “day 2” datasets. # import day2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_clean.rds&quot;) # only select needed variables day2_sub &lt;- day2 %&gt;% select(SEQN, DRDINT, DR2DRSTZ, DR2ILINE, DR2IFDCD, DR2IGRMS, DESCRIPTION, foodsource, nhanes_cycle, dayrec, added_sugar) %&gt;% rename(seqn = SEQN, line = DR2ILINE, foodcode = DR2IFDCD, grams = DR2IGRMS, description = DESCRIPTION, daysintake = DRDINT, reliable = DR2DRSTZ) # ssb ssb_2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_ssb.rds&quot;) # merge food and ssb day2_sub1 &lt;- left_join(day2_sub, ssb_2, by = c(&quot;seqn&quot; = &quot;SEQN&quot;, &quot;line&quot; = &quot;DR2ILINE&quot;, &quot;foodcode&quot; = &quot;DR2IFDCD&quot;, &quot;description&quot; = &quot;DESCRIPTION&quot;, &quot;grams&quot; = &quot;DR2IGRMS&quot;)) Then, combine the “day 1” and “day 2” datasets to get a “both_days” dataset. both_days &lt;- rbind(day1_sub1, day2_sub1) %&gt;% arrange(seqn, dayrec, line) # check to make sure the formatting worked both_days %&gt;% filter(description == &quot;Meat, NFS&quot;) %&gt;% head() #looks good! ## # A tibble: 6 × 12 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 84032 1 1 9 20000000 11.0 Meat, NFS Other 2015-2016 1 0 0 ## 2 86178 2 1 5 20000000 4.19 Meat, NFS Other 2015-2016 1 0 0 ## 3 86487 2 1 10 20000000 73.3 Meat, NFS Grocery 2015-2016 1 0 0 ## 4 86801 2 1 13 20000000 11.2 Meat, NFS Other 2015-2016 1 0 0 ## 5 87065 2 1 3 20000000 50.2 Meat, NFS Other 2015-2016 1 0 0 ## 6 88767 2 1 12 20000000 7.33 Meat, NFS Other 2015-2016 1 0 0 Lastly, remove the original diet datasets becuase they are very large and we don’t need them anymore. rm(list=setdiff(ls(), c(&quot;both_days&quot;, &quot;my_date&quot;))) Mapping from Dietary Factor to FNDDS Food Code This mapping is needed to handle some data processing in later code chunks. First, create an empty dataset template that contains all of the foodcodes that exist in the diet dataset (both_days). all_foodcodes &lt;- both_days %&gt;% select(foodcode) %&gt;% distinct() Then, import the non-grain food mapping (labeled as “map_a”). map_a &lt;- read_csv(&quot;data_inputs/OTHER/dietfactor_to_fndds_mapping/DATA/Food_to_FNDDS_mapping_detailed_04-06-25.csv&quot;) ## Rows: 109 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Foodgroup ## dbl (1): foodcode_prefix ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Then, join the template and the first mapping. my_join &lt;- full_join(mutate(all_foodcodes, i=1), mutate(map_a, i=1)) %&gt;% select(-i) %&gt;% filter(str_detect(foodcode, paste0(&quot;^&quot;, foodcode_prefix))) %&gt;% select(-foodcode_prefix) ## Joining with `by = join_by(i)` ## Warning in full_join(mutate(all_foodcodes, i = 1), mutate(map_a, i = 1)): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. Import the grain-only mapping (labeled as “map_b”). map_b &lt;- read_csv(&quot;data_inputs/OTHER/dietfactor_to_fndds_mapping/DATA/Food_to_FNDDS_mapping_WHOLE_GRAINS_ONLY_09-05-23.csv&quot;) ## Rows: 1728 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Foodgroup ## dbl (1): foodcode ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Merge my_join with the second mapping. my_join1 &lt;- rbind(my_join, map_b) %&gt;% arrange(foodcode) Lastly, merge back with both_days. both_days1 &lt;- left_join(both_days, my_join1, by = &quot;foodcode&quot;) Check how many FNDDS codes in the dataset don’t have a mapping to a dietary factor (i.e., food group category) both_days1 %&gt;% filter(is.na(Foodgroup)) %&gt;% select(foodcode, description) %&gt;% distinct() %&gt;% arrange(foodcode) ## # A tibble: 0 × 2 ## # ℹ 2 variables: foodcode &lt;dbl&gt;, description &lt;chr&gt; Check SSB by comparing the “ssb” indicator variable and the data when the foodgroup is set to “ssb”. both_days1 %&gt;% filter(ssb == 1) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 4 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 5 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 6 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 1 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 4 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## 5 83742 2 1 9 92410310 150. Soft drink… Other 2015-2016 2 3.54 1 ## 6 83744 2 1 8 92410510 512 Soft drink… Other 2015-2016 1 11.0 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() # need to change these to ssb ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 2 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 3 83753 2 1 6 95320200 744 Sports dri… Other 2015-2016 2 9.3 1 ## 4 83768 2 1 12 64204010 580. Mango nect… Grocery 2015-2016 1 9.64 1 ## 5 83780 2 1 9 64205010 116. Peach nect… Grocery 2015-2016 2 2.76 1 ## 6 83795 2 1 10 95320200 310 Sports dri… Other 2015-2016 2 3.88 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() # need to change these to other ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 1 92101000 720 Coffee, br… Grocery 2015-2016 1 0 0 ## 2 83732 2 1 7 92410320 600 Soft drink… Grocery 2015-2016 1 0 0 ## 3 83732 2 1 1 92101000 255 Coffee, br… Grocery 2015-2016 2 0 0 ## 4 83732 2 1 15 92410520 480 Soft drink… Other 2015-2016 2 0 0 ## 5 83733 2 1 1 92101000 480 Coffee, br… Grocery 2015-2016 1 0 0 ## 6 83733 2 1 1 92101000 450 Coffee, br… Grocery 2015-2016 2 0 0 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 0 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitut… Grocery 2015-2016 1 0 ## 2 83732 2 1 3 12210400 3.92 Coffee creamer,… Grocery 2015-2016 1 0.07 ## 3 83732 2 1 4 94100100 240 Water, bottled,… Grocery 2015-2016 1 0 ## 4 83732 2 1 5 51101010 75 Bread, white, t… Grocery 2015-2016 1 0.74 ## 5 83732 2 1 6 81103080 28.6 Margarine-like … Grocery 2015-2016 1 0 ## 6 83732 2 1 8 27564060 204 Frankfurter or … Grocery 2015-2016 1 1.63 ## # ℹ 2 more variables: ssb &lt;dbl&gt;, Foodgroup &lt;chr&gt; We see that, for some of the rows, ssb is labeled incorrectly, so we need to fix it. both_days2 &lt;- both_days1 %&gt;% mutate(Foodgroup = ifelse(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;, &quot;ssb&quot;, Foodgroup)) %&gt;% mutate(Foodgroup = ifelse(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;, &quot;other&quot;, Foodgroup)) Check again. Looks good. both_days2 %&gt;% filter(ssb == 1 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 4 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 5 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 6 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() # none-good ## # A tibble: 0 × 13 ## # ℹ 13 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() # none-good ## # A tibble: 0 × 13 ## # ℹ 13 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 0 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed Grocery 2015-2016 1 0 ## 2 83732 2 1 2 91200040 4 Sugar substitut… Grocery 2015-2016 1 0 ## 3 83732 2 1 3 12210400 3.92 Coffee creamer,… Grocery 2015-2016 1 0.07 ## 4 83732 2 1 4 94100100 240 Water, bottled,… Grocery 2015-2016 1 0 ## 5 83732 2 1 5 51101010 75 Bread, white, t… Grocery 2015-2016 1 0.74 ## 6 83732 2 1 6 81103080 28.6 Margarine-like … Grocery 2015-2016 1 0 ## # ℹ 2 more variables: ssb &lt;dbl&gt;, Foodgroup &lt;chr&gt; Rename variable. both_days3 &lt;- both_days2 %&gt;% rename(Foodgroup_FNDDS = Foodgroup) Tidy up the global environment and only keep the datasets we currently need. rm(list=setdiff(ls(), c(&quot;both_days3&quot;, &quot;my_date&quot;))) This dataset containing the FNDDS foodcodes that represent seafood dishes will then be used in the following code chunk. Mapping from FNDDS Food Code to FCID Code Import the mapping and join with the both_days dataset. # import map &lt;- read_csv(&quot;data_inputs/OTHER/fndds_to_fcid_mapping/DATA/FCID_0118_LASTING.csv&quot;) ## Rows: 122027 Columns: 12 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): food_desc, fcid_desc, procform_desc, cookstatus_desc, cookmethod_desc ## dbl (7): foodcode, fcidcode, procform, cookstatus, cookmethod, impute, wt ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. map1 &lt;- map %&gt;% select(foodcode, fcidcode, fcid_desc, wt) # combine with food data both_days4 &lt;- full_join(both_days3, map1, by = &quot;foodcode&quot;) ## Warning in full_join(both_days3, map1, by = &quot;foodcode&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 76852 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. # if SEQN (subject ID) is missing, remove from dataset both_days5 &lt;- both_days4 %&gt;% filter(!(is.na(seqn))) %&gt;% arrange(seqn, dayrec, line) %&gt;% relocate(c(foodsource, nhanes_cycle, dayrec), .after = last_col()) # look at ssb both_days5 %&gt;% filter(ssb == 1) %&gt;% head() ## # A tibble: 6 × 16 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced, brewe… 6.81 1 ssb 1.01e8 ## 2 83732 2 1 14 92308000 372 Tea, iced, brewe… 6.81 1 ssb 8.60e9 ## 3 83732 2 1 14 92308000 372 Tea, iced, brewe… 6.81 1 ssb 9.50e9 ## 4 83732 2 1 14 92308000 372 Tea, iced, brewe… 6.81 1 ssb 9.50e9 ## 5 83736 2 1 2 92410510 326. Soft drink, frui… 6.97 1 ssb 1.50e9 ## 6 83736 2 1 7 95320200 356. Sports drink (Ga… 4.46 1 ssb 9.50e9 ## # ℹ 5 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt; both_days5 %&gt;% filter(ssb==1) %&gt;% select(fcid_desc) %&gt;% table() ## fcid_desc ## Almond Apple, juice Apricot, juice ## 90 1759 1767 ## Banana Barley, flour Beet, sugar ## 1767 31 6782 ## Blackberry Blueberry Boysenberry ## 1759 1759 1759 ## Cantaloupe Cassava Cherry ## 17 341 5 ## Cherry, juice Cinnamon Cocoa bean, chocolate ## 1759 1244 9 ## Cocoa bean, powder Coconut, meat Coconut, milk ## 64 17 3 ## Coconut, oil Coffee, instant Coffee, roasted bean ## 1305 361 360 ## Corn, field, flour Corn, field, oil Corn, field, starch ## 41 82 424 ## Corn, field, syrup Cranberry, juice Grape, juice ## 16067 1936 1759 ## Grapefruit, juice Guava Lemon ## 1760 22 70 ## Lemon, juice Lime, juice Mango, juice ## 2971 1759 1897 ## Maple, sugar Milk, fat Milk, nonfat solids ## 70 538 600 ## Milk, water Oat, groats/rolled oats Orange ## 538 18 5 ## Orange, juice Papaya, juice Passionfruit, juice ## 2086 7 1760 ## Peach Peach, juice Pear, juice ## 1759 17 1777 ## Peppermint Pineapple, juice Potato, flour ## 1235 1771 341 ## Raspberry, juice Rice, flour Seaweed ## 1759 341 5 ## Sesame, seed Soursop Soybean, flour ## 81 2 61 ## Soybean, oil Soybean, soy milk Spices, other ## 59 19 1305 ## Strawberry, juice Sugarcane, sugar Tamarind ## 1759 7089 16 ## Tangerine, juice Tea, dried Tea, instant ## 1759 2982 279 ## Water, indirect, all sources Wheat, flour ## 6183 341 Food Loss and Waste Data Import the food loss &amp; waste coefficients and join with the both_days dataset. # import losswaste data # losswaste &lt;- read_csv(&quot;data_inputs/OTHER/food_waste/DATA/losswaste.csv&quot;) # import the proxy data for missing loss/waste data losswaste_complete &lt;- read_csv(&quot;data_inputs/OTHER/food_waste/DATA/missing_data/resolved/Missing waste coefficients (full)_090523.csv&quot;) %&gt;% select(-c(fcid_desc, Foodgroup, Proxy, Notes)) ## Rows: 484 Columns: 8 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): fcid_desc, Foodgroup, Proxy, Notes ## dbl (4): fcidcode, waste_coef, ined_coef, retloss_coef ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # merge with bothdays both_days6 &lt;- left_join(both_days5, losswaste_complete, by = &quot;fcidcode&quot;) Mapping From FCID Food Code to Dietary Factor First, we import the original mapping. # import fcid-diet factor mapping new_map &lt;- read_xlsx(&quot;data_inputs/OTHER/dietfactor_to_fcid_mapping/DATA/FCID_to_dietaryfactor_mapping_01-09-2024_final.xlsx&quot;) %&gt;% select(FCID_Code, Foodgroup) %&gt;% rename(fcidcode = FCID_Code, Foodgroup_FCID = Foodgroup) # merge both_days7 &lt;- left_join(both_days6, new_map, by = &quot;fcidcode&quot;) # which FNDDS foodcodes have missing FCID food group? both_days7 %&gt;% filter(is.na(Foodgroup_FCID)) %&gt;% head() ## # A tibble: 6 × 20 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar NA ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other NA ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar NA ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other NA ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other NA ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other NA ## # ℹ 9 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; both_days7 %&gt;% filter(is.na(Foodgroup_FCID)) %&gt;% select(foodcode, description) %&gt;% distinct() ## # A tibble: 57 × 2 ## foodcode description ## &lt;dbl&gt; &lt;chr&gt; ## 1 91200040 Sugar substitute, saccharin, powder ## 2 92410320 Soft drink, cola, diet ## 3 92410520 Soft drink, fruit flavored, diet, caffeine free ## 4 92410370 Soft drink, pepper type, diet ## 5 92410350 Soft drink, cola, decaffeinated, diet ## 6 91201010 Sugar substitute, aspartame, powder ## 7 91107000 Sugar substitute, sucralose, powder ## 8 92410210 Carbonated water, unsweetened ## 9 93301217 Vodka and water ## 10 93301218 Vodka and tonic ## # ℹ 47 more rows But, we can see that there’s some missing so our team went and manually updated the mapping, which is imported in the following code chunk. # import updated mapping fcids_new &lt;- read_csv(&quot;data_inputs/OTHER/dietfactor_to_fcid_mapping/DATA/missing_data/resolved/Missing FCIDS_mapped.csv&quot;) %&gt;% select(-description) %&gt;% rename(Foodgroup_FCID = Foodgroup) ## Rows: 55 Columns: 3 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): description, Foodgroup ## dbl (1): foodcode ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # row patch new mapping with both days both_days8 &lt;- rows_patch(both_days7, fcids_new, unmatched = &quot;ignore&quot;) ## Matching, by = &quot;foodcode&quot; # which ones have missing fcid? both_days8 %&gt;% filter(is.na(fcidcode)) %&gt;% head() ## # A tibble: 6 × 20 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar NA ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other NA ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar NA ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other NA ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other NA ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other NA ## # ℹ 9 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; both_days8 %&gt;% filter(is.na(fcidcode)) %&gt;% select(foodcode, description, fcidcode) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 3 ## foodcode description fcidcode ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 91200040 Sugar substitute, saccharin, powder NA ## 2 92410320 Soft drink, cola, diet NA ## 3 92410520 Soft drink, fruit flavored, diet, caffeine free NA ## 4 92410370 Soft drink, pepper type, diet NA ## 5 92410350 Soft drink, cola, decaffeinated, diet NA ## 6 91201010 Sugar substitute, aspartame, powder NA There are now fewer missing coefficients, but still some. In some of these cases, the FNDDS foodcode can represent the FCID code (i.e., single ingredient foods). Below, I manually add these waste coefficents for dasheen and corn. # dasheen dash &lt;- losswaste_complete %&gt;% filter(fcidcode == &quot;103139000&quot;) %&gt;% #change the fcidcode mutate(foodcode = 71962020, wt = 100) # corn corn &lt;- losswaste_complete %&gt;% filter(fcidcode == &quot;1500127000&quot;) %&gt;% #change the fcidcode mutate(foodcode = 75215990, wt = 100) # combine comb &lt;- rbind(dash, corn) %&gt;% select(-fcidcode) # row patch with bothdays both_days9 &lt;- rows_patch(both_days8, comb, by = &quot;foodcode&quot;) # check missing fcid both_days9 %&gt;% filter(is.na(fcidcode)) %&gt;% head() ## # A tibble: 6 × 20 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar NA ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other NA ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar NA ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other NA ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other NA ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other NA ## # ℹ 9 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; # check missing waste coef both_days9 %&gt;% filter(is.na(waste_coef)) %&gt;% head() ## # A tibble: 6 × 20 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 9.50e9 ## 2 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 8.60e9 ## 3 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar NA ## 4 83732 2 1 4 94100100 240 Water, bottled, … 0 0 water 8.60e9 ## 5 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other NA ## 6 83732 2 1 11 94100100 240 Water, bottled, … 0 0 water 8.60e9 ## # ℹ 9 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; There’s still a few FCID codes that don’t have waste and inedible coefficients, but it’s not very many, so we will leave for now. Calculate the FCID-level consumed, inedible, and wasted amounts of food. both_days10 &lt;- both_days9 %&gt;% mutate(consumed_amt_FCID = grams * (wt / 100), inedible_amt_FCID = consumed_amt_FCID * ined_coef, wasted_amt_FCID = consumed_amt_FCID * waste_coef) Calculate the FNDDS-level consumed, inedible, and wasted amounts of food. This isn’t needed for the environmental impact factors, but it is needed for the cost impact factors in the next section. both_days11 &lt;- both_days10 %&gt;% group_by(seqn, dayrec, line, foodcode) %&gt;% mutate(consumed_amt_FNDDS = grams, inedible_amt_FNDDS = sum(inedible_amt_FCID, na.rm = TRUE), wasted_amt_FNDDS = sum(wasted_amt_FCID, na.rm = TRUE)) %&gt;% ungroup() # get distinct dataset fndds_flw &lt;- both_days11 %&gt;% select(seqn, dayrec, line, foodcode, description, consumed_amt_FNDDS, inedible_amt_FNDDS, wasted_amt_FNDDS) %&gt;% distinct() %&gt;% arrange(seqn, dayrec, line) # export to use in next section saveRDS(fndds_flw, &quot;data_inputs/IMPACT_FACTORS/temp_data/fndds_flw.rds&quot;) Tidy up the global environment. rm(list=setdiff(ls(), c(&quot;both_days11&quot;, &quot;my_date&quot;))) FCID-Level Environmental Impact Factors (dataField) There are two environmental datasets that need to be imported. The first dataset contains greenhouse gas (GHG) and cumulative energy demand (CED) impact factors. The second contains water scarcity (WATER) and bluewater use (BLUEWATER) impact factors. # import datafield (non-water) datafield &lt;- read_xlsx(&quot;data_inputs/ENVIRONMENT/ghg_ced_impacts/DATA/dataFIELDv1.0_LASTING_120723.xlsx&quot;, sheet = &quot;FCID linkages&quot;, skip = 2) ## New names: ## • `` -&gt; `...11` ## • `` -&gt; `...12` ## • `# of datapoints` -&gt; `# of datapoints...13` ## • `N-average` -&gt; `N-average...14` ## • `Std. Dev` -&gt; `Std. Dev...15` ## • `` -&gt; `...16` ## • `# of datapoints` -&gt; `# of datapoints...17` ## • `N-average` -&gt; `N-average...18` ## • `Std. Dev` -&gt; `Std. Dev...19` ## • `` -&gt; `...20` ## • `` -&gt; `...21` ## • `` -&gt; `...22` ## • `basis` -&gt; `basis...23` ## • `n` -&gt; `n...24` ## • `proxy group mean` -&gt; `proxy group mean...25` ## • `SD (group or indiv food)` -&gt; `SD (group or indiv food)...26` ## • `scaled SD (group SD*food mean/group mean)` -&gt; `scaled SD (group SD*food mean/group mean)...27` ## • `basis` -&gt; `basis...28` ## • `n` -&gt; `n...29` ## • `proxy group mean` -&gt; `proxy group mean...30` ## • `SD (group or indiv food)` -&gt; `SD (group or indiv food)...31` ## • `scaled SD (group SD*food mean/group mean)` -&gt; `scaled SD (group SD*food mean/group mean)...32` datafield_sub &lt;- datafield %&gt;% select(FCID_Code, `MJ / kg`, `CO2 eq / kg`) %&gt;% rename(GHG_mn = `CO2 eq / kg`, CED_mn = `MJ / kg`, fcidcode = FCID_Code) %&gt;% mutate(fcidcode = as.character(fcidcode)) # import datafield (water impacts) datafield_water &lt;- read_xlsx(&quot;data_inputs/ENVIRONMENT/water_impacts/DATA/dataFIELD_water public v1_LASTING_120723.xlsx&quot;, sheet = &quot;FCID Codes&quot;, skip = 2) ## New names: ## • `` -&gt; `...10` datafield_water_sub &lt;- datafield_water %&gt;% select(FCID_Code, `liter eq. / kg`, `L /kg`) %&gt;% rename(WATER_mn = `liter eq. / kg`, BLUEWATER_mn = `L /kg`, fcidcode = FCID_Code) %&gt;% mutate(fcidcode = as.character(fcidcode)) # merge the two datafield datasets together datafield_comb &lt;- left_join(datafield_sub, datafield_water_sub, by = &quot;fcidcode&quot;) # now merge with bothdays both_days12 &lt;- both_days11 %&gt;% mutate(fcidcode = as.character(fcidcode)) %&gt;% left_join(datafield_comb, by = &quot;fcidcode&quot;) Below, we check the dataset for missing impact factors. both_days12 %&gt;% filter(is.na(GHG_mn)) %&gt;% head() ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other &lt;NA&gt; ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other &lt;NA&gt; ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other &lt;NA&gt; ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; both_days12 %&gt;% filter(is.na(GHG_mn) &amp; ssb == 1) %&gt;% head() ## # A tibble: 0 × 30 ## # ℹ 30 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, Foodgroup_FNDDS &lt;chr&gt;, fcidcode &lt;chr&gt;, fcid_desc &lt;chr&gt;, ## # wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, ## # retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, inedible_amt_FCID &lt;dbl&gt;, ## # wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, wasted_amt_FNDDS &lt;dbl&gt;, ## # CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; both_days12 %&gt;% filter(is.na(GHG_mn) &amp; Foodgroup_FNDDS == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 0 × 30 ## # ℹ 30 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, Foodgroup_FNDDS &lt;chr&gt;, fcidcode &lt;chr&gt;, fcid_desc &lt;chr&gt;, ## # wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, ## # retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, inedible_amt_FCID &lt;dbl&gt;, ## # wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, wasted_amt_FNDDS &lt;dbl&gt;, ## # CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; both_days12 %&gt;% filter(is.na(GHG_mn) &amp; Foodgroup_FNDDS == &quot;ssb&quot;) %&gt;% select(description, Foodgroup_FNDDS) %&gt;% distinct() %&gt;% head() # these are all diet drinks and not ssb ## # A tibble: 0 × 2 ## # ℹ 2 variables: description &lt;chr&gt;, Foodgroup_FNDDS &lt;chr&gt; both_days12 %&gt;% filter(is.na(GHG_mn)) %&gt;% select(Foodgroup_FNDDS) %&gt;% table() ## Foodgroup_FNDDS ## added_sugar babyfood dairy_tot fruit_exc_juice fruit_juice gr_refined ## 2125 4322 30348 4 557 4024 ## gr_whole other pf_poultry pf_redm pf_seafood veg_dg ## 1134 3438 145 27 3 5 ## veg_oth veg_sta water ## 102 9 41 both_days12 %&gt;% filter(is.na(GHG_mn)) %&gt;% select(Foodgroup_FCID) %&gt;% table() ## Foodgroup_FCID ## babyfood fruit_exc_juice gr_whole other pf_seafood veg_dg ## 40550 4 7 5046 3 5 ## veg_oth veg_sta water ## 92 9 568 Our team manually assigned proxies for some of these FCID codes with missing environmental impact factors. # import proxies for missing enviro data ghg_proxies &lt;- read_csv(&quot;data_inputs/ENVIRONMENT/ghg_ced_impacts/DATA/missing_data/resolved/Missing environmental impacts_mapped.csv&quot;) ## Rows: 6 Columns: 7 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): description, fcid_desc, proxy_desc, proxy_notes ## dbl (3): foodcode, fcidcode, proxy_fcidcode ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ghg_proxies_sub &lt;- ghg_proxies %&gt;% select(foodcode, description, proxy_fcidcode, proxy_desc) %&gt;% rename(fcidcode = proxy_fcidcode, fcid_desc = proxy_desc) %&gt;% mutate(fcidcode = as.character(fcidcode)) # update rows with proxies both_days13 &lt;- rows_update(both_days12, ghg_proxies_sub, by = c(&quot;foodcode&quot;, &quot;description&quot;)) # check corn both_days13 %&gt;% filter(foodcode == 75215990) %&gt;% head() # good ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 93779 2 1 6 75215990 170 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 2 93806 2 1 12 75215990 108 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 3 93881 2 1 7 75215990 108 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 4 93973 1 1 6 75215990 49.6 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 5 93985 2 1 10 75215990 170 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 6 94011 2 1 12 75215990 36 Corn, cooked, fr… 0 0 veg_oth 1500127… ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; # fcid should be herb both_days13 %&gt;% filter(foodcode == 72133200) %&gt;% head() # good! ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 87109 1 1 2 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## 2 87109 1 1 2 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## 3 87109 1 1 2 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## 4 87109 1 1 2 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## 5 87109 1 1 8 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## 6 87109 1 1 8 72133200 84 Sweet potato lea… 0 0 veg_dg 1901184… ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; # insert enviro data for fcids that were originally missing both_days14 &lt;- both_days13 %&gt;% rows_patch(datafield_comb, by = &quot;fcidcode&quot;, unmatched = &quot;ignore&quot;) %&gt;% ungroup() # check corn both_days14 %&gt;% filter(foodcode == 75215990) %&gt;% head() ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 93779 2 1 6 75215990 170 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 2 93806 2 1 12 75215990 108 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 3 93881 2 1 7 75215990 108 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 4 93973 1 1 6 75215990 49.6 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 5 93985 2 1 10 75215990 170 Corn, cooked, fr… 0 0 veg_oth 1500127… ## 6 94011 2 1 12 75215990 36 Corn, cooked, fr… 0 0 veg_oth 1500127… ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; # confirm there are no more missing FCIDs both_days14 %&gt;% filter(is.na(fcidcode)) %&gt;% head() # good ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other &lt;NA&gt; ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other &lt;NA&gt; ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other &lt;NA&gt; ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; # confirm there are no more missing GHG both_days14 %&gt;% filter(is.na(GHG_mn)) %&gt;% head() ## # A tibble: 6 × 30 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 2 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 3 83732 2 1 2 91200040 2 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 15 92410520 480 Soft drink, frui… 0 0 other &lt;NA&gt; ## 5 83735 1 1 4 92410370 180 Soft drink, pepp… 0 0 other &lt;NA&gt; ## 6 83735 1 1 11 92410370 360 Soft drink, pepp… 0 0 other &lt;NA&gt; ## # ℹ 19 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt; both_days14 %&gt;% filter(is.na(GHG_mn)) %&gt;% select(description, Foodgroup_FCID) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 2 ## description Foodgroup_FCID ## &lt;chr&gt; &lt;chr&gt; ## 1 Sugar substitute, saccharin, powder other ## 2 Soft drink, cola, diet other ## 3 Soft drink, fruit flavored, diet, caffeine free other ## 4 Soft drink, pepper type, diet other ## 5 Soft drink, cola, decaffeinated, diet other ## 6 Milk, human babyfood both_days14 %&gt;% filter(is.na(GHG_mn)) %&gt;% select(Foodgroup_FCID) %&gt;% distinct() ## # A tibble: 5 × 1 ## Foodgroup_FCID ## &lt;chr&gt; ## 1 other ## 2 babyfood ## 3 water ## 4 gr_whole ## 5 pf_seafood both_days14 %&gt;% filter(is.na(WATER_mn)) %&gt;% select(Foodgroup_FCID) %&gt;% distinct() ## # A tibble: 5 × 1 ## Foodgroup_FCID ## &lt;chr&gt; ## 1 other ## 2 babyfood ## 3 water ## 4 gr_whole ## 5 pf_seafood At this point, most of the missing is for babyfood and other foods, so we will move on. Tidy up the global environment. rm(list=setdiff(ls(), c(&quot;both_days14&quot;, &quot;my_date&quot;))) FCID-Level Social Impact Factors (i.e., Forced Labor Risk) Import the forced labor (FL) risk scores (excluding seafood for now) and join with both_days. # import fl scores fl &lt;- read_csv(&quot;data_inputs/SOCIAL/forced_labor/DATA/FL_scores_FCID_062124.csv&quot;) %&gt;% select(FCID_Code_chr, Weight_Conversion, FL_Score_Value_grams) %&gt;% mutate(FCID_Code_chr = as.character(FCID_Code_chr)) ## Rows: 399 Columns: 10 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (3): FCID_Desc, Foodgroup, FL_Score ## dbl (7): FCID_Code, Weight_Conversion, FL_Score_Value, FL_Score_Value_NOFEED, FL_Score_Value_grams, FL_Sc... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # now merge both_days15 &lt;- left_join(both_days14, fl, by = c(&quot;fcidcode&quot; = &quot;FCID_Code_chr&quot;)) # any missing fl scores? both_days15 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% head() #fine ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 9500115… ## 2 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 8602000… ## 3 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 4 94100100 240 Water, bottled, … 0 0 water 8601200… ## 5 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 6 83732 2 1 9 75506010 20 Mustard 0 0 veg_oth 9500390… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; both_days15 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% select(Foodgroup_FCID) %&gt;% distinct() #fine ## # A tibble: 6 × 1 ## Foodgroup_FCID ## &lt;chr&gt; ## 1 coffee_tea ## 2 water ## 3 other ## 4 pf_seafood ## 5 babyfood ## 6 gr_whole Now we have to handle the seafood scores. First, look at the rows where either the FNDDS- or FCID-level food group is seafood. both_days15 %&gt;% filter(Foodgroup_FNDDS == &quot;pf_seafood&quot;) %&gt;% head() ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 2301236… ## 2 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 2001319… ## 3 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 9500265… ## 4 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 2002330… ## 5 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 8000158… ## 6 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 2003128… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; both_days15 %&gt;% filter(Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% head() ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 8000158… ## 2 83733 2 1 5 26107140 680 Catfish, coated,… 1.29 0 pf_seafood 8000158… ## 3 83742 2 1 11 58146372 188. Pasta with tomat… 0.19 0 gr_refined 8000161… ## 4 83742 2 1 11 58146372 188. Pasta with tomat… 0.19 0 gr_refined 8000162… ## 5 83755 2 1 10 26109110 153 Cod, cooked, NS … 0 0 pf_seafood 8000160… ## 6 83756 2 1 3 27450060 119 Tuna salad, made… 0.44 0 pf_seafood 8000159… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; both_days15 %&gt;% filter(Foodgroup_FNDDS == &quot;pf_seafood&quot; &amp; Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% head() ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83733 2 1 4 26107140 226 Catfish, coated,… 0.43 0 pf_seafood 8000158… ## 2 83733 2 1 5 26107140 680 Catfish, coated,… 1.29 0 pf_seafood 8000158… ## 3 83755 2 1 10 26109110 153 Cod, cooked, NS … 0 0 pf_seafood 8000160… ## 4 83756 2 1 3 27450060 119 Tuna salad, made… 0.44 0 pf_seafood 8000159… ## 5 83761 2 1 4 27450750 197. Fish and vegetab… 0 0 pf_seafood 8000160… ## 6 83761 2 1 10 27250120 347. Shrimp and noodl… 0 0 pf_seafood 8000161… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; Split both_days into two distinct datasets so that we can work with them separately: one containing all rows where both the FNDDS- and FCID-level food group is seafood, and the second containing the remaining rows. seafood &lt;- both_days15 %&gt;% filter(Foodgroup_FNDDS == &quot;pf_seafood&quot; &amp; Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% select(-c(Weight_Conversion, FL_Score_Value_grams)) no_seafood &lt;- both_days15 %&gt;% filter(!(Foodgroup_FNDDS == &quot;pf_seafood&quot; &amp; Foodgroup_FCID == &quot;pf_seafood&quot;)) # check nrow(seafood) + nrow(no_seafood) ## [1] 2823994 nrow(both_days15) ## [1] 2823994 nrow(seafood) + nrow(no_seafood) == nrow(both_days15) ## [1] TRUE Now, import the seafood-specific forced labor scores (“sea_scores”) and join with the seafood diet dataset (“seafood”). # import seafood scores sea_scores &lt;- read_csv(&quot;data_inputs/SOCIAL/forced_labor/DATA/seafood_FL_scores_FNDDS_062124.csv&quot;) %&gt;% select(FNDDS_Code, FL_Score_Value_grams) ## Rows: 387 Columns: 8 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): FNDDS_Desc, FL_Score ## dbl (6): FNDDS_Code, FL_Score_Value_chr, FL_Score_Value_NOFEED, FL_Score_Value, FL_Score_Value_grams, FL_... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # join sea_join &lt;- left_join(seafood, sea_scores, by = c(&quot;foodcode&quot; = &quot;FNDDS_Code&quot;)) ## Warning in left_join(seafood, sea_scores, by = c(foodcode = &quot;FNDDS_Code&quot;)): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 26 of `x` matches multiple rows in `y`. ## ℹ Row 15 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. The seafood dish “bouillabaisse” was very complicated to handle, and therefore we had to calculate the FL score for this dish in a separate Excel sheet, which gets read in below. # missing sea_join %&gt;% filter(is.na(FL_Score_Value_grams)) # bouillabaise ## # A tibble: 24 × 31 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 84522 1 1 4 27350110 497. Bouillabaisse 0 0 pf_seafood 8000161000 ## 2 84522 1 1 4 27350110 497. Bouillabaisse 0 0 pf_seafood 8000160000 ## 3 84522 1 1 4 27350110 497. Bouillabaisse 0 0 pf_seafood 8000162000 ## 4 84522 1 1 4 27350110 497. Bouillabaisse 0 0 pf_seafood 8000157000 ## 5 85731 2 1 9 27350110 454 Bouillabaisse 0 0 pf_seafood 8000161000 ## 6 85731 2 1 9 27350110 454 Bouillabaisse 0 0 pf_seafood 8000160000 ## 7 85731 2 1 9 27350110 454 Bouillabaisse 0 0 pf_seafood 8000162000 ## 8 85731 2 1 9 27350110 454 Bouillabaisse 0 0 pf_seafood 8000157000 ## 9 86452 2 1 5 27350110 454 Bouillabaisse 0 0 pf_seafood 8000161000 ## 10 86452 2 1 5 27350110 454 Bouillabaisse 0 0 pf_seafood 8000160000 ## # ℹ 14 more rows ## # ℹ 20 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # FL_Score_Value_grams &lt;dbl&gt; # import bouillabaise scores bou &lt;- read_xlsx(&quot;data_inputs/SOCIAL/forced_labor/DATA/Seafood_mapping_06-04-24.xlsx&quot;, sheet = &quot;Bouillabaisse_scores&quot;) %&gt;% select(FNDDS_code, FCID_code, FL_Score_FCID) %&gt;% rename(foodcode = FNDDS_code, fcidcode = FCID_code) %&gt;% mutate(FL_Score_Value_bou = FL_Score_FCID / 1000000, fcidcode = as.character(fcidcode)) %&gt;% select(-FL_Score_FCID) # join sea_join1 &lt;- left_join(sea_join, bou) ## Joining with `by = join_by(foodcode, fcidcode)` sea_join2 &lt;- sea_join1 %&gt;% mutate(FL_Score_Value_grams = ifelse(foodcode == 27350110 &amp; is.na(FL_Score_Value_grams), FL_Score_Value_bou, FL_Score_Value_grams), # set weight conversion to 1 for seafood Weight_Conversion = 1) %&gt;% select(-FL_Score_Value_bou) sea_join2 %&gt;% filter(is.na(FL_Score_Value_grams)) #none-woo! ## # A tibble: 0 × 32 ## # ℹ 32 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, Foodgroup_FNDDS &lt;chr&gt;, fcidcode &lt;chr&gt;, fcid_desc &lt;chr&gt;, ## # wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, ## # retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, inedible_amt_FCID &lt;dbl&gt;, ## # wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, wasted_amt_FNDDS &lt;dbl&gt;, ## # CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt; Now re-combine the seafood and non-seafood datasets. # combine back with no seafood both_days12 &lt;- rbind(no_seafood, sea_join2) %&gt;% arrange(seqn, dayrec, line) # check missing both_days12 %&gt;% filter(is.na(Weight_Conversion)) %&gt;% head() #fine ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 9500115… ## 2 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 8602000… ## 3 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 4 94100100 240 Water, bottled, … 0 0 water 8601200… ## 5 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 6 83732 2 1 9 75506010 20 Mustard 0 0 veg_oth 9500390… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; both_days12 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% head() ## # A tibble: 6 × 32 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 9500115… ## 2 83732 2 1 1 92101000 720 Coffee, brewed 0 0 other 8602000… ## 3 83732 2 1 2 91200040 4 Sugar substitute… 0 0 added_sugar &lt;NA&gt; ## 4 83732 2 1 4 94100100 240 Water, bottled, … 0 0 water 8601200… ## 5 83732 2 1 7 92410320 600 Soft drink, cola… 0 0 other &lt;NA&gt; ## 6 83732 2 1 9 75506010 20 Mustard 0 0 veg_oth 9500390… ## # ℹ 21 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt; both_days12 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% select(fcid_desc) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 1 ## fcid_desc ## &lt;chr&gt; ## 1 Coffee, roasted bean ## 2 Water, indirect, all sources ## 3 &lt;NA&gt; ## 4 Water, direct, bottled ## 5 Vinegar ## 6 Water, direct, tap # missing_fl &lt;- both_days12 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% # select(description, Foodgroup_FNDDS, fcid_desc, Foodgroup_FCID) %&gt;% # filter(!(Foodgroup_FCID %in% c(&quot;water&quot;, &quot;coffee_tea&quot;, &quot;babyfood&quot;, &quot;other&quot;))) %&gt;% # distinct() # # # export # write_csv(missing_fl, paste(&quot;data_inputs/SOCIAL/forced_labor/DATA/missing_data/Missing FL scores_&quot;, my_date, &quot;.csv&quot;, sep=&quot;&quot;)) For the remaining missing FL scores for seafood, we will calculate the median seafood-specific FL score and impute the missing scores. # create impute median both_days12 %&gt;% select(seqn, line, dayrec, fcidcode, Foodgroup_FCID, fcid_desc, FL_Score_Value_grams) %&gt;% filter(Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 7 ## seqn line dayrec fcidcode Foodgroup_FCID fcid_desc FL_Score_Value_grams ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 83733 4 2 8000158000 pf_seafood Fish-freshwater finfish, farm raised 0.00131 ## 2 83733 5 2 8000158000 pf_seafood Fish-freshwater finfish, farm raised 0.00131 ## 3 83742 11 2 8000161000 pf_seafood Fish-shellfish, crustacean NA ## 4 83742 11 2 8000162000 pf_seafood Fish-shellfish, mollusc NA ## 5 83755 10 2 8000160000 pf_seafood Fish-saltwater finfish, other 0.00131 ## 6 83756 3 2 8000159000 pf_seafood Fish-saltwater finfish, tuna 0.00121 both_days12 %&gt;% select(fcidcode, fcid_desc, Foodgroup_FCID, FL_Score_Value_grams) %&gt;% filter(Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% distinct() %&gt;% arrange(fcidcode) %&gt;% head() ## # A tibble: 6 × 4 ## fcidcode fcid_desc Foodgroup_FCID FL_Score_Value_grams ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 8000157000 Fish-freshwater finfish pf_seafood 0.000751 ## 2 8000157000 Fish-freshwater finfish pf_seafood 0.00108 ## 3 8000157000 Fish-freshwater finfish pf_seafood 0.00167 ## 4 8000157000 Fish-freshwater finfish pf_seafood NA ## 5 8000157000 Fish-freshwater finfish pf_seafood 0.000578 ## 6 8000157000 Fish-freshwater finfish pf_seafood 0.00000150 imputed_fl &lt;- both_days12 %&gt;% select(seqn, line, dayrec, fcidcode, Foodgroup_FCID, fcid_desc, FL_Score_Value_grams) %&gt;% filter(Foodgroup_FCID == &quot;pf_seafood&quot;) %&gt;% distinct() %&gt;% group_by(fcidcode, fcid_desc) %&gt;% summarise(FL_g_group_median = median(FL_Score_Value_grams, na.rm = TRUE)) %&gt;% filter(!(is.na(fcidcode))) ## `summarise()` has grouped output by &#39;fcidcode&#39;. You can override using the `.groups` argument. # join imputed fl scores with food data both_days13 &lt;- left_join(both_days12, imputed_fl, by = c(&quot;fcidcode&quot;, &quot;fcid_desc&quot;)) # insert food_group median price if missing both_days14 &lt;- both_days13 %&gt;% mutate(FL_Score_Value_grams = ifelse(is.na(FL_Score_Value_grams) &amp; Foodgroup_FCID == &quot;pf_seafood&quot;, FL_g_group_median, FL_Score_Value_grams)) %&gt;% ungroup() # check if any missing price per gram (shouldn&#39;t be) both_days14 %&gt;% filter(is.na(FL_Score_Value_grams)) %&gt;% select(fcid_desc) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 1 ## fcid_desc ## &lt;chr&gt; ## 1 Coffee, roasted bean ## 2 Water, indirect, all sources ## 3 &lt;NA&gt; ## 4 Water, direct, bottled ## 5 Vinegar ## 6 Water, direct, tap both_days14 %&gt;% filter(is.na(FL_Score_Value_grams) &amp; Foodgroup_FCID == &quot;pf_seafood&quot;) #none-good ## # A tibble: 0 × 33 ## # ℹ 33 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, Foodgroup_FNDDS &lt;chr&gt;, fcidcode &lt;chr&gt;, fcid_desc &lt;chr&gt;, ## # wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, ## # retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, inedible_amt_FCID &lt;dbl&gt;, ## # wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, wasted_amt_FNDDS &lt;dbl&gt;, ## # CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, Weight_Conversion &lt;dbl&gt;, ## # FL_Score_Value_grams &lt;dbl&gt;, FL_g_group_median &lt;dbl&gt; # check cocoa bean both_days14 %&gt;% filter(fcid_desc == &quot;Cocoa bean, chocolate&quot;) %&gt;% head() ## # A tibble: 6 × 33 ## seqn daysintake reliable line foodcode grams description added_sugar ssb Foodgroup_FNDDS fcidcode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 83735 1 1 5 91705300 8 Chocolate, sweet… 0.93 0 added_sugar 9500109… ## 2 83735 1 1 6 91705310 14 Chocolate, sweet… 1.4 0 added_sugar 9500109… ## 3 83737 2 1 4 27146160 244 Chicken with mol… 0 0 pf_poultry 9500109… ## 4 83739 2 1 14 53210900 42 Cookie, graham c… 3.88 0 gr_refined 9500109… ## 5 83745 2 1 9 53206000 90 Cookie, chocolat… 6.97 0 gr_refined 9500109… ## 6 83755 2 1 11 53520160 36 Doughnut, chocol… 2.12 0 gr_refined 9500109… ## # ℹ 22 more variables: fcid_desc &lt;chr&gt;, wt &lt;dbl&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, ## # waste_coef &lt;dbl&gt;, ined_coef &lt;dbl&gt;, retloss_coef &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt;, consumed_amt_FCID &lt;dbl&gt;, ## # inedible_amt_FCID &lt;dbl&gt;, wasted_amt_FCID &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, ## # wasted_amt_FNDDS &lt;dbl&gt;, CED_mn &lt;dbl&gt;, GHG_mn &lt;dbl&gt;, WATER_mn &lt;dbl&gt;, BLUEWATER_mn &lt;dbl&gt;, ## # Weight_Conversion &lt;dbl&gt;, FL_Score_Value_grams &lt;dbl&gt;, FL_g_group_median &lt;dbl&gt; # create new nhanes cycle variable both_days15 &lt;- both_days14 %&gt;% mutate(nhanes1516 = ifelse(nhanes_cycle == &quot;2015-2016&quot;, 1, 0)) 4.1.2 Calculate Average Environmental and Social Impact, Per FCID Code Now, we will calculate (i) the average environmental impacts per 1 gram of each FCID code, and (ii) the average amount of forced labor risk per 1 gram of each FCID code. This process includes aggregating and summarizing the diet dataset. First, take the original environmental impact factors provided by the dataField datasets, the units of which are per 1 kilograms (1000 grams) and divide by 1000 to get the impacts per 1 gram of food. The forced labor impact factor, on the other hand, just needs to be multiplied by the weight conversion factor. Then, for all the impact factors, calculate the total amounts of impact for the given amount of consumed food by multiplying the impact factor (per 1 gram of food) by the consumed amount of food (in grams). my_enviro_table &lt;- both_days15 %&gt;% mutate( GHG_impact_per_gram = GHG_mn / 1000, GHG_impact_per_FCID_Consumed = GHG_impact_per_gram * consumed_amt_FCID, CED_impact_per_gram = CED_mn / 1000, CED_impact_per_FCID_Consumed = CED_impact_per_gram * consumed_amt_FCID, WATER_impact_per_gram = WATER_mn / 1000, WATER_impact_per_FCID_Consumed = WATER_impact_per_gram * consumed_amt_FCID, BLUEWATER_impact_per_gram = BLUEWATER_mn / 1000, BLUEWATER_impact_per_FCID_Consumed = BLUEWATER_impact_per_gram * consumed_amt_FCID, FL_impact_per_gram = FL_Score_Value_grams * Weight_Conversion, FL_impact_per_FCID_Consumed = FL_impact_per_gram * consumed_amt_FCID) Check missing. # what food groups have missing impact factors? my_enviro_table %&gt;% filter(is.na(GHG_impact_per_gram)) %&gt;% select(fcidcode, fcid_desc, Foodgroup_FCID) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 3 ## fcidcode fcid_desc Foodgroup_FCID ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &lt;NA&gt; &lt;NA&gt; other ## 2 3700222501 Milk, human babyfood ## 3 &lt;NA&gt; &lt;NA&gt; water ## 4 2002365001 Sunflower, oil-babyfood babyfood ## 5 1400114001 Coconut, oil-babyfood babyfood ## 6 3600223001 Milk, nonfat solids-baby food/infant formula babyfood # this is fine my_enviro_table %&gt;% filter(is.na(GHG_impact_per_gram)) %&gt;% select(Foodgroup_FCID) %&gt;% distinct() ## # A tibble: 5 × 1 ## Foodgroup_FCID ## &lt;chr&gt; ## 1 other ## 2 babyfood ## 3 water ## 4 gr_whole ## 5 pf_seafood my_enviro_table %&gt;% filter(is.na(FL_impact_per_gram)) %&gt;% select(fcidcode, fcid_desc, Foodgroup_FCID) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 3 ## fcidcode fcid_desc Foodgroup_FCID ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 9500115000 Coffee, roasted bean coffee_tea ## 2 8602000000 Water, indirect, all sources water ## 3 &lt;NA&gt; &lt;NA&gt; other ## 4 8601200000 Water, direct, bottled water ## 5 9500390000 Vinegar other ## 6 8601100000 Water, direct, tap water Then, calculate the total impacts, per day, per person, by adding up the food-level impacts for each person-day combination. Additionally, calculate the consumed, inedible, and wasted amounts of food per day, per person, to be used later in the code. enviro_impact &lt;- my_enviro_table %&gt;% group_by(seqn, fcidcode, dayrec) %&gt;% summarise(GHG_per_day_Consumed = sum(GHG_impact_per_FCID_Consumed, na.rm = TRUE), CED_per_day_Consumed = sum(CED_impact_per_FCID_Consumed, na.rm = TRUE), WATER_per_day_Consumed = sum(WATER_impact_per_FCID_Consumed, na.rm = TRUE), BLUEWATER_per_day_Consumed = sum(BLUEWATER_impact_per_FCID_Consumed, na.rm = TRUE), FL_per_day_Consumed = sum(FL_impact_per_FCID_Consumed, na.rm = TRUE), consumed_per_day = sum(consumed_amt_FCID, na.rm = TRUE), inedible_per_day = sum(inedible_amt_FCID, na.rm = TRUE), wasted_per_day = sum(wasted_amt_FCID, na.rm = TRUE)) %&gt;% filter(!(is.na(fcidcode))) # this is needed bc there are some na fcidcodes ## `summarise()` has grouped output by &#39;seqn&#39;, &#39;fcidcode&#39;. You can override using the `.groups` argument. Now, repeat the same steps above specifically for sugar sweetened beverages (this is done by including the “ssb” variable in the “group_by” statement). # now do ssb ssb_impact &lt;- my_enviro_table %&gt;% group_by(seqn, fcidcode, dayrec, ssb) %&gt;% summarise(GHG_per_day_Consumed = sum(GHG_impact_per_FCID_Consumed, na.rm = TRUE), CED_per_day_Consumed = sum(CED_impact_per_FCID_Consumed, na.rm = TRUE), WATER_per_day_Consumed = sum(WATER_impact_per_FCID_Consumed, na.rm = TRUE), BLUEWATER_per_day_Consumed = sum(BLUEWATER_impact_per_FCID_Consumed, na.rm = TRUE), FL_per_day_Consumed = sum(FL_impact_per_FCID_Consumed, na.rm = TRUE), consumed_per_day = sum(consumed_amt_FCID, na.rm = TRUE), inedible_per_day = sum(inedible_amt_FCID, na.rm = TRUE), wasted_per_day = sum(wasted_amt_FCID, na.rm = TRUE)) %&gt;% filter(!(is.na(fcidcode))) ## `summarise()` has grouped output by &#39;seqn&#39;, &#39;fcidcode&#39;, &#39;dayrec&#39;. You can override using the `.groups` ## argument. # calculate sum of fcid codes for ssb ssb_impact %&gt;% filter(ssb == 1) %&gt;% head() ## # A tibble: 6 × 12 ## # Groups: seqn, fcidcode, dayrec [6] ## seqn fcidcode dayrec ssb GHG_per_day_Consumed CED_per_day_Consumed WATER_per_day_Consumed ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 101052000 2 1 0.00321 0.0375 3.95 ## 2 83732 8602000000 2 1 0 0 0 ## 3 83732 9500362000 2 1 0.00731 0.0537 10.7 ## 4 83732 9500372000 2 1 0.00378 0.0529 11.2 ## 5 83736 101052000 1 1 0.00184 0.0215 2.26 ## 6 83736 101052000 2 1 0.00192 0.0225 2.36 ## # ℹ 5 more variables: BLUEWATER_per_day_Consumed &lt;dbl&gt;, FL_per_day_Consumed &lt;dbl&gt;, consumed_per_day &lt;dbl&gt;, ## # inedible_per_day &lt;dbl&gt;, wasted_per_day &lt;dbl&gt; # calculate summed ssb impact for each seqn and day ssb_impact1 &lt;- ssb_impact %&gt;% ungroup() %&gt;% filter(ssb == 1) %&gt;% group_by(seqn, dayrec) %&gt;% summarise(GHG_per_day_Consumed_ssb = sum(GHG_per_day_Consumed, na.rm = TRUE), CED_per_day_Consumed_ssb = sum(CED_per_day_Consumed, na.rm = TRUE), WATER_per_day_Consumed_ssb = sum(WATER_per_day_Consumed, na.rm = TRUE), BLUEWATER_per_day_Consumed_ssb = sum(BLUEWATER_per_day_Consumed, na.rm = TRUE), FL_per_day_Consumed_ssb = sum(FL_per_day_Consumed, na.rm = TRUE), consumed_per_day_ssb = sum(consumed_per_day, na.rm = TRUE), inedible_per_day_ssb = sum(inedible_per_day, na.rm = TRUE), wasted_per_day_ssb = sum(wasted_per_day, na.rm = TRUE)) ## `summarise()` has grouped output by &#39;seqn&#39;. You can override using the `.groups` argument. # go back to non-ssb # check missing enviro_impact %&gt;% filter(is.na(consumed_per_day)) #none-good ## # A tibble: 0 × 11 ## # Groups: seqn, fcidcode [0] ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, dayrec &lt;dbl&gt;, GHG_per_day_Consumed &lt;dbl&gt;, ## # CED_per_day_Consumed &lt;dbl&gt;, WATER_per_day_Consumed &lt;dbl&gt;, BLUEWATER_per_day_Consumed &lt;dbl&gt;, ## # FL_per_day_Consumed &lt;dbl&gt;, consumed_per_day &lt;dbl&gt;, inedible_per_day &lt;dbl&gt;, wasted_per_day &lt;dbl&gt; enviro_impact %&gt;% filter(is.na(fcidcode)) ## # A tibble: 0 × 11 ## # Groups: seqn, fcidcode [0] ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, dayrec &lt;dbl&gt;, GHG_per_day_Consumed &lt;dbl&gt;, ## # CED_per_day_Consumed &lt;dbl&gt;, WATER_per_day_Consumed &lt;dbl&gt;, BLUEWATER_per_day_Consumed &lt;dbl&gt;, ## # FL_per_day_Consumed &lt;dbl&gt;, consumed_per_day &lt;dbl&gt;, inedible_per_day &lt;dbl&gt;, wasted_per_day &lt;dbl&gt; Transform dataset to wide format. enviro_wide &lt;- pivot_wider(enviro_impact, names_from = dayrec, values_from = c(contains(&quot;per_day&quot;))) Because some participants have 2 days of dietary recall, we need to calculate average impacts for each FCID code, per participant. If a participant only has 1 day of recall, then we use that to represent the average. To calculate the average, we first need to determine how many days of recall each participant has. # calculate # days of recall both_days15 %&gt;% select(reliable) %&gt;% table() ## reliable ## 1 4 ## 2799377 25083 daysofintake &lt;- both_days15 %&gt;% select(seqn, daysintake, reliable) %&gt;% distinct() # join enviro_wide1 &lt;- enviro_wide %&gt;% left_join(daysofintake, by = &quot;seqn&quot;) ## Warning in left_join(., daysofintake, by = &quot;seqn&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 33073 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. # check enviro_wide1 %&gt;% filter(daysintake == 1 &amp; is.na(consumed_per_day_1)) #good ## # A tibble: 0 × 20 ## # Groups: seqn, fcidcode [0] ## # ℹ 20 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, GHG_per_day_Consumed_1 &lt;dbl&gt;, GHG_per_day_Consumed_2 &lt;dbl&gt;, ## # CED_per_day_Consumed_1 &lt;dbl&gt;, CED_per_day_Consumed_2 &lt;dbl&gt;, WATER_per_day_Consumed_1 &lt;dbl&gt;, ## # WATER_per_day_Consumed_2 &lt;dbl&gt;, BLUEWATER_per_day_Consumed_1 &lt;dbl&gt;, BLUEWATER_per_day_Consumed_2 &lt;dbl&gt;, ## # FL_per_day_Consumed_1 &lt;dbl&gt;, FL_per_day_Consumed_2 &lt;dbl&gt;, consumed_per_day_1 &lt;dbl&gt;, ## # consumed_per_day_2 &lt;dbl&gt;, inedible_per_day_1 &lt;dbl&gt;, inedible_per_day_2 &lt;dbl&gt;, wasted_per_day_1 &lt;dbl&gt;, ## # wasted_per_day_2 &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt; Now, we have to fill in some 0s to properly calculate averages later on. If a participant has 2 days of intake and their corresponding impact (e.g., GHG) for day 1 or day 2 is missing (NA), then we need to replace those NAs with 0s, because in this case, the data aren’t “missing”, the participant just didn’t consume that food on those day. enviro_wide2 &lt;- enviro_wide1 %&gt;% mutate(# day 2 GHG_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(GHG_per_day_Consumed_2), 0, GHG_per_day_Consumed_2), CED_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(CED_per_day_Consumed_2), 0, CED_per_day_Consumed_2), WATER_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(WATER_per_day_Consumed_2), 0, WATER_per_day_Consumed_2), BLUEWATER_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(BLUEWATER_per_day_Consumed_2), 0, BLUEWATER_per_day_Consumed_2), FL_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(FL_per_day_Consumed_2), 0, FL_per_day_Consumed_2), consumed_per_day_2 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_2), 0, consumed_per_day_2), wasted_per_day_2 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_2), 0, wasted_per_day_2), inedible_per_day_2 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_2), 0, inedible_per_day_2), # day1 GHG_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(GHG_per_day_Consumed_1), 0, GHG_per_day_Consumed_1), CED_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(CED_per_day_Consumed_1), 0, CED_per_day_Consumed_1), WATER_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(WATER_per_day_Consumed_1), 0, WATER_per_day_Consumed_1), BLUEWATER_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(BLUEWATER_per_day_Consumed_1), 0, BLUEWATER_per_day_Consumed_1), FL_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(FL_per_day_Consumed_1), 0, FL_per_day_Consumed_1), consumed_per_day_1 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_1), 0, consumed_per_day_1), wasted_per_day_1 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_1), 0, wasted_per_day_1), inedible_per_day_1 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_1), 0, inedible_per_day_1)) Calculate the average total impacts of consumed food at the FCID code-level for each person. This will give us the data we need to calculate the environmental and forced labor impact factors in the next section. # summarize DAY1 AND DAY2 enviro_wide3 &lt;- enviro_wide2 %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate(ghg_impact_avg_Consumed = mean(c(GHG_per_day_Consumed_1, GHG_per_day_Consumed_2), na.rm = TRUE), ced_impact_avg_Consumed = mean(c(CED_per_day_Consumed_1, CED_per_day_Consumed_2), na.rm = TRUE), water_impact_avg_Consumed = mean(c(WATER_per_day_Consumed_1, WATER_per_day_Consumed_2), na.rm = TRUE), bluewater_impact_avg_Consumed = mean(c(BLUEWATER_per_day_Consumed_1, BLUEWATER_per_day_Consumed_2), na.rm = TRUE), fl_impact_avg_Consumed = mean(c(FL_per_day_Consumed_1, FL_per_day_Consumed_2), na.rm = TRUE), consumed_avg = mean(c(consumed_per_day_1, consumed_per_day_2), na.rm = TRUE), inedible_avg = mean(c(inedible_per_day_1, inedible_per_day_2), na.rm = TRUE), wasted_avg = mean(c(wasted_per_day_1, wasted_per_day_2), na.rm = TRUE)) %&gt;% select(seqn, fcidcode, starts_with(c(&quot;ghg_impact_avg_&quot;, &quot;ced_impact_avg_&quot;, &quot;water_impact_avg_&quot;, &quot;bluewater_impact_avg_&quot;, &quot;fl_impact_avg_&quot;)), consumed_avg, inedible_avg, wasted_avg) Import the FCID-to-dietary-factor mapping and join with enviro_wide so that we can later on summarize the impacts at the dietary factor (i.e., food group) level. # import fcid-diet factor mapping new_map &lt;- read_xlsx(&quot;data_inputs/OTHER/dietfactor_to_fcid_mapping/DATA/FCID_to_dietaryfactor_mapping_01-09-2024_final.xlsx&quot;) %&gt;% select(FCID_Code, Foodgroup) %&gt;% rename(fcidcode = FCID_Code, Foodgroup_FCID = Foodgroup) %&gt;% mutate(fcidcode = as.character(fcidcode)) # join enviro_wide4 &lt;- enviro_wide3 %&gt;% left_join(new_map, by = &quot;fcidcode&quot;) # CHECK NA enviro_wide4 %&gt;% filter(is.na(Foodgroup_FCID)) #none-good ## # A tibble: 0 × 11 ## # Rowwise: ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, ghg_impact_avg_Consumed &lt;dbl&gt;, ced_impact_avg_Consumed &lt;dbl&gt;, ## # water_impact_avg_Consumed &lt;dbl&gt;, bluewater_impact_avg_Consumed &lt;dbl&gt;, fl_impact_avg_Consumed &lt;dbl&gt;, ## # consumed_avg &lt;dbl&gt;, inedible_avg &lt;dbl&gt;, wasted_avg &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; enviro_wide4 %&gt;% filter(is.na(consumed_avg)) #none-good ## # A tibble: 0 × 11 ## # Rowwise: ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, ghg_impact_avg_Consumed &lt;dbl&gt;, ced_impact_avg_Consumed &lt;dbl&gt;, ## # water_impact_avg_Consumed &lt;dbl&gt;, bluewater_impact_avg_Consumed &lt;dbl&gt;, fl_impact_avg_Consumed &lt;dbl&gt;, ## # consumed_avg &lt;dbl&gt;, inedible_avg &lt;dbl&gt;, wasted_avg &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; enviro_wide4 %&gt;% filter(is.na(ghg_impact_avg_Consumed)) #none-good ## # A tibble: 0 × 11 ## # Rowwise: ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, ghg_impact_avg_Consumed &lt;dbl&gt;, ced_impact_avg_Consumed &lt;dbl&gt;, ## # water_impact_avg_Consumed &lt;dbl&gt;, bluewater_impact_avg_Consumed &lt;dbl&gt;, fl_impact_avg_Consumed &lt;dbl&gt;, ## # consumed_avg &lt;dbl&gt;, inedible_avg &lt;dbl&gt;, wasted_avg &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; enviro_wide4 %&gt;% filter(is.na(fl_impact_avg_Consumed)) #none-good ## # A tibble: 0 × 11 ## # Rowwise: ## # ℹ 11 variables: seqn &lt;dbl&gt;, fcidcode &lt;chr&gt;, ghg_impact_avg_Consumed &lt;dbl&gt;, ced_impact_avg_Consumed &lt;dbl&gt;, ## # water_impact_avg_Consumed &lt;dbl&gt;, bluewater_impact_avg_Consumed &lt;dbl&gt;, fl_impact_avg_Consumed &lt;dbl&gt;, ## # consumed_avg &lt;dbl&gt;, inedible_avg &lt;dbl&gt;, wasted_avg &lt;dbl&gt;, Foodgroup_FCID &lt;chr&gt; Now add up the impacts per person, by dietary factor (food group). enviro_wide5 &lt;- enviro_wide4 %&gt;% group_by(seqn, Foodgroup_FCID) %&gt;% summarise(ghg_impact_sum_Consumed = sum(ghg_impact_avg_Consumed), ced_impact_sum_Consumed = sum(ced_impact_avg_Consumed), water_impact_sum_Consumed = sum(water_impact_avg_Consumed), bluewater_impact_sum_Consumed = sum(bluewater_impact_avg_Consumed), fl_impact_sum_Consumed = sum(fl_impact_avg_Consumed), consumed_sum = sum(consumed_avg), inedible_sum = sum(inedible_avg), wasted_sum = sum(wasted_avg)) ## `summarise()` has grouped output by &#39;seqn&#39;. You can override using the `.groups` argument. Now, repeat the same steps above specifically for sugar sweetened beverages. # average day 1 and day 2 impacts ssb_wide &lt;- pivot_wider(ssb_impact1, id_cols = seqn, names_from = dayrec, values_from = c(contains(&quot;per_day&quot;))) # join ssb_wide1 &lt;- ssb_wide %&gt;% left_join(daysofintake, by = &quot;seqn&quot;) # fix 2 participants with duplicated data ssb_wide1 %&gt;% filter(seqn == &quot;87444&quot;) %&gt;% head() ## # A tibble: 2 × 19 ## # Groups: seqn [1] ## seqn GHG_per_day_Consumed_ssb_2 GHG_per_day_Consumed_ssb_1 CED_per_day_Consumed_s…¹ CED_per_day_Consumed…² ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 87444 NA 0.0106 NA 0.123 ## 2 87444 NA 0.0106 NA 0.123 ## # ℹ abbreviated names: ¹​CED_per_day_Consumed_ssb_2, ²​CED_per_day_Consumed_ssb_1 ## # ℹ 14 more variables: WATER_per_day_Consumed_ssb_2 &lt;dbl&gt;, WATER_per_day_Consumed_ssb_1 &lt;dbl&gt;, ## # BLUEWATER_per_day_Consumed_ssb_2 &lt;dbl&gt;, BLUEWATER_per_day_Consumed_ssb_1 &lt;dbl&gt;, ## # FL_per_day_Consumed_ssb_2 &lt;dbl&gt;, FL_per_day_Consumed_ssb_1 &lt;dbl&gt;, consumed_per_day_ssb_2 &lt;dbl&gt;, ## # consumed_per_day_ssb_1 &lt;dbl&gt;, inedible_per_day_ssb_2 &lt;dbl&gt;, inedible_per_day_ssb_1 &lt;dbl&gt;, ## # wasted_per_day_ssb_2 &lt;dbl&gt;, wasted_per_day_ssb_1 &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt; ssb_wide1 %&gt;% filter(seqn == &quot;95147&quot;) %&gt;% head() ## # A tibble: 2 × 19 ## # Groups: seqn [1] ## seqn GHG_per_day_Consumed_ssb_2 GHG_per_day_Consumed_ssb_1 CED_per_day_Consumed_s…¹ CED_per_day_Consumed…² ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 95147 NA 0.0340 NA 0.393 ## 2 95147 NA 0.0340 NA 0.393 ## # ℹ abbreviated names: ¹​CED_per_day_Consumed_ssb_2, ²​CED_per_day_Consumed_ssb_1 ## # ℹ 14 more variables: WATER_per_day_Consumed_ssb_2 &lt;dbl&gt;, WATER_per_day_Consumed_ssb_1 &lt;dbl&gt;, ## # BLUEWATER_per_day_Consumed_ssb_2 &lt;dbl&gt;, BLUEWATER_per_day_Consumed_ssb_1 &lt;dbl&gt;, ## # FL_per_day_Consumed_ssb_2 &lt;dbl&gt;, FL_per_day_Consumed_ssb_1 &lt;dbl&gt;, consumed_per_day_ssb_2 &lt;dbl&gt;, ## # consumed_per_day_ssb_1 &lt;dbl&gt;, inedible_per_day_ssb_2 &lt;dbl&gt;, inedible_per_day_ssb_1 &lt;dbl&gt;, ## # wasted_per_day_ssb_2 &lt;dbl&gt;, wasted_per_day_ssb_1 &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt; ssb_wide2 &lt;- ssb_wide1 %&gt;% filter(!(seqn == &quot;87444&quot; &amp; reliable == 4)) %&gt;% filter(!(seqn == &quot;95147&quot; &amp; reliable == 4)) # add 0s when appropriate ssb_wide3 &lt;- ssb_wide2 %&gt;% mutate(# day 2 GHG_per_day_Consumed_ssb_2 = ifelse(daysintake == 2 &amp; is.na(GHG_per_day_Consumed_ssb_2), 0, GHG_per_day_Consumed_ssb_2), CED_per_day_Consumed_ssb_2 = ifelse(daysintake == 2 &amp; is.na(CED_per_day_Consumed_ssb_2), 0, CED_per_day_Consumed_ssb_2), WATER_per_day_Consumed_ssb_2 = ifelse(daysintake == 2 &amp; is.na(WATER_per_day_Consumed_ssb_2), 0, WATER_per_day_Consumed_ssb_2), BLUEWATER_per_day_Consumed_ssb_2 = ifelse(daysintake == 2 &amp; is.na(BLUEWATER_per_day_Consumed_ssb_2), 0, BLUEWATER_per_day_Consumed_ssb_2), FL_per_day_Consumed_ssb_2 = ifelse(daysintake == 2 &amp; is.na(FL_per_day_Consumed_ssb_2), 0, FL_per_day_Consumed_ssb_2), consumed_per_day_ssb_2 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_ssb_2), 0, consumed_per_day_ssb_2), wasted_per_day_ssb_2 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_ssb_2), 0, wasted_per_day_ssb_2), inedible_per_day_ssb_2 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_ssb_2), 0, inedible_per_day_ssb_2), # day1 GHG_per_day_Consumed_ssb_1 = ifelse(daysintake == 2 &amp; is.na(GHG_per_day_Consumed_ssb_1), 0, GHG_per_day_Consumed_ssb_1), CED_per_day_Consumed_ssb_1 = ifelse(daysintake == 2 &amp; is.na(CED_per_day_Consumed_ssb_1), 0, CED_per_day_Consumed_ssb_1), WATER_per_day_Consumed_ssb_1 = ifelse(daysintake == 2 &amp; is.na(WATER_per_day_Consumed_ssb_1), 0, WATER_per_day_Consumed_ssb_1), BLUEWATER_per_day_Consumed_ssb_1 = ifelse(daysintake == 2 &amp; is.na(BLUEWATER_per_day_Consumed_ssb_1), 0, BLUEWATER_per_day_Consumed_ssb_1), FL_per_day_Consumed_ssb_1 = ifelse(daysintake == 2 &amp; is.na(FL_per_day_Consumed_ssb_1), 0, FL_per_day_Consumed_ssb_1), consumed_per_day_ssb_1 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_ssb_1), 0, consumed_per_day_ssb_1), wasted_per_day_ssb_1 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_ssb_1), 0, wasted_per_day_ssb_1), inedible_per_day_ssb_1 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_ssb_1), 0, inedible_per_day_ssb_1)) # summarize DAY1 AND DAY2 ssb_wide4 &lt;- ssb_wide3 %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate(ghg_impact_sum_Consumed = mean(c(GHG_per_day_Consumed_ssb_1, GHG_per_day_Consumed_ssb_2), na.rm = TRUE), ced_impact_sum_Consumed = mean(c(CED_per_day_Consumed_ssb_1, CED_per_day_Consumed_ssb_2), na.rm = TRUE), water_impact_sum_Consumed = mean(c(WATER_per_day_Consumed_ssb_1, WATER_per_day_Consumed_ssb_2), na.rm = TRUE), bluewater_impact_sum_Consumed = mean(c(BLUEWATER_per_day_Consumed_ssb_1, BLUEWATER_per_day_Consumed_ssb_2), na.rm = TRUE), fl_impact_sum_Consumed = mean(c(FL_per_day_Consumed_ssb_1, FL_per_day_Consumed_ssb_2), na.rm = TRUE), consumed_sum = mean(c(consumed_per_day_ssb_1, consumed_per_day_ssb_2), na.rm = TRUE), inedible_sum = mean(c(inedible_per_day_ssb_1, inedible_per_day_ssb_2), na.rm = TRUE), wasted_sum = mean(c(wasted_per_day_ssb_1, wasted_per_day_ssb_2), na.rm = TRUE)) %&gt;% select(seqn, ghg_impact_sum_Consumed, ced_impact_sum_Consumed, water_impact_sum_Consumed, bluewater_impact_sum_Consumed, fl_impact_sum_Consumed, consumed_sum, inedible_sum, wasted_sum) %&gt;% mutate(Foodgroup_FCID = &quot;ssb&quot;) %&gt;% relocate(Foodgroup_FCID, .after = &quot;seqn&quot;) Combine the food and SSB datasets together, then transform to wide format. # rbind with rest of data enviro_wide6 &lt;- rbind(enviro_wide5, ssb_wide4) %&gt;% arrange(seqn, Foodgroup_FCID) # transform to wide enviro_wide7 &lt;- enviro_wide6 %&gt;% pivot_wider(id_cols = seqn, names_from = Foodgroup_FCID, values_from = !c(seqn, Foodgroup_FCID)) %&gt;% replace(is.na(.), 0) # check enviro_wide7 %&gt;% select(contains(&quot;ssb&quot;)) %&gt;% head() ## Adding missing grouping variables: `seqn` ## # A tibble: 6 × 9 ## # Groups: seqn [6] ## seqn ghg_impact_sum_Consumed_ssb ced_impact_sum_Consumed_ssb water_impact_sum_Con…¹ bluewater_impact_sum…² ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 0.00715 0.0721 12.9 2.66 ## 2 83733 0 0 0 0 ## 3 83734 0 0 0 0 ## 4 83735 0 0 0 0 ## 5 83736 0.0375 0.417 19.0 5.71 ## 6 83737 0 0 0 0 ## # ℹ abbreviated names: ¹​water_impact_sum_Consumed_ssb, ²​bluewater_impact_sum_Consumed_ssb ## # ℹ 4 more variables: fl_impact_sum_Consumed_ssb &lt;dbl&gt;, consumed_sum_ssb &lt;dbl&gt;, inedible_sum_ssb &lt;dbl&gt;, ## # wasted_sum_ssb &lt;dbl&gt; Export datasets to the temporary folder, so they can be used to calculate the impact factors in the next section. saveRDS(both_days15, &quot;data_inputs/IMPACT_FACTORS/temp_data/both_days15_env.rds&quot;) saveRDS(enviro_wide7, &quot;data_inputs/IMPACT_FACTORS/temp_data/enviro_input_dat.rds&quot;) "],["cleaning-code-for-cost-data.html", "Chapter 5 Cleaning Code for Cost Data 5.1 Clean and Restructure Intermediary Datasets", " Chapter 5 Cleaning Code for Cost Data This chapter walks you through all of the R code used to clean the raw COST-related data inputs. The resulting cleaned dataset is then used to calculate the cost impact factors (see Chapter XXX). 5.1 Clean and Restructure Intermediary Datasets This script imports all of raw cost-related data inputs, and then cleans and merges them so that the cost impact factors can later be calculated. Note that you must first open the ‘methods_manual’ R project before running this script or else it will not work. First, let’s set up our environment. # check working directory getwd() ## [1] &quot;/Users/bmb73/Library/CloudStorage/Box-Box/lasting_aim_3/model development/methods_manual&quot; # SET UP ----- rm(list = ls()) options(scipen=999) library(tidyverse) library(readxl) library(survey) my_date &lt;- Sys.Date() 5.1.1 Import and Merge Data Inputs NHANES Diet Intake First, read in the NHANES food-level datasets. The data were split into “day 1” and “day 2” earlier, and here we are going to merge them into “both days”. There also are different datasets containing just sugar sweetened beverage (SSB) data, so we have to import those in separately, and then merge with the rest of the day1/day2 diet datasets. Import all of the “day 1” datasets first. # import day1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_clean.rds&quot;) # only select needed variables day1_sub &lt;- day1 %&gt;% select(SEQN, DRDINT, DR1DRSTZ, DR1ILINE, DR1IFDCD, DR1IGRMS, DESCRIPTION, foodsource, nhanes_cycle, dayrec, added_sugar) %&gt;% rename(seqn = SEQN, line = DR1ILINE, foodcode = DR1IFDCD, grams = DR1IGRMS, description = DESCRIPTION, daysintake = DRDINT, reliable = DR1DRSTZ) # ssb ssb_1 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day1_ssb.rds&quot;) # merge food and ssb day1_sub1 &lt;- left_join(day1_sub, ssb_1, by = c(&quot;seqn&quot; = &quot;SEQN&quot;, &quot;line&quot; = &quot;DR1ILINE&quot;, &quot;foodcode&quot; = &quot;DR1IFDCD&quot;, &quot;description&quot; = &quot;DESCRIPTION&quot;, &quot;grams&quot; = &quot;DR1IGRMS&quot;)) Then import all of “day 2” datasets. # import day2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_clean.rds&quot;) # only select needed variables day2_sub &lt;- day2 %&gt;% select(SEQN, DRDINT, DR2DRSTZ, DR2ILINE, DR2IFDCD, DR2IGRMS, DESCRIPTION, foodsource, nhanes_cycle, dayrec, added_sugar) %&gt;% rename(seqn = SEQN, line = DR2ILINE, foodcode = DR2IFDCD, grams = DR2IGRMS, description = DESCRIPTION, daysintake = DRDINT, reliable = DR2DRSTZ) # ssb ssb_2 &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/foods_day2_ssb.rds&quot;) # merge food and ssb day2_sub1 &lt;- left_join(day2_sub, ssb_2, by = c(&quot;seqn&quot; = &quot;SEQN&quot;, &quot;line&quot; = &quot;DR2ILINE&quot;, &quot;foodcode&quot; = &quot;DR2IFDCD&quot;, &quot;description&quot; = &quot;DESCRIPTION&quot;, &quot;grams&quot; = &quot;DR2IGRMS&quot;)) Then, combine the “day 1” and “day 2” datasets to get a “both_days” dataset. both_days &lt;- rbind(day1_sub1, day2_sub1) %&gt;% arrange(seqn, dayrec, line) # check to make sure the formatting worked both_days %&gt;% filter(description == &quot;Meat, NFS&quot;) %&gt;% head() #looks good! ## # A tibble: 6 × 12 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 84032 1 1 9 20000000 11.0 Meat, NFS Other 2015-2016 1 0 0 ## 2 86178 2 1 5 20000000 4.19 Meat, NFS Other 2015-2016 1 0 0 ## 3 86487 2 1 10 20000000 73.3 Meat, NFS Grocery 2015-2016 1 0 0 ## 4 86801 2 1 13 20000000 11.2 Meat, NFS Other 2015-2016 1 0 0 ## 5 87065 2 1 3 20000000 50.2 Meat, NFS Other 2015-2016 1 0 0 ## 6 88767 2 1 12 20000000 7.33 Meat, NFS Other 2015-2016 1 0 0 Lastly, remove the original diet datasets becuase they are very large and we don’t need them anymore. rm(list=setdiff(ls(), c(&quot;both_days&quot;, &quot;my_date&quot;))) Mappings from Dietary Factor to FNDDS Food Code There are two mappings from dietary factor to FNDDS Food Code. There is one specifically just for whole and refined grains - see section XXX on how the whole vs. refined grains designation was determined. And the second one is for all other non-grain foods. First, create an empty dataset template that contains all of the foodcodes that exist in the diet dataset (both_days). all_foodcodes &lt;- both_days %&gt;% select(foodcode) %&gt;% distinct() Then, import the non-grain food mapping (labeled as “map_a”). map_a &lt;- read_csv(&quot;data_inputs/OTHER/dietfactor_to_fndds_mapping/DATA/Food_to_FNDDS_mapping_detailed_04-06-25.csv&quot;) ## Rows: 109 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Foodgroup ## dbl (1): foodcode_prefix ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Then, join the template and the first mapping. my_join &lt;- full_join(mutate(all_foodcodes, i=1), mutate(map_a, i=1)) %&gt;% select(-i) %&gt;% filter(str_detect(foodcode, paste0(&quot;^&quot;, foodcode_prefix))) %&gt;% select(-foodcode_prefix) ## Joining with `by = join_by(i)` ## Warning in full_join(mutate(all_foodcodes, i = 1), mutate(map_a, i = 1)): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. Import the grain-only mapping (labeled as “map_b”). map_b &lt;- read_csv(&quot;data_inputs/OTHER/dietfactor_to_fndds_mapping/DATA/Food_to_FNDDS_mapping_WHOLE_GRAINS_ONLY_09-05-23.csv&quot;) ## Rows: 1728 Columns: 2 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Foodgroup ## dbl (1): foodcode ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Merge my_join with the second mapping. my_join1 &lt;- rbind(my_join, map_b) %&gt;% arrange(foodcode) Lastly, merge back with both_days. both_days1 &lt;- left_join(both_days, my_join1, by = &quot;foodcode&quot;) Check how many FNDDS codes in the dataset don’t have a mapping to a dietary factor (i.e., food group category) both_days1 %&gt;% filter(is.na(Foodgroup)) %&gt;% select(foodcode, description) %&gt;% distinct() %&gt;% arrange(foodcode) ## # A tibble: 0 × 2 ## # ℹ 2 variables: foodcode &lt;dbl&gt;, description &lt;chr&gt; Check SSB by comparing the “ssb” indicator variable and the data when the foodgroup is set to “ssb”. both_days1 %&gt;% filter(ssb == 1) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 4 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 5 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 6 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 1 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 4 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## 5 83742 2 1 9 92410310 150. Soft drink… Other 2015-2016 2 3.54 1 ## 6 83744 2 1 8 92410510 512 Soft drink… Other 2015-2016 1 11.0 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() # need to change these to ssb ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 2 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 3 83753 2 1 6 95320200 744 Sports dri… Other 2015-2016 2 9.3 1 ## 4 83768 2 1 12 64204010 580. Mango nect… Grocery 2015-2016 1 9.64 1 ## 5 83780 2 1 9 64205010 116. Peach nect… Grocery 2015-2016 2 2.76 1 ## 6 83795 2 1 10 95320200 310 Sports dri… Other 2015-2016 2 3.88 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() # need to change these to other ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 1 92101000 720 Coffee, br… Grocery 2015-2016 1 0 0 ## 2 83732 2 1 7 92410320 600 Soft drink… Grocery 2015-2016 1 0 0 ## 3 83732 2 1 1 92101000 255 Coffee, br… Grocery 2015-2016 2 0 0 ## 4 83732 2 1 15 92410520 480 Soft drink… Other 2015-2016 2 0 0 ## 5 83733 2 1 1 92101000 480 Coffee, br… Grocery 2015-2016 1 0 0 ## 6 83733 2 1 1 92101000 450 Coffee, br… Grocery 2015-2016 2 0 0 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days1 %&gt;% filter(ssb == 0 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 2 91200040 4 Sugar substitut… Grocery 2015-2016 1 0 ## 2 83732 2 1 3 12210400 3.92 Coffee creamer,… Grocery 2015-2016 1 0.07 ## 3 83732 2 1 4 94100100 240 Water, bottled,… Grocery 2015-2016 1 0 ## 4 83732 2 1 5 51101010 75 Bread, white, t… Grocery 2015-2016 1 0.74 ## 5 83732 2 1 6 81103080 28.6 Margarine-like … Grocery 2015-2016 1 0 ## 6 83732 2 1 8 27564060 204 Frankfurter or … Grocery 2015-2016 1 1.63 ## # ℹ 2 more variables: ssb &lt;dbl&gt;, Foodgroup &lt;chr&gt; We see that, for some of the rows, ssb is labeled incorrectly, so we need to fix it. both_days2 &lt;- both_days1 %&gt;% mutate(Foodgroup = ifelse(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;, &quot;ssb&quot;, Foodgroup)) %&gt;% mutate(Foodgroup = ifelse(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;, &quot;other&quot;, Foodgroup)) Check again. Looks good. both_days2 %&gt;% filter(ssb == 1 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 14 92308000 372 Tea, iced,… Other 2015-2016 2 6.81 1 ## 2 83736 2 1 2 92410510 326. Soft drink… Grocery 2015-2016 1 6.97 1 ## 3 83736 2 1 7 95320200 356. Sports dri… Grocery 2015-2016 1 4.46 1 ## 4 83736 2 1 5 95320200 372 Sports dri… Grocery 2015-2016 2 4.65 1 ## 5 83736 2 1 7 92410310 248 Soft drink… Grocery 2015-2016 2 5.88 1 ## 6 83742 2 1 13 92510960 207. Lemonade, … Other 2015-2016 1 3.22 1 ## # ℹ 1 more variable: Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 1 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() # none-good ## # A tibble: 0 × 13 ## # ℹ 13 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 0 &amp; Foodgroup == &quot;ssb&quot;) %&gt;% head() # none-good ## # A tibble: 0 × 13 ## # ℹ 13 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup &lt;chr&gt; both_days2 %&gt;% filter(ssb == 0 &amp; Foodgroup != &quot;ssb&quot;) %&gt;% head() ## # A tibble: 6 × 13 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 1 92101000 720 Coffee, brewed Grocery 2015-2016 1 0 ## 2 83732 2 1 2 91200040 4 Sugar substitut… Grocery 2015-2016 1 0 ## 3 83732 2 1 3 12210400 3.92 Coffee creamer,… Grocery 2015-2016 1 0.07 ## 4 83732 2 1 4 94100100 240 Water, bottled,… Grocery 2015-2016 1 0 ## 5 83732 2 1 5 51101010 75 Bread, white, t… Grocery 2015-2016 1 0.74 ## 6 83732 2 1 6 81103080 28.6 Margarine-like … Grocery 2015-2016 1 0 ## # ℹ 2 more variables: ssb &lt;dbl&gt;, Foodgroup &lt;chr&gt; Tidy up the global environment and only keep the datasets we currently need. rm(list=setdiff(ls(), c(&quot;both_days2&quot;, &quot;my_date&quot;))) Food-At-Home (FAH) to Food-Away-Fram-Home (FAFH) Ratios Import the FAH to FAFH ratios, whcih are later used to calculate the price of food purchased at grocery stores (i.e., food at home) vs. food bought outside of grocery stores (i.e., food away from home). # import ratios &lt;- read_csv(&quot;data_inputs/ECONOMIC/fah_fafh_ratio/DATA/output_data/fafh_fah_ratio_clean_07-06-23.csv&quot;) %&gt;% select(Diet_var, ratio_FAFH_FAH) ## Rows: 23 Columns: 5 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): Diet_var, Diet_label ## dbl (3): mean_100g_FAH, mean_100g_FAFH, ratio_FAFH_FAH ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # rename &quot;dairy&quot; to &quot;dairy_tot&quot; ratios1 &lt;- ratios %&gt;% mutate(Diet_var_new = ifelse(Diet_var == &quot;dairy&quot;, &quot;dairy_tot&quot;, Diet_var)) %&gt;% select(-Diet_var) Merge with both_days and then check for any missing values. # join with both_days both_days3 &lt;- left_join(both_days2, ratios1, by = c(&quot;Foodgroup&quot; = &quot;Diet_var_new&quot;)) %&gt;% ungroup() # rename vars both_days4 &lt;- both_days3 %&gt;% rename(Foodgroup_FNDDS = Foodgroup) # any missing ratios? both_days4 %&gt;% filter(is.na(ratio_FAFH_FAH)) %&gt;% head() ## # A tibble: 6 × 14 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83732 2 1 4 94100100 240 Water, bot… Grocery 2015-2016 1 0 0 ## 2 83732 2 1 11 94100100 240 Water, bot… Grocery 2015-2016 1 0 0 ## 3 83732 2 1 14 94100100 360 Water, bot… Grocery 2015-2016 1 0 0 ## 4 83732 2 1 16 94000100 120 Water, tap Other 2015-2016 1 0 0 ## 5 83732 2 1 4 94000100 240 Water, tap Other 2015-2016 2 0 0 ## 6 83732 2 1 8 94100100 480 Water, bot… Grocery 2015-2016 2 0 0 ## # ℹ 2 more variables: Foodgroup_FNDDS &lt;chr&gt;, ratio_FAFH_FAH &lt;dbl&gt; both_days4 %&gt;% filter(is.na(ratio_FAFH_FAH)) %&gt;% select(Foodgroup_FNDDS) %&gt;% distinct() ## # A tibble: 2 × 1 ## Foodgroup_FNDDS ## &lt;chr&gt; ## 1 water ## 2 babyfood # assign ratio to 1 for water and babyfood just as a placeholder both_days5 &lt;- both_days4 %&gt;% mutate(ratio_FAFH_FAH = ifelse(Foodgroup_FNDDS == &quot;water&quot; | Foodgroup_FNDDS == &quot;babyfood&quot;, 1, ratio_FAFH_FAH)) We see that all missing ratios are for water or babyfood, which we’re not using in this analysis, so we can ignore and just assign 1. Do a final check. both_days5 %&gt;% filter(is.na(ratio_FAFH_FAH)) # none-good ## # A tibble: 0 × 14 ## # ℹ 14 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;dbl&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup_FNDDS &lt;chr&gt;, ratio_FAFH_FAH &lt;dbl&gt; Food Cost Data There are two cost datasets: one for the years 2015-2016 and the other for the years 2017-2018. We need to merge these with the corresponding NHANES cohorts (2015-2016 and 2017-2018). First import and join the two datasets. Then, because the variable “price_100g” represents the food cost per 100 grams of food, we create a new variable that represents the food cost per 1 gram of food (which is what we want to use later on). # import 2015-2016 price data cost1516 &lt;- read_xlsx(&quot;data_inputs/ECONOMIC/food_prices/DATA/pp_national_average_prices_andi_v.1.30.2023.xlsx&quot;, sheet = &quot;PP-NAP1516&quot;) %&gt;% select(food_code, price_100gm) %&gt;% mutate(nhanes1516 = 1) # import 2017-2018 cost1718 &lt;- read_xlsx(&quot;data_inputs/ECONOMIC/food_prices/DATA/pp_national_average_prices_andi_v.1.30.2023.xlsx&quot;, sheet = &quot;PP-NAP1718&quot;) %&gt;% select(food_code, price_100gm) %&gt;% mutate(nhanes1516 = 0) # combine price datasets price_comb &lt;- rbind(cost1516, cost1718) %&gt;% mutate(price_per_gram = price_100gm / 100) # create price_per_gram var Then, join with both_days and check for missing values. We also calculate two variables, two_digits and three_digits, that represent the first two and three digits, respectively, of the NHANES FNDDS food code. The beginning digits of the food code correspond with different food categorizations created by the USDA. These variables will be used later. # create new nhanes cycle variable both_days6 &lt;- both_days5 %&gt;% mutate(nhanes1516 = ifelse(nhanes_cycle == &quot;2015-2016&quot;, 1, 0)) # join with food data both_days7 &lt;- left_join(both_days6, price_comb, by = c(&quot;foodcode&quot; = &quot;food_code&quot;, &quot;nhanes1516&quot;)) %&gt;% mutate(foodcode = as.character(foodcode), two_digits = as.numeric(substr(foodcode, 1, 2)), #first two digits of fndds foodcode three_digits = as.numeric(substr(foodcode, 1, 3))) #first three digits of fndds foodcode # how many are missing price data? both_days7 %&gt;% filter(is.na(price_per_gram)) %&gt;% head() ## # A tibble: 6 × 19 ## seqn daysintake reliable line foodcode grams description foodsource nhanes_cycle dayrec added_sugar ssb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83734 2 1 4 27510233 225 Cheeseburg… Other 2015-2016 2 1.24 0 ## 2 83735 1 1 3 27540250 242 Chicken fi… Other 2015-2016 1 2.08 0 ## 3 83737 2 1 1 55200070 80 Waffle, wh… Grocery 2015-2016 1 0.62 0 ## 4 83737 2 1 1 32130830 77 Egg omelet… Grocery 2015-2016 2 0 0 ## 5 83742 2 1 15 58146391 133. Pasta with… Other 2015-2016 1 0 0 ## 6 83742 2 1 16 58146301 133. Pasta with… Other 2015-2016 1 0.15 0 ## # ℹ 7 more variables: Foodgroup_FNDDS &lt;chr&gt;, ratio_FAFH_FAH &lt;dbl&gt;, nhanes1516 &lt;dbl&gt;, price_100gm &lt;dbl&gt;, ## # price_per_gram &lt;dbl&gt;, two_digits &lt;dbl&gt;, three_digits &lt;dbl&gt; both_days7 %&gt;% filter(is.na(price_100gm)) %&gt;% select(foodcode, description, Foodgroup_FNDDS) %&gt;% distinct() %&gt;% head() ## # A tibble: 6 × 3 ## foodcode description Foodgroup_FNDDS ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 27510233 Cheeseburger, 1 medium patty, with condiments, on bun, from fast food / restauran… pf_redm ## 2 27540250 Chicken fillet, broiled, sandwich with cheese, on whole wheat roll, with lettuce,… pf_poultry ## 3 55200070 Waffle, whole grain, reduced fat, from frozen gr_refined ## 4 32130830 Egg omelet or scrambled egg, with meat and dark-green vegetables, fat added in co… pf_egg ## 5 58146391 Pasta with cream sauce and added vegetables, restaurant gr_refined ## 6 58146301 Pasta with tomato-based sauce, and added vegetables, restaurant gr_refined There are a fair number of missing values, so we are going to calculate the average price for each food group (determined by first two digits of FNDDS food code) x foodsource (grocery vs not) combination, and then use these food group-level averages for the missing values (i.e., impute). Create a dataset called imputed_price that contains the average prices for each food group x food source combination. imputed_price &lt;- both_days7 %&gt;% select(seqn, line, foodcode, two_digits, foodsource, price_per_gram) %&gt;% distinct() %&gt;% group_by(two_digits, foodsource) %&gt;% summarise(price_g_group_mean = mean(price_per_gram, na.rm = TRUE), price_g_group_median = median(price_per_gram, na.rm = TRUE), price_g_group_sd = sd(price_per_gram, na.rm = TRUE)) ## `summarise()` has grouped output by &#39;two_digits&#39;. You can override using the `.groups` argument. Then, merge with both_days and calculate a new variable, price_per_gram, that replaces any missing price value with the group median. # join imputed prices with food data both_days8 &lt;- left_join(both_days7, imputed_price, by = c(&quot;two_digits&quot;, &quot;foodsource&quot;)) # insert food_group median price if missing both_days9 &lt;- both_days8 %&gt;% mutate(price_per_gram = ifelse(is.na(price_per_gram), price_g_group_median, price_per_gram)) %&gt;% ungroup() # check if any missing price per gram (shouldn&#39;t be) both_days9 %&gt;% filter(is.na(price_per_gram)) #none-good ## # A tibble: 0 × 22 ## # ℹ 22 variables: seqn &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;chr&gt;, grams &lt;dbl&gt;, ## # description &lt;chr&gt;, foodsource &lt;chr&gt;, nhanes_cycle &lt;chr&gt;, dayrec &lt;dbl&gt;, added_sugar &lt;dbl&gt;, ssb &lt;dbl&gt;, ## # Foodgroup_FNDDS &lt;chr&gt;, ratio_FAFH_FAH &lt;dbl&gt;, nhanes1516 &lt;dbl&gt;, price_100gm &lt;dbl&gt;, price_per_gram &lt;dbl&gt;, ## # two_digits &lt;dbl&gt;, three_digits &lt;dbl&gt;, price_g_group_mean &lt;dbl&gt;, price_g_group_median &lt;dbl&gt;, ## # price_g_group_sd &lt;dbl&gt; Tidy up the global environment. rm(list=setdiff(ls(), c(&quot;both_days9&quot;, &quot;my_date&quot;))) Mixed Dishes We want to obtain the food price of whole foods that correspond with the food groups in the DGA dietary patterns. Therefore, we do not want to use the prices of “mixed foods” that typically represent larger dishes that incorporate many different food groups and is thus not a good representation of whole foods. To deal with this, we use a dataset that identifies FNDDS food code prefixes that represent “mixed dishes”. We use this data to categorize food codes into mixed vs. non-mixed foods, and then later stratify our results by this categorization. See Section XX to see how these mixed dish codes were determined. mixed &lt;- read_csv(&quot;data_inputs/DIET/dietary_intake/DATA/raw_data/mixed/mixed_dishes_100923.csv&quot;) %&gt;% select(-foodcode_desc) ## Rows: 13 Columns: 3 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): foodcode_desc ## dbl (2): foodcode_prefix, mixed_dish ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Some of the categorizations are for prefixes with two digits, and some are for prefixes with three digits. mixed_2dig &lt;- mixed %&gt;% filter(!(foodcode_prefix %in% c(416, 418, 419, 423))) mixed_3dig &lt;- mixed %&gt;% filter(foodcode_prefix %in% c(416, 418, 419, 423)) %&gt;% rename(three_digits = foodcode_prefix) First, join both_days with the two digits, and then the three digits. Then, create an indicator variable called “mixed_dish” that we can stratify by later. both_days10 &lt;- both_days9 %&gt;% left_join(mixed_2dig, by = c(&quot;two_digits&quot; = &quot;foodcode_prefix&quot;)) both_days11 &lt;- both_days10 %&gt;% rows_patch(mixed_3dig, unmatched = &quot;ignore&quot;) %&gt;% mutate(mixed_dish = ifelse(is.na(mixed_dish), 0, mixed_dish)) ## Matching, by = &quot;three_digits&quot; Check if everything merged correctly. both_days11 %&gt;% filter(mixed_dish == 1) %&gt;% select(two_digits) %&gt;% distinct() %&gt;% arrange(two_digits) ## # A tibble: 11 × 1 ## two_digits ## &lt;dbl&gt; ## 1 27 ## 2 28 ## 3 32 ## 4 33 ## 5 41 ## 6 42 ## 7 58 ## 8 59 ## 9 76 ## 10 77 ## 11 78 # looks good Lastly, save a copy of this temporary dataset in case we need it for debugging later. saveRDS(both_days11, &quot;data_inputs/IMPACT_FACTORS/temp_data/both_days11_cost.rds&quot;) Tidy up the global environment. rm(list=setdiff(ls(), c(&quot;both_days11&quot;, &quot;my_date&quot;))) 5.1.2 Calculate Average Food Cost, Per FNDDS Food Code Now, we will calculate the average food cost per 1 gram for each FNDDS food code. This process includes aggregating and summarizing the diet dataset. # keep this commented out unless you are starting the script from here # both_days11 &lt;- read_rds(&quot;data_inputs/IMPACT_FACTORS/temp_data/both_days11_cost.rds&quot;) # my_date &lt;- Sys.Date() First, select the variables we need to eventually calculate the cost impact factors. my_price_table &lt;- both_days11 %&gt;% select(seqn, dayrec, line, foodcode, description, Foodgroup_FNDDS, foodsource, ratio_FAFH_FAH, price_per_gram, mixed_dish, grams) %&gt;% distinct() %&gt;% arrange(seqn, dayrec, line) Then, import the food-level consumed, inedible, and wasted amounts that was calculated in the previous Section XXX and join with my_price table. These values were calculated in the previous section because the inedible and wasted coefficients are at the FCID-level, which is the same level that the environmental impacts are at. # import fndds_flw &lt;- read_rds(&quot;data_inputs/IMPACT_FACTORS/temp_data/fndds_flw.rds&quot;) %&gt;% mutate(foodcode = as.character(foodcode)) # join my_price_table1 &lt;- left_join(my_price_table, fndds_flw, by = c(&quot;seqn&quot;, &quot;dayrec&quot;, &quot;line&quot;, &quot;foodcode&quot;, &quot;description&quot;)) # look at missing my_price_table1 %&gt;% filter(is.na(inedible_amt_FNDDS) | is.na(wasted_amt_FNDDS)) ## # A tibble: 0 × 14 ## # ℹ 14 variables: seqn &lt;dbl&gt;, dayrec &lt;dbl&gt;, line &lt;dbl&gt;, foodcode &lt;chr&gt;, description &lt;chr&gt;, ## # Foodgroup_FNDDS &lt;chr&gt;, foodsource &lt;chr&gt;, ratio_FAFH_FAH &lt;dbl&gt;, price_per_gram &lt;dbl&gt;, mixed_dish &lt;dbl&gt;, ## # grams &lt;dbl&gt;, consumed_amt_FNDDS &lt;dbl&gt;, inedible_amt_FNDDS &lt;dbl&gt;, wasted_amt_FNDDS &lt;dbl&gt; Now, we need to adjust for the difference in price for food purchased at the grocery store vs. not purchased there. We do this by multiplying the food-level FAFH-FAH ratio by the food price/1g rate if the food source is “Other” (i.e., not grocery). We also need to calculate the total price for the amounts of food consumed (price_impact_per_foodcode_Consumed). # adjust price for FAFH # if food source is &#39;other&#39;, then multiple price by fah/fafh ratio my_price_table2 &lt;- my_price_table1 %&gt;% mutate(price_per_gram_adjusted = ifelse(foodsource == &quot;Other&quot;, price_per_gram * ratio_FAFH_FAH, price_per_gram), price_impact_per_foodcode_Consumed = consumed_amt_FNDDS * price_per_gram_adjusted) Now, we want to calculate the total amount of money spent on each FNDDS foodcode, per person, per day. This is necessary because for some participants, they consumed a given FNDDS foodcode multiple times in the same day, and we want to combine these so each FNDDS food code only has one corresponding daily price. For example, if someone had 100 grams of coffee in the morning and then another 75 grams in the afternoon, we want to get the price for 175 grams of coffee consumed that day. # Calculate total price per day, per person price_impact_total &lt;- my_price_table2 %&gt;% group_by(seqn, foodcode, dayrec, mixed_dish) %&gt;% summarise(price_per_day_Consumed = sum(price_impact_per_foodcode_Consumed), consumed_per_day = sum(consumed_amt_FNDDS), inedible_per_day = sum(inedible_amt_FNDDS), wasted_per_day = sum(wasted_amt_FNDDS)) ## `summarise()` has grouped output by &#39;seqn&#39;, &#39;foodcode&#39;, &#39;dayrec&#39;. You can override using the `.groups` ## argument. Transform dataset to wide format. price_wide_total &lt;- pivot_wider(price_impact_total, names_from = c(dayrec), values_from = c(price_per_day_Consumed, consumed_per_day, inedible_per_day, wasted_per_day)) Because some participants have 2 days of dietary recall, we need to calculate an average price for each foodcode, per particpant. If a participant only has 1 day of recall, then we use that to represent the average. To calculate the average, we first need to determine how many days of recall each particpant has. # calculate # days of recall both_days11 %&gt;% select(reliable) %&gt;% table() ## reliable ## 1 4 ## 420721 7623 daysofintake &lt;- both_days11 %&gt;% select(seqn, daysintake, reliable) %&gt;% distinct() # join price_wide_total1 &lt;- price_wide_total %&gt;% left_join(daysofintake, by = &quot;seqn&quot;) ## Warning in left_join(., daysofintake, by = &quot;seqn&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 10171 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. # check missing price_wide_total1 %&gt;% filter(daysintake == 1 &amp; is.na(consumed_per_day_1)) %&gt;% head() ## # A tibble: 6 × 13 ## # Groups: seqn, foodcode [6] ## seqn foodcode mixed_dish price_per_day_Consumed_2 price_per_day_Consumed_1 consumed_per_day_2 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 84306 11000000 0 NA NA NA ## 2 85182 11000000 0 NA NA NA ## 3 85616 11000000 0 NA NA NA ## 4 86025 11000000 0 NA NA NA ## 5 86408 11000000 0 NA NA NA ## 6 86704 11000000 0 NA NA NA ## # ℹ 7 more variables: consumed_per_day_1 &lt;dbl&gt;, inedible_per_day_2 &lt;dbl&gt;, inedible_per_day_1 &lt;dbl&gt;, ## # wasted_per_day_2 &lt;dbl&gt;, wasted_per_day_1 &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt; Now, we have to fill in some 0s to properly calculate averages later on. If a participant has 2 days of intake and their corresponding price for day 1 or day 2 is missing (NA), then we need to replace those NAs with 0s, because in this case, the data aren’t “missing”, the participant just didn’t consume/spend money on that food that day. # add 0s when appropriate price_wide_total2 &lt;- price_wide_total1 %&gt;% mutate( # day 2 price_per_day_Consumed_2 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_2), 0, price_per_day_Consumed_2), consumed_per_day_2 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_2), 0, consumed_per_day_2), wasted_per_day_2 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_2), 0, wasted_per_day_2), inedible_per_day_2 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_2), 0, inedible_per_day_2), # day1 price_per_day_Consumed_1 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_1), 0, price_per_day_Consumed_1), consumed_per_day_1 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_1), 0, consumed_per_day_1), wasted_per_day_1 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_1), 0, wasted_per_day_1), inedible_per_day_1 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_1), 0, inedible_per_day_1)) Calculate the average total price of consumed food at the FNDDS foodcode-level for each person. This will give us the data we need to calculate the cost impact factors in the next section. price_wide_total3 &lt;- price_wide_total2 %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate(price_total_avg_Consumed = mean(c(price_per_day_Consumed_1, price_per_day_Consumed_2), na.rm = TRUE), consumed_total_avg = mean(c(consumed_per_day_1, consumed_per_day_2), na.rm = TRUE), inedible_total_avg = mean(c(inedible_per_day_1, inedible_per_day_2), na.rm = TRUE), wasted_total_avg = mean(c(wasted_per_day_1, wasted_per_day_2), na.rm = TRUE)) %&gt;% select(seqn, foodcode, mixed_dish, price_total_avg_Consumed, consumed_total_avg, inedible_total_avg, wasted_total_avg) We also want to calculate the same thing as above, but additionally stratified by food source (grocery vs. non-grocery). So we do the same calculations above, but additionally group by “foodsource”. # STRATIFIED BY FAH VS FAFH # Calculate fah and fafh price, per person price_impact_split &lt;- my_price_table2 %&gt;% group_by(seqn, foodcode, dayrec, foodsource, mixed_dish) %&gt;% summarise(price_per_day_Consumed = sum(price_impact_per_foodcode_Consumed), consumed_per_day = sum(consumed_amt_FNDDS), inedible_per_day = sum(inedible_amt_FNDDS), wasted_per_day = sum(wasted_amt_FNDDS)) ## `summarise()` has grouped output by &#39;seqn&#39;, &#39;foodcode&#39;, &#39;dayrec&#39;, &#39;foodsource&#39;. You can override using the ## `.groups` argument. Calculate the average of Day 1 and Day 2 prices for each FNDDS foodcode. price_wide_split &lt;- pivot_wider(price_impact_split, names_from = c(foodsource, dayrec), values_from = c(price_per_day_Consumed, consumed_per_day, inedible_per_day, wasted_per_day)) # join with days of intake dataset price_wide_split1 &lt;- price_wide_split %&gt;% left_join(daysofintake, by = &quot;seqn&quot;) ## Warning in left_join(., daysofintake, by = &quot;seqn&quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 10171 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. # check price_wide_split1 %&gt;% filter(daysintake == 1 &amp; is.na(consumed_per_day_Other_1)) #good ## # A tibble: 17,721 × 21 ## # Groups: seqn, foodcode [17,721] ## seqn foodcode mixed_dish price_per_day_Consumed_Other_2 price_per_day_Consumed_G…¹ price_per_day_Consum…² ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 83735 12310350 0 NA 0.0719 NA ## 2 83735 54301100 0 NA 0.161 NA ## 3 83735 58106602 1 NA 0.725 NA ## 4 83735 71405040 0 NA 0.355 NA ## 5 83735 91705300 0 NA 0.131 NA ## 6 83735 91705310 0 NA 0.253 NA ## 7 83735 91745010 0 NA 0.0791 NA ## 8 83735 92410370 0 NA 0.521 NA ## 9 83735 94100100 0 NA 0.0634 NA ## 10 83750 11112110 0 NA 0.458 NA ## # ℹ 17,711 more rows ## # ℹ abbreviated names: ¹​price_per_day_Consumed_Grocery_1, ²​price_per_day_Consumed_Grocery_2 ## # ℹ 15 more variables: price_per_day_Consumed_Other_1 &lt;dbl&gt;, consumed_per_day_Other_2 &lt;dbl&gt;, ## # consumed_per_day_Grocery_1 &lt;dbl&gt;, consumed_per_day_Grocery_2 &lt;dbl&gt;, consumed_per_day_Other_1 &lt;dbl&gt;, ## # inedible_per_day_Other_2 &lt;dbl&gt;, inedible_per_day_Grocery_1 &lt;dbl&gt;, inedible_per_day_Grocery_2 &lt;dbl&gt;, ## # inedible_per_day_Other_1 &lt;dbl&gt;, wasted_per_day_Other_2 &lt;dbl&gt;, wasted_per_day_Grocery_1 &lt;dbl&gt;, ## # wasted_per_day_Grocery_2 &lt;dbl&gt;, wasted_per_day_Other_1 &lt;dbl&gt;, daysintake &lt;dbl&gt;, reliable &lt;dbl&gt; # add 0s when appropriate price_wide_split2 &lt;- price_wide_split1 %&gt;% mutate( # TWO DAYS OF INTAKE # day 2 - Other price_per_day_Consumed_Other_2 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_Other_2), 0, price_per_day_Consumed_Other_2), consumed_per_day_Other_2 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_Other_2), 0, consumed_per_day_Other_2), wasted_per_day_Other_2 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_Other_2), 0, wasted_per_day_Other_2), inedible_per_day_Other_2 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_Other_2), 0, inedible_per_day_Other_2), # day1 - Other price_per_day_Consumed_Other_1 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_Other_1), 0, price_per_day_Consumed_Other_1), consumed_per_day_Other_1 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_Other_1), 0, consumed_per_day_Other_1), wasted_per_day_Other_1 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_Other_1), 0, wasted_per_day_Other_1), inedible_per_day_Other_1 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_Other_1), 0, inedible_per_day_Other_1), # day 2 - Grocery price_per_day_Consumed_Grocery_2 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_Grocery_2), 0, price_per_day_Consumed_Grocery_2), consumed_per_day_Grocery_2 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_Grocery_2), 0, consumed_per_day_Grocery_2), wasted_per_day_Grocery_2 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_Grocery_2), 0, wasted_per_day_Grocery_2), inedible_per_day_Grocery_2 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_Grocery_2), 0, inedible_per_day_Grocery_2), # day1 - Grocery price_per_day_Consumed_Grocery_1 = ifelse(daysintake == 2 &amp; is.na(price_per_day_Consumed_Grocery_1), 0, price_per_day_Consumed_Grocery_1), consumed_per_day_Grocery_1 = ifelse(daysintake == 2 &amp; is.na(consumed_per_day_Grocery_1), 0, consumed_per_day_Grocery_1), wasted_per_day_Grocery_1 = ifelse(daysintake == 2 &amp; is.na(wasted_per_day_Grocery_1), 0, wasted_per_day_Grocery_1), inedible_per_day_Grocery_1 = ifelse(daysintake == 2 &amp; is.na(inedible_per_day_Grocery_1), 0, inedible_per_day_Grocery_1), # ONE DAY OF INTAKE # day1 - Other price_per_day_Consumed_Other_1 = ifelse(daysintake == 1 &amp; is.na(price_per_day_Consumed_Other_1), 0, price_per_day_Consumed_Other_1), consumed_per_day_Other_1 = ifelse(daysintake == 1 &amp; is.na(consumed_per_day_Other_1), 0, consumed_per_day_Other_1), wasted_per_day_Other_1 = ifelse(daysintake == 1 &amp; is.na(wasted_per_day_Other_1), 0, wasted_per_day_Other_1), inedible_per_day_Other_1 = ifelse(daysintake == 1 &amp; is.na(inedible_per_day_Other_1), 0, inedible_per_day_Other_1), # day1 - Grocery price_per_day_Consumed_Grocery_1 = ifelse(daysintake == 1 &amp; is.na(price_per_day_Consumed_Grocery_1), 0, price_per_day_Consumed_Grocery_1), consumed_per_day_Grocery_1 = ifelse(daysintake == 1 &amp; is.na(consumed_per_day_Grocery_1), 0, consumed_per_day_Grocery_1), wasted_per_day_Grocery_1 = ifelse(daysintake == 1 &amp; is.na(wasted_per_day_Grocery_1), 0, wasted_per_day_Grocery_1), inedible_per_day_Grocery_1 = ifelse(daysintake == 1 &amp; is.na(inedible_per_day_Grocery_1), 0, inedible_per_day_Grocery_1)) # summarize at foodcode-level for each person price_wide_split3 &lt;- price_wide_split2 %&gt;% ungroup() %&gt;% rowwise() %&gt;% mutate( #FAH (Grocery) price_fah_avg_Consumed = mean(c(price_per_day_Consumed_Grocery_1, price_per_day_Consumed_Grocery_2), na.rm = TRUE), consumed_fah_avg = mean(c(consumed_per_day_Grocery_1, consumed_per_day_Grocery_2), na.rm = TRUE), inedible_fah_avg = mean(c(inedible_per_day_Grocery_1, inedible_per_day_Grocery_2), na.rm = TRUE), wasted_fah_avg = mean(c(wasted_per_day_Grocery_1, wasted_per_day_Grocery_2), na.rm = TRUE), #FAFH (Other) price_fafh_avg_Consumed = mean(c(price_per_day_Consumed_Other_1, price_per_day_Consumed_Other_2), na.rm = TRUE), consumed_fafh_avg = mean(c(consumed_per_day_Other_1, consumed_per_day_Other_2), na.rm = TRUE), inedible_fafh_avg = mean(c(inedible_per_day_Other_1, inedible_per_day_Other_2), na.rm = TRUE), wasted_fafh_avg = mean(c(wasted_per_day_Other_1, wasted_per_day_Other_2), na.rm = TRUE)) %&gt;% select(seqn, foodcode, mixed_dish, price_fah_avg_Consumed, consumed_fah_avg, inedible_fah_avg, wasted_fah_avg, price_fafh_avg_Consumed, consumed_fafh_avg, inedible_fafh_avg, wasted_fafh_avg) Join the total price and the split price averages into one dataset. # join price_wide_comb &lt;- full_join(price_wide_total3, price_wide_split3, by = c(&quot;seqn&quot;, &quot;foodcode&quot;, &quot;mixed_dish&quot;)) ## Warning in full_join(price_wide_total3, price_wide_split3, by = c(&quot;seqn&quot;, : Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 10171 of `x` matches multiple rows in `y`. ## ℹ Row 10171 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = &quot;many-to-many&quot;` to silence this warning. # create foodcode-to-food group &quot;mapping&quot; to join with map &lt;- both_days11 %&gt;% ungroup() %&gt;% select(foodcode, Foodgroup_FNDDS) %&gt;% distinct() # join price_wide_comb1 &lt;- left_join(price_wide_comb, map, by = &quot;foodcode&quot;) %&gt;% relocate(Foodgroup_FNDDS, .after = mixed_dish) # add up prices by food group price_wide_comb2 &lt;- price_wide_comb1 %&gt;% group_by(seqn, Foodgroup_FNDDS, mixed_dish) %&gt;% summarise( # Consumed price_total_sum_Consumed = sum(price_total_avg_Consumed), consumed_total_sum = sum(consumed_total_avg), price_fah_sum_Consumed = sum(price_fah_avg_Consumed), consumed_fah_sum = sum(consumed_fah_avg), price_fafh_sum_Consumed = sum(price_fafh_avg_Consumed), consumed_fafh_sum = sum(consumed_fafh_avg), # Inedible inedible_total_sum = sum(inedible_total_avg), inedible_fah_sum = sum(inedible_fah_avg), inedible_fafh_sum = sum(inedible_fafh_avg), # Wasted wasted_total_sum = sum(wasted_total_avg), wasted_fah_sum = sum(wasted_fah_avg), wasted_fafh_sum = sum(wasted_fafh_avg)) ## `summarise()` has grouped output by &#39;seqn&#39;, &#39;Foodgroup_FNDDS&#39;. You can override using the `.groups` ## argument. # transform to wide price_wide_comb3 &lt;- price_wide_comb2 %&gt;% pivot_wider(id_cols = seqn, names_from = c(Foodgroup_FNDDS, mixed_dish), values_from = -c(seqn, Foodgroup_FNDDS, mixed_dish)) %&gt;% replace(is.na(.), 0) Export dataset to the temporary folder, so it can be used to calculate the impact factors in the next section. write_rds(price_wide_comb3, &quot;data_inputs/IMPACT_FACTORS/temp_data/price_input_dat.rds&quot;) "],["calculate-cost-environment-and-social-impact-factors.html", "Chapter 6 Calculate Cost, Environment, and Social Impact Factors 6.1 Prepare Data 6.2 Cost Impact Factors 6.3 Environmental &amp; Social Impact Factors 6.4 Finalize Impact Factors 6.5 Calculate Inedible and Wasted Proportions 6.6 Export Data", " Chapter 6 Calculate Cost, Environment, and Social Impact Factors This chapter walks you through all of the R code used to calculate the impact factors that are used in the final model. Additionally, the food group-level inedible and wasted proportions are calculated at the end. Note that you must first open the ‘methods_manual’ R project before running this script or else it will not work. First, let’s set up our environment. # check working directory getwd() ## [1] &quot;/Users/bmb73/Library/CloudStorage/Box-Box/lasting_aim_3/model development/methods_manual&quot; # SET UP ----- rm(list = ls()) options(scipen=999) library(tidyverse) library(readxl) library(survey) library(bookdown) my_date &lt;- Sys.Date() 6.1 Prepare Data First, we need to import the NHANES dataset to get the survey weight variables that are necessary to incorporate when calculating mean estimates from NHANES data. See more information here: https://wwwn.cdc.gov/nchs/nhanes/tutorials/weighting.aspx # import subgroup-seqn mapping nhanes &lt;- read_rds(&quot;data_inputs/DIET/dietary_intake/DATA/clean_data/nhanes1518_adj_clean_wide.rds&quot;) # select subset of variables subgroup_dat &lt;- nhanes %&gt;% select(SEQN, subgroup, SDMVPSU, SDMVSTRA, wtnew, inAnalysis) Then, create a cleaning function that will be used to clean the output summary data from the “svymean” function used below. clean_func &lt;- function(x, y){ x1 &lt;- x %&gt;% select(subgroup, contains(y)) # split up into mean and se my_se &lt;- x1 %&gt;% select(subgroup, starts_with(&quot;se.&quot;)) my_mean &lt;- x1 %&gt;% select(subgroup, !starts_with(&quot;se.&quot;)) # transform both datsets to long my_se_long &lt;- my_se %&gt;% pivot_longer(cols = starts_with(&quot;se.&quot;), names_to = &quot;food&quot;, names_prefix = c(&quot;se.&quot;), values_to = paste0(y, &quot;_se&quot;)) my_mean_long &lt;- my_mean %&gt;% pivot_longer(cols = !subgroup, names_to = &quot;food&quot;, values_to = paste0(y, &quot;_mean&quot;)) # join allfoods_bysub_long &lt;- left_join(my_mean_long, my_se_long, by = c(&quot;subgroup&quot;, &quot;food&quot;)) # fix names dat &lt;- allfoods_bysub_long %&gt;% mutate(food_type = case_when(grepl(&quot;fah&quot;, food) ~ &quot;Grocery&quot;, grepl(&quot;fafh&quot;, food) ~ &quot;Non-Grocery&quot;, grepl(&quot;total&quot;, food) ~ &quot;Total&quot;)) %&gt;% mutate(food = gsub(&quot;.*_sum_&quot;, &quot;&quot;, food)) %&gt;% arrange(subgroup, food) print(dat) } Import the data that were cleaned in the last few chapters. # diet intake data # both_days &lt;- read_rds(&quot;data_inputs/IMPACT_FACTORS/temp_data/both_days15_env.rds&quot;) # price data price_dat &lt;- read_rds(&quot;data_inputs/IMPACT_FACTORS/temp_data/price_input_dat.rds&quot;) # environment and social data enviro_dat &lt;- read_rds(&quot;data_inputs/IMPACT_FACTORS/temp_data/enviro_input_dat.rds&quot;) 6.2 Cost Impact Factors 6.2.1 Cost Impact Factors, by Food, by Subgroup Join the price data with the NHANES subgroup data. # full join price_dat1 &lt;- full_join(price_dat, subgroup_dat, by = c(&quot;seqn&quot; = &quot;SEQN&quot;)) Define the “survey design” for the cost dataset. Survey designs are a unique part of the R ‘survey’ package. Set the appropriate weight variables. Then, subset the dataset to only include participants who are eligible to be in the sample (i.e., inAnalysis == 1). Chapter XXX explains more about these weight and inAnalysis variables. # Define survey design for cost dataset my_cost_svy &lt;- svydesign(data=price_dat1, id=~SDMVPSU, # Masked Variance Unit Pseudo-PSU strata=~SDMVSTRA, # Masked Variance Unit Pseudo-Stratum weights=~wtnew, # New sample weight nest=TRUE) # Create a survey design object for the subset of interest my_cost_svy_sub &lt;- subset(my_cost_svy, inAnalysis==1) 6.2.1.1 Calculate Daily Mean Cost, For The Whole Sample Apply the ‘svymean’ function in order to calculate the mean daily cost for each food group, using the entire sample. allfoods_cost &lt;- svymean(reformulate(names(price_dat1) %&gt;% str_subset(&quot;price&quot;)), my_cost_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_cost) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_cost)) colnames(allfoods_cost) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_cost)) 6.2.1.2 Calculate Daily Mean Consumed, Inedible, and Wasted Amounts (FNDDS-Level), For The Whole Sample Apply the ‘svymean’ function in order to calculate the mean daily consumed, inedible, and wasted amounts of each food group, using the entire sample. 6.2.1.2.1 Consumed allfoods_cost_consumed &lt;- svymean(reformulate(names(price_dat1) %&gt;% str_subset(&quot;consumed&quot;)), my_cost_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_cost_consumed) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_cost_consumed)) colnames(allfoods_cost_consumed) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_cost_consumed)) 6.2.1.2.2 Inedible allfoods_cost_inedible &lt;- svymean(reformulate(names(price_dat1) %&gt;% str_subset(&quot;inedible&quot;)), my_cost_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_cost_inedible) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_cost_inedible)) colnames(allfoods_cost_inedible) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_cost_inedible)) 6.2.1.2.3 Wasted allfoods_cost_wasted &lt;- svymean(reformulate(names(price_dat1) %&gt;% str_subset(&quot;wasted&quot;)), my_cost_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_cost_wasted) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_cost_wasted)) colnames(allfoods_cost_wasted) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_cost_wasted)) 6.2.1.3 Calculate Daily Mean Cost, For All 48 Subgroups Apply the ‘svyby’ function in order to calculate the mean daily cost for each food group, separately for each of the 48 population subgroups. allfoods_cost_bysub &lt;- svyby(reformulate(names(price_dat1) %&gt;% str_subset(&quot;price&quot;)), ~subgroup, my_cost_svy_sub, svymean) Combine the mean cost values for the whole sample (i.e., subgroup 0) with the mean cost values for subgroups 1-48. # bind with subgroup 0 allfoods_cost_bysub1 &lt;- rbind(allfoods_cost, allfoods_cost_bysub) 6.2.1.4 Calculate Daily Mean Consumed, Inedible, and Wasted Amounts (FNDDS-Level), For All 48 Subgroups Apply the ‘svyby’ function in order to calculate the mean daily consumed, inedible, and wasted amounts of each food group, separately for each of the 48 population subgroups. Then, combine the mean values for the whole sample (i.e., subgroup 0) with the mean values for subgroups 1-48. 6.2.1.4.1 Consumed allfoods_cost_consumed_bysub &lt;- svyby(reformulate(names(price_dat1) %&gt;% str_subset(&quot;consumed&quot;)), ~subgroup, my_cost_svy_sub, svymean) # bind with subgroup 0 allfoods_cost_consumed_bysub1 &lt;- rbind(allfoods_cost_consumed, allfoods_cost_consumed_bysub) 6.2.1.4.2 Inedible allfoods_cost_inedible_bysub &lt;- svyby(reformulate(names(price_dat1) %&gt;% str_subset(&quot;inedible&quot;)), ~subgroup, my_cost_svy_sub, svymean) # bind with subgroup 0 allfoods_cost_inedible_bysub1 &lt;- rbind(allfoods_cost_inedible, allfoods_cost_inedible_bysub) 6.2.1.4.3 Wasted allfoods_cost_wasted_bysub &lt;- svyby(reformulate(names(price_dat1) %&gt;% str_subset(&quot;wasted&quot;)), ~subgroup, my_cost_svy_sub, svymean) # bind with subgroup 0 allfoods_cost_wasted_bysub1 &lt;- rbind(allfoods_cost_wasted, allfoods_cost_wasted_bysub) 6.2.1.5 Clean Output Data Apply the cleaning function (defined above) to the mean cost dataset. # APPLY FUNCTION TO COST DAT cost_dat &lt;- clean_func(x = allfoods_cost_bysub1, y = &quot;price&quot;) ## # A tibble: 5,292 × 5 ## subgroup food price_mean price_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar_0 0.164 0.00690 Total ## 2 0 Consumed_added_sugar_0 0.0826 0.00345 Grocery ## 3 0 Consumed_added_sugar_0 0.0811 0.00494 Non-Grocery ## 4 0 Consumed_babyfood_0 0.0000216 0.0000184 Total ## 5 0 Consumed_babyfood_0 0.0000216 0.0000184 Grocery ## 6 0 Consumed_babyfood_0 0 0 Non-Grocery ## 7 0 Consumed_babyfood_1 0.00117 0.00116 Total ## 8 0 Consumed_babyfood_1 0.00117 0.00116 Grocery ## 9 0 Consumed_babyfood_1 0 0 Non-Grocery ## 10 0 Consumed_dairy_tot_0 0.755 0.0244 Total ## # ℹ 5,282 more rows # MORE MANUAL CLEANING cost_dat1 &lt;- cost_dat %&gt;% mutate(intake_type = case_when(grepl(&quot;Consumed&quot;, food) ~ &quot;Consumed&quot;, grepl(&quot;Wasted&quot;, food) ~ &quot;Wasted&quot;, grepl(&quot;Inedible&quot;, food) ~ &quot;Inedible&quot;)) %&gt;% mutate(food = gsub(&quot;Consumed_|Wasted_|Inedible_&quot;, &quot;&quot;, food)) # MORE MANUAL CLEANING cost_dat2 &lt;- cost_dat1 %&gt;% mutate(mixed_dish = case_when(grepl(&quot;_0&quot;, food) ~ &quot;Non-Mixed&quot;, grepl(&quot;_1&quot;, food) ~ &quot;Mixed&quot;)) %&gt;% mutate(food = gsub(&quot;_0|_1&quot;, &quot;&quot;, food)) %&gt;% relocate(intake_type, food_type, mixed_dish, .after = food) %&gt;% arrange(intake_type, subgroup, food, food_type, mixed_dish) # examine cost_dat2 %&gt;% filter(food_type == &quot;Total&quot;) %&gt;% head() ## # A tibble: 6 × 7 ## subgroup food intake_type food_type mixed_dish price_mean price_se ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 added_sugar Consumed Total Non-Mixed 0.164 0.00690 ## 2 0 babyfood Consumed Total Mixed 0.00117 0.00116 ## 3 0 babyfood Consumed Total Non-Mixed 0.0000216 0.0000184 ## 4 0 dairy_tot Consumed Total Non-Mixed 0.755 0.0244 ## 5 0 fruit_exc_juice Consumed Total Mixed 0.0180 0.00207 ## 6 0 fruit_exc_juice Consumed Total Non-Mixed 0.420 0.0170 # pivot to wide cost_dat3 &lt;- cost_dat2 %&gt;% pivot_wider(names_from = intake_type, values_from = c(price_mean, price_se)) %&gt;% arrange(subgroup, food, food_type) Apply the cleaning function (defined above) to the mean consumed, inedible, and wasted datasets. # APPLY FUNCTION TO INTAKE DATASETS cost_consumed_dat &lt;- clean_func(x = allfoods_cost_consumed_bysub1, y = &quot;consumed&quot;) ## # A tibble: 5,292 × 5 ## subgroup food consumed_mean consumed_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar_0 16.8 0.571 Total ## 2 0 added_sugar_0 11.7 0.454 Grocery ## 3 0 added_sugar_0 5.11 0.304 Non-Grocery ## 4 0 babyfood_0 0.00712 0.00653 Total ## 5 0 babyfood_0 0.00712 0.00653 Grocery ## 6 0 babyfood_0 0 0 Non-Grocery ## 7 0 babyfood_1 0.185 0.184 Total ## 8 0 babyfood_1 0.185 0.184 Grocery ## 9 0 babyfood_1 0 0 Non-Grocery ## 10 0 dairy_tot_0 186. 5.90 Total ## # ℹ 5,282 more rows cost_wasted_dat &lt;- clean_func(x = allfoods_cost_wasted_bysub1, y = &quot;wasted&quot;) ## # A tibble: 5,292 × 5 ## subgroup food wasted_mean wasted_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar_0 7.16 0.294 Total ## 2 0 added_sugar_0 5.04 0.254 Grocery ## 3 0 added_sugar_0 2.13 0.124 Non-Grocery ## 4 0 babyfood_0 0.000775 0.000724 Total ## 5 0 babyfood_0 0.000775 0.000724 Grocery ## 6 0 babyfood_0 0 0 Non-Grocery ## 7 0 babyfood_1 0.0449 0.0447 Total ## 8 0 babyfood_1 0.0449 0.0447 Grocery ## 9 0 babyfood_1 0 0 Non-Grocery ## 10 0 dairy_tot_0 54.1 1.73 Total ## # ℹ 5,282 more rows cost_inedible_dat &lt;- clean_func(x = allfoods_cost_inedible_bysub1, y = &quot;inedible&quot;) ## # A tibble: 5,292 × 5 ## subgroup food inedible_mean inedible_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar_0 0.217 0.0228 Total ## 2 0 added_sugar_0 0.172 0.0193 Grocery ## 3 0 added_sugar_0 0.0450 0.00874 Non-Grocery ## 4 0 babyfood_0 0 0 Total ## 5 0 babyfood_0 0 0 Grocery ## 6 0 babyfood_0 0 0 Non-Grocery ## 7 0 babyfood_1 0.0475 0.0473 Total ## 8 0 babyfood_1 0.0475 0.0473 Grocery ## 9 0 babyfood_1 0 0 Non-Grocery ## 10 0 dairy_tot_0 1.72 0.251 Total ## # ℹ 5,282 more rows # join all 3 cost_intake_dat &lt;- left_join(cost_consumed_dat, cost_wasted_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;, &quot;food_type&quot;)) %&gt;% left_join(cost_inedible_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;, &quot;food_type&quot;)) # create mixed dish variable cost_intake_dat1 &lt;- cost_intake_dat %&gt;% mutate(mixed_dish = case_when(grepl(&quot;_0&quot;, food) ~ &quot;Non-Mixed&quot;, grepl(&quot;_1&quot;, food) ~ &quot;Mixed&quot;)) %&gt;% mutate(food = gsub(&quot;_0|_1&quot;, &quot;&quot;, food)) # join cost_final_dat &lt;- left_join(cost_dat3, cost_intake_dat1, by = c(&quot;subgroup&quot;, &quot;food&quot;, &quot;food_type&quot;, &quot;mixed_dish&quot;)) %&gt;% rename(fndds_consumed_mean = consumed_mean, fndds_consumed_se = consumed_se, fndds_wasted_mean = wasted_mean, fndds_wasted_se = wasted_se, fndds_inedible_mean = inedible_mean, fndds_inedible_se = inedible_se) 6.2.2 Cost Impact Factors, Per 100 Grams and Per 1 DGA Serving First, import the conversion units. units &lt;- read_csv(paste(&quot;data_inputs/FINAL/cleaned_raw_data/unit_conversions_&quot;, my_date, &quot;_FINAL.csv&quot;, sep=&quot;&quot;)) %&gt;% select(Food_group, Conversion_to_grams) ## Rows: 41 Columns: 4 ## ── Column specification ───────────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (3): Food_group, DGA_unit, Equation ## dbl (1): Conversion_to_grams ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # merge with units cost_final_dat1 &lt;- cost_final_dat %&gt;% left_join(units, by = c(&quot;food&quot; = &quot;Food_group&quot;)) cost_final_dat1 %&gt;% filter(is.na(Conversion_to_grams)) %&gt;% head() ## # A tibble: 0 × 13 ## # ℹ 13 variables: subgroup &lt;dbl&gt;, food &lt;chr&gt;, food_type &lt;chr&gt;, mixed_dish &lt;chr&gt;, price_mean_Consumed &lt;dbl&gt;, ## # price_se_Consumed &lt;dbl&gt;, fndds_consumed_mean &lt;dbl&gt;, fndds_consumed_se &lt;dbl&gt;, fndds_wasted_mean &lt;dbl&gt;, ## # fndds_wasted_se &lt;dbl&gt;, fndds_inedible_mean &lt;dbl&gt;, fndds_inedible_se &lt;dbl&gt;, Conversion_to_grams &lt;dbl&gt; Then, calculate the cost impact factors (i) per 100 grams and (ii) per DGA unit. To calculate the cost per 100 grams, you divide the daily mean cost of the food group by the daily amount of food consumed, and then multiply by 100. # calculate impact factors cost_final_dat2 &lt;- cost_final_dat1 %&gt;% rowwise() %&gt;% mutate(costper100gram_consumed = ifelse(fndds_consumed_mean == 0, 0, (price_mean_Consumed / fndds_consumed_mean) * 100), costperDGA_consumed = costper100gram_consumed * (Conversion_to_grams / 100)) # check cost_final_dat2 %&gt;% select(subgroup, food, food_type, mixed_dish, costperDGA_consumed) %&gt;% head() ## # A tibble: 6 × 5 ## # Rowwise: ## subgroup food food_type mixed_dish costperDGA_consumed ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 0 added_sugar Grocery Non-Mixed 0.0297 ## 2 0 added_sugar Non-Grocery Non-Mixed 0.0667 ## 3 0 added_sugar Total Non-Mixed 0.0410 ## 4 0 babyfood Grocery Mixed 0 ## 5 0 babyfood Grocery Non-Mixed 0 ## 6 0 babyfood Non-Grocery Mixed 0 6.3 Environmental &amp; Social Impact Factors 6.3.1 Environmental &amp; Social Impact Factors, by Food, by Subgroup Essentially the same steps that were used to calculate the cost impact factors are also used to calculate the environmental and social impact factors. First, define the “survey design” for the enviro dataset. Survey designs are a unique part of the R ‘survey’ package. Set the appropriate weight variables. Then, subset the dataset to only include participants who are eligible to be in the sample (i.e., inAnalysis == 1). Chapter XXX explains more about these weight and inAnalysis variables. # join enviro_dat1 &lt;- full_join(enviro_dat, subgroup_dat, by = c(&quot;seqn&quot; = &quot;SEQN&quot;)) # Define survey design for ghg dataset my_enviro_svy &lt;- svydesign(data=enviro_dat1, id=~SDMVPSU, # Masked Variance Unit Pseudo-PSU strata=~SDMVSTRA, # Masked Variance Unit Pseudo-Stratum weights=~wtnew, # New sample weight nest=TRUE) # Create a survey design object for the subset of interest my_enviro_svy_sub &lt;- subset(my_enviro_svy, inAnalysis==1) 6.3.1.1 Calculate Daily Mean Environment and Social Impacts, (i) For The Whole Sample, and (ii) For All 48 Subgroups 6.3.1.1.1 Greenhouse Gas Emissions (GHG) # CALCULATE GHG IMPACT (WHOLE SAMPLE) allfoods_ghg &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;ghg&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_ghg) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_ghg)) colnames(allfoods_ghg) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_ghg)) # CALCULATE GHG IMPACT, BY SUBGROUP allfoods_ghg_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;ghg&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_ghg_bysub1 &lt;- rbind(allfoods_ghg, allfoods_ghg_bysub) 6.3.1.1.2 Cumulative Energy Demand (CED) # CALCULATE CED IMPACT (WHOLE SAMPLE) allfoods_ced &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;ced&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_ced) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_ced)) colnames(allfoods_ced) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_ced)) # CALCULATE CED IMPACT, BY SUBGROUP allfoods_ced_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;ced&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_ced_bysub1 &lt;- rbind(allfoods_ced, allfoods_ced_bysub) 6.3.1.1.3 Water Scarcity # CALCULATE WATER IMPACT (WHOLE SAMPLE) allfoods_water &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;^water&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_water) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_water)) colnames(allfoods_water) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_water)) # CALCULATE WATER IMPACT, BY SUBGROUP allfoods_water_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;^water&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_water_bysub1 &lt;- rbind(allfoods_water, allfoods_water_bysub) 6.3.1.1.4 Bluewater Use # CALCULATE BLUEWATER IMPACT (WHOLE SAMPLE) allfoods_bluewater &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;bluewater&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_bluewater) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_bluewater)) colnames(allfoods_bluewater) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_bluewater)) # CALCULATE BLUEWATER IMPACT, BY SUBGROUP allfoods_bluewater_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;bluewater&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_bluewater_bysub1 &lt;- rbind(allfoods_bluewater, allfoods_bluewater_bysub) 6.3.1.1.5 Forced Labor Risk (FL) # CALCULATE FL IMPACT (WHOLE SAMPLE) allfoods_fl &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;fl&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_fl) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_fl)) colnames(allfoods_fl) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_fl)) # CALCULATE FL IMPACT, BY SUBGROUP allfoods_fl_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;fl&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_fl_bysub1 &lt;- rbind(allfoods_fl, allfoods_fl_bysub) 6.3.1.2 Calculate Daily Mean Consumed, Inedible, and Wasted Amounts (FCID-Level), For The Whole Sample Apply the ‘svymean’ function in order to calculate the mean daily consumed, inedible, and wasted amounts of each food group, using the entire sample. 6.3.1.2.1 Consumed # consumed allfoods_enviro_consumed &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;consumed&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_enviro_consumed) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_enviro_consumed)) colnames(allfoods_enviro_consumed) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_enviro_consumed)) 6.3.1.2.2 Inedible # inedible allfoods_enviro_inedible &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;inedible&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_enviro_inedible) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_enviro_inedible)) colnames(allfoods_enviro_inedible) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_enviro_inedible)) 6.3.1.2.3 Wasted # wasted allfoods_enviro_wasted &lt;- svymean(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;wasted&quot;)), my_enviro_svy_sub) %&gt;% as.data.frame() %&gt;% rownames_to_column(var = &quot;var&quot;) %&gt;% pivot_wider(names_from = var, values_from = c(mean, SE)) %&gt;% mutate(subgroup = 0) %&gt;% relocate(subgroup) # fix colnames colnames(allfoods_enviro_wasted) &lt;- gsub(&quot;mean_&quot;, &quot;&quot;, colnames(allfoods_enviro_wasted)) colnames(allfoods_enviro_wasted) &lt;- gsub(&quot;SE_&quot;, &quot;se.&quot;, colnames(allfoods_enviro_wasted)) 6.3.1.3 Calculate Daily Mean Consumed, Inedible, and Wasted Amounts (FCID-Level), For All 48 Subgroups Apply the ‘svyby’ function in order to calculate the mean daily consumed, inedible, and wasted amounts of each food group, separately for each of the 48 population subgroups. Then, combine the mean values for the whole sample (i.e., subgroup 0) with the mean values for subgroups 1-48. 6.3.1.3.1 Consumed allfoods_enviro_consumed_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;consumed&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_enviro_consumed_bysub1 &lt;- rbind(allfoods_enviro_consumed, allfoods_enviro_consumed_bysub) 6.3.1.3.2 Inedible # inedible allfoods_enviro_inedible_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;inedible&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_enviro_inedible_bysub1 &lt;- rbind(allfoods_enviro_inedible, allfoods_enviro_inedible_bysub) 6.3.1.3.3 Wasted # wasted allfoods_enviro_wasted_bysub &lt;- svyby(reformulate(names(enviro_dat1) %&gt;% str_subset(&quot;wasted&quot;)), ~subgroup, my_enviro_svy_sub, svymean) # bind with subgroup 0 allfoods_enviro_wasted_bysub1 &lt;- rbind(allfoods_enviro_wasted, allfoods_enviro_wasted_bysub) 6.3.1.4 Clean Output Data Apply the cleaning function (defined above) to the mean enviro datasets. # APPLY TO ENVIRO DATA ghg_dat &lt;- clean_func(x = allfoods_ghg_bysub1, y = &quot;ghg&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food ghg_mean ghg_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar 0.0504 0.000994 &lt;NA&gt; ## 2 0 Consumed_babyfood 0 0 &lt;NA&gt; ## 3 0 Consumed_coffee_tea 0.0453 0.00142 &lt;NA&gt; ## 4 0 Consumed_dairy_cow 0.326 0.00671 &lt;NA&gt; ## 5 0 Consumed_dairy_soy 0.00251 0.000218 &lt;NA&gt; ## 6 0 Consumed_fruit_exc_juice 0.0617 0.00371 &lt;NA&gt; ## 7 0 Consumed_fruit_juice 0.0536 0.00199 &lt;NA&gt; ## 8 0 Consumed_gr_refined 0.0620 0.00107 &lt;NA&gt; ## 9 0 Consumed_gr_whole 0.0169 0.000426 &lt;NA&gt; ## 10 0 Consumed_leg_tot 0.0158 0.000514 &lt;NA&gt; ## # ℹ 1,166 more rows ced_dat &lt;- clean_func(x = allfoods_ced_bysub1, y = &quot;ced&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food ced_mean ced_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar 0.492 0.0111 &lt;NA&gt; ## 2 0 Consumed_babyfood 0 0 &lt;NA&gt; ## 3 0 Consumed_coffee_tea 0.470 0.0146 &lt;NA&gt; ## 4 0 Consumed_dairy_cow 1.76 0.0362 &lt;NA&gt; ## 5 0 Consumed_dairy_soy 0.0164 0.00142 &lt;NA&gt; ## 6 0 Consumed_fruit_exc_juice 0.468 0.0204 &lt;NA&gt; ## 7 0 Consumed_fruit_juice 0.422 0.0143 &lt;NA&gt; ## 8 0 Consumed_gr_refined 0.354 0.00559 &lt;NA&gt; ## 9 0 Consumed_gr_whole 0.107 0.00230 &lt;NA&gt; ## 10 0 Consumed_leg_tot 0.0956 0.00270 &lt;NA&gt; ## # ℹ 1,166 more rows water_dat &lt;- clean_func(x = allfoods_water_bysub1, y = &quot;water&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food water_mean water_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar 35.8 0.719 &lt;NA&gt; ## 2 0 Consumed_babyfood 0 0 &lt;NA&gt; ## 3 0 Consumed_coffee_tea 51.5 1.62 &lt;NA&gt; ## 4 0 Consumed_dairy_cow 91.4 1.88 &lt;NA&gt; ## 5 0 Consumed_dairy_soy 0.219 0.0190 &lt;NA&gt; ## 6 0 Consumed_fruit_exc_juice 217. 11.2 &lt;NA&gt; ## 7 0 Consumed_fruit_juice 140. 3.93 &lt;NA&gt; ## 8 0 Consumed_gr_refined 96.5 1.48 &lt;NA&gt; ## 9 0 Consumed_gr_whole 32.3 1.09 &lt;NA&gt; ## 10 0 Consumed_leg_tot 24.6 1.07 &lt;NA&gt; ## # ℹ 1,166 more rows bluewater_dat &lt;- clean_func(x = allfoods_bluewater_bysub1, y = &quot;bluewater&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food bluewater_mean bluewater_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar 9.68 0.193 &lt;NA&gt; ## 2 0 Consumed_babyfood 0 0 &lt;NA&gt; ## 3 0 Consumed_coffee_tea 9.15 0.293 &lt;NA&gt; ## 4 0 Consumed_dairy_cow 21.8 0.449 &lt;NA&gt; ## 5 0 Consumed_dairy_soy 0.126 0.0109 &lt;NA&gt; ## 6 0 Consumed_fruit_exc_juice 29.4 1.49 &lt;NA&gt; ## 7 0 Consumed_fruit_juice 16.9 0.500 &lt;NA&gt; ## 8 0 Consumed_gr_refined 30.7 0.451 &lt;NA&gt; ## 9 0 Consumed_gr_whole 6.66 0.171 &lt;NA&gt; ## 10 0 Consumed_leg_tot 5.87 0.213 &lt;NA&gt; ## # ℹ 1,166 more rows fl_dat &lt;- clean_func(x = allfoods_fl_bysub1, y = &quot;fl&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food fl_mean fl_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 Consumed_added_sugar 0.0223 0.000390 &lt;NA&gt; ## 2 0 Consumed_babyfood 0 0 &lt;NA&gt; ## 3 0 Consumed_coffee_tea 0 0 &lt;NA&gt; ## 4 0 Consumed_dairy_cow 0.0412 0.000847 &lt;NA&gt; ## 5 0 Consumed_dairy_soy 0.00274 0.000238 &lt;NA&gt; ## 6 0 Consumed_fruit_exc_juice 0.0304 0.00147 &lt;NA&gt; ## 7 0 Consumed_fruit_juice 0.0264 0.000803 &lt;NA&gt; ## 8 0 Consumed_gr_refined 0.00801 0.000203 &lt;NA&gt; ## 9 0 Consumed_gr_whole 0.00205 0.0000627 &lt;NA&gt; ## 10 0 Consumed_leg_tot 0.00406 0.000141 &lt;NA&gt; ## # ℹ 1,166 more rows # join cleaned datasets enviro_dat &lt;- left_join(ghg_dat, ced_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) %&gt;% left_join(water_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) %&gt;% left_join(bluewater_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) %&gt;% left_join(fl_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) # more cleaning enviro_dat1 &lt;- enviro_dat %&gt;% mutate(intake_type = case_when(grepl(&quot;Consumed&quot;, food) ~ &quot;Consumed&quot;, grepl(&quot;Wasted&quot;, food) ~ &quot;Wasted&quot;, grepl(&quot;Inedible&quot;, food) ~ &quot;Inedible&quot;)) %&gt;% mutate(food = gsub(&quot;Consumed_|Wasted_|Inedible_&quot;, &quot;&quot;, food)) # pivot to wide enviro_dat2 &lt;- enviro_dat1 %&gt;% pivot_wider(names_from = intake_type, values_from = !c(subgroup, food, intake_type)) %&gt;% arrange(subgroup, food) Apply the cleaning function (defined above) to the mean consumed, inedible, and wasted datasets. # APPLY FUNCTION TO INTAKE DAT enviro_consumed_dat &lt;- clean_func(x = allfoods_enviro_consumed_bysub1, y = &quot;consumed&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food consumed_mean consumed_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar 81.1 1.71 &lt;NA&gt; ## 2 0 babyfood 1.09 0.176 &lt;NA&gt; ## 3 0 coffee_tea 6.84 0.223 &lt;NA&gt; ## 4 0 dairy_cow 189. 5.04 &lt;NA&gt; ## 5 0 dairy_soy 9.72 0.843 &lt;NA&gt; ## 6 0 fruit_exc_juice 107. 4.03 &lt;NA&gt; ## 7 0 fruit_juice 57.0 1.80 &lt;NA&gt; ## 8 0 gr_refined 108. 1.31 &lt;NA&gt; ## 9 0 gr_whole 33.6 0.831 &lt;NA&gt; ## 10 0 leg_tot 21.5 0.577 &lt;NA&gt; ## # ℹ 1,166 more rows enviro_wasted_dat &lt;- clean_func(x = allfoods_enviro_wasted_bysub1, y = &quot;wasted&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food wasted_mean wasted_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar 41.3 0.887 &lt;NA&gt; ## 2 0 babyfood 0.153 0.0461 &lt;NA&gt; ## 3 0 coffee_tea 0 0 &lt;NA&gt; ## 4 0 dairy_cow 60.4 1.51 &lt;NA&gt; ## 5 0 dairy_soy 2.64 0.229 &lt;NA&gt; ## 6 0 fruit_exc_juice 84.4 5.04 &lt;NA&gt; ## 7 0 fruit_juice 8.06 0.326 &lt;NA&gt; ## 8 0 gr_refined 31.3 0.418 &lt;NA&gt; ## 9 0 gr_whole 8.20 0.189 &lt;NA&gt; ## 10 0 leg_tot 4.91 0.149 &lt;NA&gt; ## # ℹ 1,166 more rows enviro_inedible_dat &lt;- clean_func(x = allfoods_enviro_inedible_bysub1, y = &quot;inedible&quot;) %&gt;% select(-food_type) ## # A tibble: 1,176 × 5 ## subgroup food inedible_mean inedible_se food_type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0 added_sugar 0 0 &lt;NA&gt; ## 2 0 babyfood 0.0475 0.0473 &lt;NA&gt; ## 3 0 coffee_tea 0 0 &lt;NA&gt; ## 4 0 dairy_cow 0 0 &lt;NA&gt; ## 5 0 dairy_soy 0 0 &lt;NA&gt; ## 6 0 fruit_exc_juice 87.3 6.06 &lt;NA&gt; ## 7 0 fruit_juice 0 0 &lt;NA&gt; ## 8 0 gr_refined 0 0 &lt;NA&gt; ## 9 0 gr_whole 5.30 0.245 &lt;NA&gt; ## 10 0 leg_tot 1.18 0.0663 &lt;NA&gt; ## # ℹ 1,166 more rows # join enviro_intake_dat &lt;- left_join(enviro_consumed_dat, enviro_wasted_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) %&gt;% left_join(enviro_inedible_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) # join enviro and intake dat enviro_final_dat &lt;- left_join(enviro_dat2, enviro_intake_dat, by = c(&quot;subgroup&quot;, &quot;food&quot;)) %&gt;% rename(fcid_consumed_mean = consumed_mean, fcid_consumed_se = consumed_se, fcid_wasted_mean = wasted_mean, fcid_wasted_se = wasted_se, fcid_inedible_mean = inedible_mean, fcid_inedible_se = inedible_se) # look at just inedible and wasted enviro_final_dat %&gt;% filter(subgroup == 0) %&gt;% select(food, fcid_consumed_mean, fcid_wasted_mean, fcid_inedible_mean) %&gt;% head() ## # A tibble: 6 × 4 ## food fcid_consumed_mean fcid_wasted_mean fcid_inedible_mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 added_sugar 81.1 41.3 0 ## 2 babyfood 1.09 0.153 0.0475 ## 3 coffee_tea 6.84 0 0 ## 4 dairy_cow 189. 60.4 0 ## 5 dairy_soy 9.72 2.64 0 ## 6 fruit_exc_juice 107. 84.4 87.3 # something funky happening with inedible amts of meat # update: this is correct, fcid weight basis for meat is boneless meat so inedible=0 6.3.2 Environment/Social Impact Factors, Per 100 Grams and Per 1 DGA Serving First, join with the conversion units. # merge with units enviro_final_dat1 &lt;- enviro_final_dat %&gt;% left_join(units, by = c(&quot;food&quot; = &quot;Food_group&quot;)) enviro_final_dat1 %&gt;% filter(is.na(Conversion_to_grams)) #good ## # A tibble: 0 × 19 ## # ℹ 19 variables: subgroup &lt;dbl&gt;, food &lt;chr&gt;, ghg_mean_Consumed &lt;dbl&gt;, ghg_se_Consumed &lt;dbl&gt;, ## # ced_mean_Consumed &lt;dbl&gt;, ced_se_Consumed &lt;dbl&gt;, water_mean_Consumed &lt;dbl&gt;, water_se_Consumed &lt;dbl&gt;, ## # bluewater_mean_Consumed &lt;dbl&gt;, bluewater_se_Consumed &lt;dbl&gt;, fl_mean_Consumed &lt;dbl&gt;, ## # fl_se_Consumed &lt;dbl&gt;, fcid_consumed_mean &lt;dbl&gt;, fcid_consumed_se &lt;dbl&gt;, fcid_wasted_mean &lt;dbl&gt;, ## # fcid_wasted_se &lt;dbl&gt;, fcid_inedible_mean &lt;dbl&gt;, fcid_inedible_se &lt;dbl&gt;, Conversion_to_grams &lt;dbl&gt; Then, calculate the environment/social impact factors (i) per 100 grams and (ii) per DGA unit. To calculate the impacts (e.g., GHG) per 100 grams, you divide the daily mean GHG of the food group by the daily amount of food consumed AND inedible, and then multiply by 100. Note: The variable “ghg_mean_Consumed” represents the GHG impact of consumed and inedible food (because the impact of both the consumed and inedible amounts is included in the original datafield impact factors). Therefore, the denominator of the equation is the sum of consumed food AND inedible food. enviro_final_dat2 &lt;- enviro_final_dat1 %&gt;% rowwise() %&gt;% mutate(#GHG GHGper100gram_consumed = ifelse(fcid_consumed_mean == 0, 0, (ghg_mean_Consumed / sum(fcid_consumed_mean, fcid_inedible_mean)) * 100), GHGperDGA_consumed = GHGper100gram_consumed * (Conversion_to_grams / 100), #CED CEDper100gram_consumed = ifelse(fcid_consumed_mean == 0, 0, (ced_mean_Consumed / sum(fcid_consumed_mean, fcid_inedible_mean)) * 100), CEDperDGA_consumed = CEDper100gram_consumed * (Conversion_to_grams / 100), #WATER WATERper100gram_consumed = ifelse(fcid_consumed_mean == 0, 0, (water_mean_Consumed / sum(fcid_consumed_mean, fcid_inedible_mean)) * 100), WATERperDGA_consumed = WATERper100gram_consumed * (Conversion_to_grams / 100), #BLUEWATER BLUEWATERper100gram_consumed = ifelse(fcid_consumed_mean == 0, 0, (bluewater_mean_Consumed / sum(fcid_consumed_mean, fcid_inedible_mean)) * 100), BLUEWATERperDGA_consumed = BLUEWATERper100gram_consumed * (Conversion_to_grams / 100), #FORCED LABOR FLper100gram_consumed = ifelse(fcid_consumed_mean == 0, 0, (fl_mean_Consumed / sum(fcid_consumed_mean, fcid_inedible_mean)) * 100), FLperDGA_consumed = FLper100gram_consumed * (Conversion_to_grams / 100)) %&gt;% select(-Conversion_to_grams) 6.4 Finalize Impact Factors 6.4.1 Merge Cost, Environment, and Social Impact Factors Merge all of the impact factors into one dataset. # cost impact factors cost_IFs &lt;- cost_final_dat2 %&gt;% rename(costper100g = costper100gram_consumed, costperDGA = costperDGA_consumed) %&gt;% filter(!(food %in% c(&quot;babyfood&quot;, &quot;coffee_tea&quot;, &quot;other&quot;, &quot;water&quot;))) # environment impact factors enviro_IFs &lt;- enviro_final_dat2 %&gt;% filter(!(food %in% c(&quot;babyfood&quot;, &quot;coffee_tea&quot;, &quot;other&quot;, &quot;water&quot;))) %&gt;% rename(GHGperDGA = GHGperDGA_consumed, GHGper100g = GHGper100gram_consumed, CEDperDGA = CEDperDGA_consumed, CEDper100g = CEDper100gram_consumed, WATERperDGA = WATERperDGA_consumed, WATERper100g = WATERper100gram_consumed, BLUEWATERperDGA = BLUEWATERperDGA_consumed, BLUEWATERper100g = BLUEWATERper100gram_consumed, FLperDGA = FLperDGA_consumed, FLper100g = FLper100gram_consumed) 6.5 Calculate Inedible and Wasted Proportions 6.5.1 Environment/Social The following proportions were calculated at the FCID-level: Wasted Proportion = Mean Wasted Amount / Mean Edible Amount Inedible Proportion = Mean Inedible Amount / Mean Purchased Amount enviro_IFs1 &lt;- enviro_IFs %&gt;% rowwise() %&gt;% mutate(# coefficients wasted_coef_fcid = fcid_wasted_mean / fcid_consumed_mean, inedible_coef_fcid = fcid_inedible_mean / fcid_consumed_mean, # amounts fcid_purchased_mean = sum(fcid_consumed_mean, fcid_wasted_mean, fcid_inedible_mean), fcid_edible_mean = sum(fcid_consumed_mean, fcid_wasted_mean), # proportions wasted_prop_fcid = fcid_wasted_mean / fcid_edible_mean, inedible_prop_fcid = fcid_inedible_mean / fcid_purchased_mean, consumed_prop_fcid = fcid_consumed_mean / fcid_edible_mean, prop_sum = sum(wasted_prop_fcid, consumed_prop_fcid)) ## change to summing wasted/edible and consumed/edible so that this sums to one, and can use as a check # is sum = 1? table(enviro_IFs1$prop_sum, useNA = &quot;always&quot;) #good ## ## 1 &lt;NA&gt; ## 980 0 # create dataset with just IFs enviro_IFs_sub &lt;- enviro_IFs1 %&gt;% select(subgroup, food, wasted_coef_fcid, wasted_prop_fcid, inedible_coef_fcid, inedible_prop_fcid, contains(&quot;perDGA&quot;)) # look at a few foods enviro_IFs_sub %&gt;% filter(food == &quot;gr_whole&quot;) %&gt;% head() ## # A tibble: 6 × 11 ## # Rowwise: ## subgroup food wasted_coef_fcid wasted_prop_fcid inedible_coef_fcid inedible_prop_fcid GHGperDGA CEDperDGA ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 gr_wh… 0.244 0.196 0.158 0.113 0.0222 0.141 ## 2 1 gr_wh… 0.256 0.204 0.115 0.0841 0.0256 0.157 ## 3 2 gr_wh… 0.256 0.204 0.106 0.0778 0.0267 0.179 ## 4 3 gr_wh… 0.249 0.199 0.141 0.101 0.0248 0.168 ## 5 4 gr_wh… 0.255 0.203 0.168 0.118 0.0250 0.140 ## 6 5 gr_wh… 0.240 0.194 0.181 0.127 0.0210 0.135 ## # ℹ 3 more variables: WATERperDGA &lt;dbl&gt;, BLUEWATERperDGA &lt;dbl&gt;, FLperDGA &lt;dbl&gt; enviro_IFs_sub %&gt;% filter(food == &quot;pf_redm_tot&quot;) %&gt;% head() ## # A tibble: 6 × 11 ## # Rowwise: ## subgroup food wasted_coef_fcid wasted_prop_fcid inedible_coef_fcid inedible_prop_fcid GHGperDGA CEDperDGA ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 pf_re… 0.306 0.234 0 0 0.717 1.65 ## 2 1 pf_re… 0.310 0.237 0 0 0.693 1.62 ## 3 2 pf_re… 0.314 0.239 0 0 0.682 1.60 ## 4 3 pf_re… 0.295 0.228 0 0 0.784 1.76 ## 5 4 pf_re… 0.305 0.234 0 0 0.732 1.64 ## 6 5 pf_re… 0.306 0.234 0 0 0.723 1.67 ## # ℹ 3 more variables: WATERperDGA &lt;dbl&gt;, BLUEWATERperDGA &lt;dbl&gt;, FLperDGA &lt;dbl&gt; enviro_IFs_sub %&gt;% filter(food == &quot;veg_dg&quot;) %&gt;% head() ## # A tibble: 6 × 11 ## # Rowwise: ## subgroup food wasted_coef_fcid wasted_prop_fcid inedible_coef_fcid inedible_prop_fcid GHGperDGA CEDperDGA ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 veg_dg 0.381 0.276 0.757 0.354 0.0449 0.390 ## 2 1 veg_dg 0.288 0.223 0.568 0.306 0.0445 0.385 ## 3 2 veg_dg 0.595 0.373 0.967 0.377 0.0338 0.280 ## 4 3 veg_dg 0.317 0.241 0.828 0.386 0.0600 0.537 ## 5 4 veg_dg 0.398 0.285 0.793 0.362 0.0466 0.406 ## 6 5 veg_dg 0.304 0.233 0.722 0.356 0.0472 0.413 ## # ℹ 3 more variables: WATERperDGA &lt;dbl&gt;, BLUEWATERperDGA &lt;dbl&gt;, FLperDGA &lt;dbl&gt; 6.5.2 Cost The following proportions were calculated at the FNDDS-level: Wasted Proportion = Mean Wasted Amount / Mean Edible Amount Inedible Proportion = Mean Inedible Amount / Mean Purchased Amount cost_IFs1 &lt;- cost_IFs %&gt;% rowwise() %&gt;% mutate(# coefficients wasted_coef_fndds = fndds_wasted_mean / fndds_consumed_mean, inedible_coef_fndds = fndds_inedible_mean / fndds_consumed_mean, # amounts fndds_purchased_mean = sum(fndds_consumed_mean, fndds_wasted_mean, fndds_inedible_mean), fndds_edible_mean = sum(fndds_consumed_mean, fndds_wasted_mean), # proportions wasted_prop_fndds = ifelse(fndds_edible_mean == 0, 0, fndds_wasted_mean / fndds_edible_mean), inedible_prop_fndds = ifelse(fndds_purchased_mean == 0, 0, fndds_inedible_mean / fndds_purchased_mean), consumed_prop_fndds = ifelse(fndds_edible_mean == 0, 0, fndds_consumed_mean / fndds_edible_mean), prop_sum_fndds = sum(wasted_prop_fndds, consumed_prop_fndds)) ##c hange to summing wasted/edible and consumed/edible so that this sums to one, and can use as a check table(cost_IFs1$prop_sum_fndds, useNA = &quot;always&quot;) ## ## 0 1 &lt;NA&gt; ## 363 4194 0 # check cost_IFs1 %&gt;% filter(wasted_prop_fndds == 0) %&gt;% head() ## # A tibble: 6 × 23 ## # Rowwise: ## subgroup food food_type mixed_dish price_mean_Consumed price_se_Consumed fndds_consumed_mean ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 fruit_juice Non-Grocery Mixed 0 0 0 ## 2 1 veg_oth Grocery Mixed 0 0 0 ## 3 1 veg_oth Non-Grocery Mixed 0 0 0 ## 4 1 veg_oth Total Mixed 0 0 0 ## 5 2 fruit_juice Grocery Mixed 0 0 0 ## 6 2 fruit_juice Non-Grocery Mixed 0 0 0 ## # ℹ 16 more variables: fndds_consumed_se &lt;dbl&gt;, fndds_wasted_mean &lt;dbl&gt;, fndds_wasted_se &lt;dbl&gt;, ## # fndds_inedible_mean &lt;dbl&gt;, fndds_inedible_se &lt;dbl&gt;, Conversion_to_grams &lt;dbl&gt;, costper100g &lt;dbl&gt;, ## # costperDGA &lt;dbl&gt;, wasted_coef_fndds &lt;dbl&gt;, inedible_coef_fndds &lt;dbl&gt;, fndds_purchased_mean &lt;dbl&gt;, ## # fndds_edible_mean &lt;dbl&gt;, wasted_prop_fndds &lt;dbl&gt;, inedible_prop_fndds &lt;dbl&gt;, consumed_prop_fndds &lt;dbl&gt;, ## # prop_sum_fndds &lt;dbl&gt; # subset cost_IFs_sub &lt;- cost_IFs1 %&gt;% select(subgroup, food, food_type, mixed_dish, wasted_coef_fndds, wasted_prop_fndds, inedible_coef_fndds, inedible_prop_fndds, costperDGA) # check a few cost_IFs_sub %&gt;% filter(food == &quot;gr_whole&quot;) %&gt;% head() ## # A tibble: 6 × 9 ## # Rowwise: ## subgroup food food_type mixed_dish wasted_coef_fndds wasted_prop_fndds inedible_coef_fndds ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 gr_whole Grocery Mixed 0.287 0.223 0.111 ## 2 0 gr_whole Grocery Non-Mixed 0.174 0.148 0.0406 ## 3 0 gr_whole Non-Grocery Mixed 0.527 0.345 0.713 ## 4 0 gr_whole Non-Grocery Non-Mixed 0.172 0.147 0.0239 ## 5 0 gr_whole Total Mixed 0.325 0.245 0.207 ## 6 0 gr_whole Total Non-Mixed 0.174 0.148 0.0388 ## # ℹ 2 more variables: inedible_prop_fndds &lt;dbl&gt;, costperDGA &lt;dbl&gt; cost_IFs_sub %&gt;% filter(food == &quot;pf_redm&quot;) %&gt;% head() ## # A tibble: 6 × 9 ## # Rowwise: ## subgroup food food_type mixed_dish wasted_coef_fndds wasted_prop_fndds inedible_coef_fndds ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 pf_redm Grocery Mixed 0.297 0.229 0.0781 ## 2 0 pf_redm Grocery Non-Mixed 0.346 0.257 0.000443 ## 3 0 pf_redm Non-Grocery Mixed 0.285 0.222 0.0548 ## 4 0 pf_redm Non-Grocery Non-Mixed 0.330 0.248 0.000421 ## 5 0 pf_redm Total Mixed 0.292 0.226 0.0676 ## 6 0 pf_redm Total Non-Mixed 0.340 0.254 0.000435 ## # ℹ 2 more variables: inedible_prop_fndds &lt;dbl&gt;, costperDGA &lt;dbl&gt; 6.6 Export Data # cost IFs write_csv(cost_IFs_sub, paste(&quot;data_inputs/IMPACT_FACTORS/output_data/Impacts_cost_&quot;, my_date, &quot;.csv&quot;, sep=&quot;&quot;)) # enviro IFs write_csv(enviro_IFs_sub, paste(&quot;data_inputs/IMPACT_FACTORS/output_data/Impacts_enviro_&quot;, my_date, &quot;.csv&quot;, sep=&quot;&quot;)) "],["finalize-model-data-inputs.html", "Chapter 7 Finalize Model Data Inputs 7.1 Clean and Merge All Inputs 7.2 Copy Model Inputs to GitHub", " Chapter 7 Finalize Model Data Inputs This chapter walks you through the final cleaning process for the model inputs. Set up the working environment. rm(list = ls()) options(scipen=999) library(tidyverse) # create date value date &lt;- Sys.Date() 7.1 Clean and Merge All Inputs Import the diet/health dataset (i.e., mega_costenv). nhanes &lt;- read_csv(paste0(&quot;data_inputs/FINAL/cleaned_data/mega_costenv_structure_temp_&quot;, date, &quot;_FINAL.csv&quot;)) Here is where you specify the substitution effects. For the four-pillar paper, we set these to 0. However, if you will take into account substituion effects (Kyra, I mean you), you will need to update these numbers. Please consult Fred and/or Nicole as to what these values should be for your analysis. # add in substitution effects, currently set to 0 nhanes1 &lt;- nhanes %&gt;% mutate(Mean_substitution_Food_price = 0, SE_substitution_Food_price = 0, Mean_substitution_CED = 0, SE_substitution_CED = 0, Mean_substitution_GHG = 0, SE_substitution_GHG = 0, Mean_substitution_WATER = 0, SE_substitution_WATER = 0, Mean_substitution_BLUEWATER = 0, SE_substitution_BLUEWATER = 0, Mean_substitution_FL = 0, SE_substitution_FL = 0) Import the impact factors. enviro_IFs &lt;- read_csv(paste0(&quot;data_inputs/IMPACT_FACTORS/output_data/Impacts_enviro_&quot;, date, &quot;.csv&quot;)) cost_IFs &lt;- read_csv(paste0(&quot;data_inputs/IMPACT_FACTORS/output_data/Impacts_cost_&quot;, date, &quot;.csv&quot;)) For the cost impact factors, we made the decsion to use the factors for the “non-mixed” dishes, as we thought these were the best representation of the food groups in the DGA (which is what our analysis focused on). Again, you may need to consult Nicole on what the best decision is for your analysis. # use the &#39;non-mixed&#39; dishes for impact factors cost_IFs1 &lt;- cost_IFs %&gt;% filter(mixed_dish == &quot;Non-Mixed&quot;) %&gt;% select(-mixed_dish) %&gt;% filter(subgroup != 0) # remove subgroup 0 enviro_IFs1 &lt;- enviro_IFs %&gt;% filter(subgroup != 0) # remove subgroup 0 To match the format of the cost impact factors, we need to duplicate the environmental impact factors three times to account for the different food types (i.e., grocery, non-grocery, and total). We don’t have different environmental factors for these different food types, so we just use the exact same values across all three types (hence why we just duplicate). enviro_IFs_tot &lt;- enviro_IFs1 %&gt;% mutate(food_type = &quot;Total&quot;) enviro_IFs_gro &lt;- enviro_IFs1 %&gt;% mutate(food_type = &quot;Grocery&quot;) enviro_IFs_non &lt;- enviro_IFs1 %&gt;% mutate(food_type = &quot;Non-Grocery&quot;) # bind together enviro_IFs2 &lt;- rbind(enviro_IFs_tot, enviro_IFs_gro, enviro_IFs_non) %&gt;% relocate(food_type, .after = food) %&gt;% arrange(subgroup, food, food_type) Merge the environmental and cost impact factors. # compare table(cost_IFs1$subgroup, useNA = &quot;always&quot;) table(enviro_IFs2$subgroup, useNA = &quot;always&quot;) #same table(cost_IFs1$food, useNA = &quot;always&quot;) table(enviro_IFs2$food, useNA = &quot;always&quot;) #diff food groups table(cost_IFs1$food_type, useNA = &quot;always&quot;) table(enviro_IFs2$food_type, useNA = &quot;always&quot;) #same # merge enviro and cost impact factors impact_factors &lt;- full_join(cost_IFs1, enviro_IFs2, by = c(&quot;subgroup&quot;, &quot;food&quot;, &quot;food_type&quot;)) %&gt;% arrange(subgroup, food, food_type) Below, we set the standard errors for the environmental (and social) impact factors to 0 since we don’t have any variability values from dataField to use. We also create the “counterfactual” impact factors, which are just the same. This is mostly redundant, it’s just a necessary thing to do based on the way the model code is set up to run. impact_factors1 &lt;- impact_factors %&gt;% rename( Mean_CED = CEDperDGA, Mean_GHG = GHGperDGA, Mean_WATER = WATERperDGA, Mean_BLUEWATER = BLUEWATERperDGA, Mean_Food_price = costperDGA, Mean_FL = FLperDGA ) %&gt;% mutate( # set SE to 0 SE_CED = 0, SE_GHG = 0, SE_WATER = 0, SE_BLUEWATER = 0, SE_Food_price = 0, SE_FL = 0, # set counterfactual impact factors # CED CF_Mean_CED = Mean_CED, CF_SE_CED = SE_CED, #GHG CF_Mean_GHG = Mean_GHG, CF_SE_GHG = SE_GHG, # Water CF_Mean_WATER = Mean_WATER, CF_SE_WATER = SE_WATER, # Bluewater CF_Mean_BLUEWATER = Mean_BLUEWATER, CF_SE_BLUEWATER = SE_BLUEWATER, # Price CF_Mean_Food_price = Mean_Food_price, CF_SE_Food_price = SE_Food_price, # Forced labor CF_Mean_FL = Mean_FL, CF_SE_FL = SE_FL) Join impact factors with diet/health data. comb &lt;- left_join(nhanes1, impact_factors1, by = c(&quot;subgroup_id&quot; = &quot;subgroup&quot;, &quot;Foodgroup&quot; = &quot;food&quot;, &quot;datatype&quot; = &quot;food_type&quot;)) The impact factor units are manually defined below. We also set all the conversions to 1 for the four-pillar analysis (consult Nicole for this). We also set all of the inedible and wasted proportions. For the environmental impact factors, they’re set to “inedible_prop_fcid” and “wasted_prop_fcid”, and for the economic impact factor, it’s set to “inedible_prop_fndds” and “wasted_prop_fndds”. Similar to above, the standard errors are set to 0. Lastly, similar to above, the counterfactual versions of the inedible/wasted proportions are set to their non-counterfactual counterparts. comb1 &lt;- comb %&gt;% mutate(Food_price_unit = &quot;USD&quot;, Food_price_impact_unit = paste0(Food_price_unit, &quot;/&quot;, TMRED_intake_unit), CED_unit = &quot;MJ&quot;, CED_impact_unit = paste0(CED_unit, &quot;/&quot;, TMRED_intake_unit), GHG_unit = &quot;kgCO2-eq&quot;, GHG_impact_unit = paste0(GHG_unit, &quot;/&quot;, TMRED_intake_unit), WATER_unit = &quot;L-eq&quot;, WATER_impact_unit = paste0(WATER_unit, &quot;/&quot;, TMRED_intake_unit), BLUEWATER_unit = &quot;L&quot;, BLUEWATER_impact_unit = paste0(BLUEWATER_unit, &quot;/&quot;, TMRED_intake_unit), FL_unit = &quot;mrh-eq&quot;, FL_impact_unit = paste0(FL_unit, &quot;/&quot;, TMRED_intake_unit), # set to 1 for now Food_price_to_intake_conversion = 1, CED_to_intake_conversion = 1, GHG_to_intake_conversion = 1, WATER_to_intake_conversion = 1, BLUEWATER_to_intake_conversion = 1, FL_to_intake_conversion = 1, substitution_unit = 1, # WASTE AND INEDIBLE PROPORTIONS # i) inedible CED_inedible_p = inedible_prop_fcid, GHG_inedible_p = inedible_prop_fcid, WATER_inedible_p = inedible_prop_fcid, BLUEWATER_inedible_p = inedible_prop_fcid, FL_inedible_p = inedible_prop_fcid, Food_price_inedible_p = inedible_prop_fndds, CED_inedible_p_se = 0, GHG_inedible_p_se = 0, WATER_inedible_p_se = 0, BLUEWATER_inedible_p_se = 0, FL_inedible_p_se = 0, Food_price_inedible_p_se = 0, # ii) wasted CED_foodwaste_p = wasted_prop_fcid, GHG_foodwaste_p = wasted_prop_fcid, WATER_foodwaste_p = wasted_prop_fcid, BLUEWATER_foodwaste_p = wasted_prop_fcid, FL_foodwaste_p = wasted_prop_fcid, Food_price_foodwaste_p = wasted_prop_fndds, CED_foodwaste_p_se = 0, GHG_foodwaste_p_se = 0, WATER_foodwaste_p_se = 0, BLUEWATER_foodwaste_p_se = 0, FL_foodwaste_p_se = 0, Food_price_foodwaste_p_se = 0, # WASTE AND INEDIBLE (COUNTERFACTUALS) # i) inedible CF_CED_inedible_p = CED_inedible_p, CF_GHG_inedible_p = GHG_inedible_p, CF_WATER_inedible_p = WATER_inedible_p, CF_BLUEWATER_inedible_p = BLUEWATER_inedible_p, CF_Food_price_inedible_p = Food_price_inedible_p, CF_FL_inedible_p = FL_inedible_p, CF_CED_inedible_p_se = CED_inedible_p_se, CF_GHG_inedible_p_se = GHG_inedible_p_se, CF_WATER_inedible_p_se = WATER_inedible_p_se, CF_BLUEWATER_inedible_p_se = BLUEWATER_inedible_p_se, CF_Food_price_inedible_p_se = Food_price_inedible_p_se, CF_FL_inedible_p_se = FL_inedible_p_se, # ii) wasted CF_CED_foodwaste_p = CED_foodwaste_p, CF_GHG_foodwaste_p = GHG_foodwaste_p, CF_WATER_foodwaste_p = WATER_foodwaste_p, CF_BLUEWATER_foodwaste_p = BLUEWATER_foodwaste_p, CF_Food_price_foodwaste_p = Food_price_foodwaste_p, CF_FL_foodwaste_p = FL_foodwaste_p, CF_CED_foodwaste_p_se = CED_foodwaste_p_se, CF_GHG_foodwaste_p_se = GHG_foodwaste_p_se, CF_WATER_foodwaste_p_se = WATER_foodwaste_p_se, CF_BLUEWATER_foodwaste_p_se = BLUEWATER_foodwaste_p_se, CF_Food_price_foodwaste_p_se = Food_price_foodwaste_p_se, CF_FL_foodwaste_p_se = FL_foodwaste_p_se) Change some variables names. comb2 &lt;- comb1 %&gt;% rename(Population_size = population) %&gt;% mutate(Sex_label = ifelse(Sex == 1, &quot;Female&quot;, &quot;Male&quot;), Intake_unit = paste0(TMRED_intake_unit, &quot;/day&quot;)) List out the final order your want for the variables. final.order &lt;- c( &quot;subgroup_id&quot;, &quot;Age&quot;, &quot;Age_label&quot;, &quot;Sex&quot;, &quot;Sex_label&quot;, &quot;Race&quot;, &quot;Race_label&quot;, &quot;Foodgroup&quot;, &quot;datatype&quot;, &quot;diet_pattern&quot;, &quot;Mean_Intake&quot;, &quot;SE_Intake&quot;, &quot;sigma_u_wgt&quot;, &quot;Intake_unit&quot;, &quot;pro_gro&quot;, &quot;pro_nongro&quot;, &quot;diet_label&quot;, &quot;Food_desc&quot;, &quot;CF_Mean_Intake&quot;, &quot;CF_SE_Intake&quot;, &quot;CF_sd_intake&quot;, &quot;CF_intake_unit&quot;, &quot;TMRED_Mean_Intake&quot;, &quot;TMRED_SD_Intake&quot;, &quot;TMRED_intake_unit&quot;, &quot;Population_size&quot;, &quot;overweight_rate&quot;, &quot;overweight_rate_se&quot;, &quot;hbp&quot;, &quot;hbp_se&quot;, &quot;nhb&quot;, &quot;nhb_se&quot;, &quot;sbp_mean&quot;, &quot;sbp_se&quot;, &quot;highSBP_rate&quot;, &quot;highSBP_rate_se&quot;, &quot;Mean_GHG&quot;, &quot;SE_GHG&quot;, &quot;GHG_unit&quot;, &quot;GHG_impact_unit&quot;, &quot;Mean_CED&quot;, &quot;SE_CED&quot;, &quot;CED_unit&quot;, &quot;CED_impact_unit&quot;, &quot;Mean_WATER&quot;, &quot;SE_WATER&quot;, &quot;WATER_unit&quot;, &quot;WATER_impact_unit&quot;, &quot;Mean_BLUEWATER&quot;, &quot;SE_BLUEWATER&quot;, &quot;BLUEWATER_unit&quot;, &quot;BLUEWATER_impact_unit&quot;, &quot;Mean_FL&quot;, &quot;SE_FL&quot;, &quot;FL_unit&quot;, &quot;FL_impact_unit&quot;, &quot;Mean_Food_price&quot;, &quot;SE_Food_price&quot;, &quot;Food_price_unit&quot;, &quot;Food_price_impact_unit&quot;, &quot;CF_Mean_GHG&quot;, &quot;CF_SE_GHG&quot;, &quot;CF_Mean_CED&quot;, &quot;CF_SE_CED&quot;, &quot;CF_Mean_WATER&quot;, &quot;CF_SE_WATER&quot;, &quot;CF_Mean_BLUEWATER&quot;, &quot;CF_SE_BLUEWATER&quot;, &quot;CF_Mean_FL&quot;, &quot;CF_SE_FL&quot;, &quot;CF_Mean_Food_price&quot;, &quot;CF_SE_Food_price&quot;, &quot;Mean_substitution_GHG&quot;, &quot;SE_substitution_GHG&quot;, &quot;Mean_substitution_CED&quot;, &quot;SE_substitution_CED&quot;, &quot;Mean_substitution_WATER&quot;, &quot;SE_substitution_WATER&quot;, &quot;Mean_substitution_BLUEWATER&quot;, &quot;SE_substitution_BLUEWATER&quot;, &quot;Mean_substitution_FL&quot;, &quot;SE_substitution_FL&quot;, &quot;Mean_substitution_Food_price&quot;, &quot;SE_substitution_Food_price&quot;, &quot;GHG_to_intake_conversion&quot;, &quot;CED_to_intake_conversion&quot;, &quot;WATER_to_intake_conversion&quot;, &quot;BLUEWATER_to_intake_conversion&quot;, &quot;FL_to_intake_conversion&quot;, &quot;Food_price_to_intake_conversion&quot;, &quot;substitution_unit&quot;, &quot;GHG_inedible_p&quot;, &quot;GHG_inedible_p_se&quot;, &quot;CED_inedible_p&quot;, &quot;CED_inedible_p_se&quot;, &quot;WATER_inedible_p&quot;, &quot;WATER_inedible_p_se&quot;, &quot;BLUEWATER_inedible_p&quot;, &quot;BLUEWATER_inedible_p_se&quot;, &quot;FL_inedible_p&quot;, &quot;FL_inedible_p_se&quot;, &quot;Food_price_inedible_p&quot;, &quot;Food_price_inedible_p_se&quot;, &quot;GHG_foodwaste_p&quot;, &quot;GHG_foodwaste_p_se&quot;, &quot;CED_foodwaste_p&quot;, &quot;CED_foodwaste_p_se&quot;, &quot;WATER_foodwaste_p&quot;, &quot;WATER_foodwaste_p_se&quot;, &quot;BLUEWATER_foodwaste_p&quot;, &quot;BLUEWATER_foodwaste_p_se&quot;, &quot;FL_foodwaste_p&quot;, &quot;FL_foodwaste_p_se&quot;, &quot;Food_price_foodwaste_p&quot;, &quot;Food_price_foodwaste_p_se&quot;, &quot;CF_GHG_inedible_p&quot;, &quot;CF_GHG_inedible_p_se&quot;, &quot;CF_CED_inedible_p&quot;, &quot;CF_CED_inedible_p_se&quot;, &quot;CF_WATER_inedible_p&quot;, &quot;CF_WATER_inedible_p_se&quot;, &quot;CF_BLUEWATER_inedible_p&quot;, &quot;CF_BLUEWATER_inedible_p_se&quot;, &quot;CF_FL_inedible_p&quot;, &quot;CF_FL_inedible_p_se&quot;, &quot;CF_Food_price_inedible_p&quot;, &quot;CF_Food_price_inedible_p_se&quot;, &quot;CF_GHG_foodwaste_p&quot;, &quot;CF_GHG_foodwaste_p_se&quot;, &quot;CF_CED_foodwaste_p&quot;, &quot;CF_CED_foodwaste_p_se&quot;, &quot;CF_WATER_foodwaste_p&quot;, &quot;CF_WATER_foodwaste_p_se&quot;, &quot;CF_BLUEWATER_foodwaste_p&quot;, &quot;CF_BLUEWATER_foodwaste_p_se&quot;, &quot;CF_FL_foodwaste_p&quot;, &quot;CF_FL_foodwaste_p_se&quot;, &quot;CF_Food_price_foodwaste_p&quot;, &quot;CF_Food_price_foodwaste_p_se&quot;) Apply the final order. # apply final &lt;- comb2[,final.order] Filter out diet variables you don’t want included in your dataset/analysis. final1 &lt;- final %&gt;% filter(!(Foodgroup %in% c(&quot;fiber&quot;, &quot;kcal&quot;, &quot;pf_animal&quot;, &quot;pf_leg&quot;, &quot;pf_plant&quot;, &quot;pf_soy&quot;, &quot;pufa_energy&quot;, &quot;sfat_energy&quot;, &quot;sea_omega3_fa&quot;, &quot;veg_leg&quot;))) Lastly, we decided as a team to utilize the inedible/wasted proportions that were calculated at the FCID-level (i.e., environmental impact factors). Below, we replace the cost inedible/wasted proportions with the GHG inedible/wasted proportions when they’re not missing. If they’re alrady NA, then they remain NA. final2 &lt;- final1 %&gt;% # renaming with _new to compare old vs. new values mutate(Food_price_inedible_p_new = ifelse(!(is.na(Food_price_inedible_p)) &amp; !(is.na(GHG_inedible_p)), GHG_inedible_p, Food_price_inedible_p), Food_price_inedible_p_se_new = ifelse(!(is.na(Food_price_inedible_p)) &amp; !(is.na(GHG_inedible_p)), GHG_inedible_p_se, Food_price_inedible_p_se), Food_price_foodwaste_p_new = ifelse(!(is.na(Food_price_foodwaste_p)) &amp; !(is.na(GHG_foodwaste_p)), GHG_foodwaste_p, Food_price_foodwaste_p), Food_price_foodwaste_p_se_new = ifelse(!(is.na(Food_price_foodwaste_p)) &amp; !(is.na(GHG_foodwaste_p)), GHG_foodwaste_p_se, Food_price_foodwaste_p_se)) # replacing the old inedible/ replacing with new, and getting rid of &quot;new&quot; to reduce confusion final3 &lt;- final2 %&gt;% mutate(Food_price_inedible_p = Food_price_inedible_p_new, Food_price_inedible_p_se = Food_price_inedible_p_se_new, Food_price_foodwaste_p = Food_price_foodwaste_p_new, Food_price_foodwaste_p_se = Food_price_foodwaste_p_se_new, CF_Food_price_inedible_p = Food_price_inedible_p_new, CF_Food_price_inedible_p_se = Food_price_inedible_p_se_new, CF_Food_price_foodwaste_p = Food_price_foodwaste_p_new, CF_Food_price_foodwaste_p_se = Food_price_foodwaste_p_se_new, Food_price_inedible_p_new=NULL, Food_price_inedible_p_se_new=NULL, Food_price_foodwaste_p_new=NULL, Food_price_foodwaste_p_se_new=NULL) Export to the “FINAL” folder. write_csv(final3, paste0(&quot;data_inputs/FINAL/model_data/mega_costenv_structure_&quot;, date, &quot;_FINAL.csv&quot;)) 7.2 Copy Model Inputs to GitHub All of the model input files are currently located in the “FINAL” folder on Box. Below, we copy them to GitHub so that we can access them on the cluster. current_folder &lt;- &quot;data_inputs/FINAL/model_data&quot; # where files currently live on Box new_folder &lt;- &quot;/Users/bmb73/Documents/GitHub/LASTING/in/FINAL&quot; # Github repo on Brooke&#39;s laptop # new_folder &lt;- &quot;/Users/fcudhe01/Documents/GitHub/LASTING/in/FINAL&quot; # Github repo on Fred&#39;s laptop list_of_files &lt;- list.files(current_folder, &quot;.csv&quot;) file.copy(file.path(current_folder, list_of_files), new_folder) ## [1] FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
